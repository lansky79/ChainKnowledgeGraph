"""
çŸ¥è¯†å›¾è°±æ•°æ®ç®¡ç†é¡µé¢
æä¾›æ•°æ®å¯¼å…¥ã€å¯¼å‡ºã€æŸ¥çœ‹ç­‰åŠŸèƒ½
"""
import streamlit as st
import pandas as pd
import numpy as np
import os
import json
import traceback
import logging
import sys
from datetime import datetime
from utils.db_connector import Neo4jConnector
from utils.export_handler import ExportHandler
from utils.analytics import Analytics
from utils.logger import setup_logger
import time

# è®¾ç½®æ—¥å¿—
logger = setup_logger("KG_Data_Management")

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®ç®¡ç†",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSï¼Œä½¿ç•Œé¢æ›´ç´§å‡‘
st.markdown("""
<style>
    .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
    }
    h1, h2, h3, h4, h5, h6 {
        margin-top: 0.5rem;
        margin-bottom: 0.5rem;
    }
    .export-section {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# é¡µé¢æ ‡é¢˜
st.title("ğŸ“Š æ•°æ®ç®¡ç†")

# åˆå§‹åŒ–ç»„ä»¶
@st.cache_resource
def get_components():
    """è·å–ç»„ä»¶å®ä¾‹ï¼ˆç¼“å­˜èµ„æºï¼‰"""
    db = Neo4jConnector()
    return {
        "db": db,
        "export_handler": ExportHandler(db),
        "analytics": Analytics(db)
    }

components = get_components()
db = components["db"]
export_handler = components["export_handler"]
analytics = components["analytics"]

# åˆ›å»ºé€‰é¡¹å¡
tab1, tab2, tab3, tab4 = st.tabs(["æ•°æ®å¯¼å…¥", "æ•°æ®å¯¼å‡º", "æ•°æ®æŸ¥çœ‹", "ç¤ºä¾‹æ•°æ®"])

# æ•°æ®å¯¼å…¥é€‰é¡¹å¡
with tab1:
    st.header("ğŸ“¥ å¯¼å…¥æ•°æ®åˆ°çŸ¥è¯†å›¾è°±")
    
    # æ–‡ä»¶ä¸Šä¼ éƒ¨åˆ†
    st.subheader("ä¸Šä¼ æ•°æ®æ–‡ä»¶")
    
    col1, col2 = st.columns(2)
    
    with col1:
        company_file = st.file_uploader("ä¸Šä¼ å…¬å¸æ•°æ® (JSONæ ¼å¼)", type=["json"], key="company_file")
        industry_file = st.file_uploader("ä¸Šä¼ è¡Œä¸šæ•°æ® (JSONæ ¼å¼)", type=["json"], key="industry_file")
        product_file = st.file_uploader("ä¸Šä¼ äº§å“æ•°æ® (JSONæ ¼å¼)", type=["json"], key="product_file")
    
    with col2:
        company_industry_file = st.file_uploader("ä¸Šä¼ å…¬å¸-è¡Œä¸šå…³ç³»æ•°æ® (JSONæ ¼å¼)", type=["json"], key="company_industry_file")
        company_product_file = st.file_uploader("ä¸Šä¼ å…¬å¸-äº§å“å…³ç³»æ•°æ® (JSONæ ¼å¼)", type=["json"], key="company_product_file")
        industry_industry_file = st.file_uploader("ä¸Šä¼ è¡Œä¸š-è¡Œä¸šå…³ç³»æ•°æ® (JSONæ ¼å¼)", type=["json"], key="industry_industry_file")
    
    # å¯¼å…¥æŒ‰é’®
    if st.button("ğŸ“¥ å¯¼å…¥æ•°æ®", key="import_button"):
        with st.spinner("æ­£åœ¨å¯¼å…¥æ•°æ®..."):
            try:
                # å¯¼å…¥èŠ‚ç‚¹æ•°æ®
                nodes_imported = 0
                relationships_imported = 0
                
                # å¯¼å…¥å…¬å¸æ•°æ®
                if company_file:
                    company_data = json.load(company_file)
                    st.info(f"æ­£åœ¨å¯¼å…¥ {len(company_data)} ä¸ªå…¬å¸èŠ‚ç‚¹...")
                    
                    for company in company_data:
                        db.query(
                            "MERGE (c:company {name: $name}) "
                            "ON CREATE SET c.description = $description",
                            {"name": company["name"], "description": company.get("description", "")}
                        )
                    
                    nodes_imported += len(company_data)
                
                # å¯¼å…¥è¡Œä¸šæ•°æ®
                if industry_file:
                    industry_data = json.load(industry_file)
                    st.info(f"æ­£åœ¨å¯¼å…¥ {len(industry_data)} ä¸ªè¡Œä¸šèŠ‚ç‚¹...")
                    
                    for industry in industry_data:
                        db.query(
                            "MERGE (i:industry {name: $name}) "
                            "ON CREATE SET i.description = $description",
                            {"name": industry["name"], "description": industry.get("description", "")}
                        )
                    
                    nodes_imported += len(industry_data)
                
                # å¯¼å…¥äº§å“æ•°æ®
                if product_file:
                    product_data = json.load(product_file)
                    st.info(f"æ­£åœ¨å¯¼å…¥ {len(product_data)} ä¸ªäº§å“èŠ‚ç‚¹...")
                    
                    for product in product_data:
                        db.query(
                            "MERGE (p:product {name: $name}) "
                            "ON CREATE SET p.description = $description",
                            {"name": product["name"], "description": product.get("description", "")}
                        )
                    
                    nodes_imported += len(product_data)
                
                # å¯¼å…¥å…³ç³»æ•°æ®
                # å¯¼å…¥å…¬å¸-è¡Œä¸šå…³ç³»
                if company_industry_file:
                    company_industry_data = json.load(company_industry_file)
                    st.info(f"æ­£åœ¨å¯¼å…¥ {len(company_industry_data)} ä¸ªå…¬å¸-è¡Œä¸šå…³ç³»...")
                    
                    for rel in company_industry_data:
                        db.query(
                            "MATCH (c:company {name: $company_name}), (i:industry {name: $industry_name}) "
                            "MERGE (c)-[r:æ‰€å±è¡Œä¸š]->(i)",
                            {"company_name": rel["company_name"], "industry_name": rel["industry_name"]}
                        )
                    
                    relationships_imported += len(company_industry_data)
                
                # å¯¼å…¥å…¬å¸-äº§å“å…³ç³»
                if company_product_file:
                    company_product_data = json.load(company_product_file)
                    st.info(f"æ­£åœ¨å¯¼å…¥ {len(company_product_data)} ä¸ªå…¬å¸-äº§å“å…³ç³»...")
                    
                    for rel in company_product_data:
                        db.query(
                            "MATCH (c:company {name: $company_name}), (p:product {name: $product_name}) "
                            "MERGE (c)-[r:ä¸»è¥äº§å“]->(p)",
                            {"company_name": rel["company_name"], "product_name": rel["product_name"]}
                        )
                    
                    relationships_imported += len(company_product_data)
                
                # å¯¼å…¥è¡Œä¸š-è¡Œä¸šå…³ç³»
                if industry_industry_file:
                    industry_industry_data = json.load(industry_industry_file)
                    st.info(f"æ­£åœ¨å¯¼å…¥ {len(industry_industry_data)} ä¸ªè¡Œä¸š-è¡Œä¸šå…³ç³»...")
                    
                    for rel in industry_industry_data:
                        db.query(
                            "MATCH (i1:industry {name: $from_industry}), (i2:industry {name: $to_industry}) "
                            "MERGE (i1)-[r:ä¸Šçº§è¡Œä¸š]->(i2)",
                            {"from_industry": rel["from_industry"], "to_industry": rel["to_industry"]}
                        )
                    
                    relationships_imported += len(industry_industry_data)
                
                # æ˜¾ç¤ºå¯¼å…¥ç»“æœ
                if nodes_imported > 0 or relationships_imported > 0:
                    st.success(f"âœ… æˆåŠŸå¯¼å…¥ {nodes_imported} ä¸ªèŠ‚ç‚¹å’Œ {relationships_imported} æ¡å…³ç³»")
                    # æ¸…é™¤ç¼“å­˜
                    st.cache_data.clear()
                else:
                    st.warning("æœªå¯¼å…¥ä»»ä½•æ•°æ®ï¼Œè¯·ä¸Šä¼ è‡³å°‘ä¸€ä¸ªæ•°æ®æ–‡ä»¶")
            
            except Exception as e:
                st.error(f"å¯¼å…¥æ•°æ®å¤±è´¥: {str(e)}")
                logger.error(f"å¯¼å…¥æ•°æ®å¤±è´¥: {str(e)}\n{traceback.format_exc()}")

# æ•°æ®å¯¼å‡ºé€‰é¡¹å¡
with tab2:
    st.header("ğŸ“¤ å¯¼å‡ºçŸ¥è¯†å›¾è°±æ•°æ®")
    
    # å¯¼å‡ºé€‰é¡¹
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("å¯¼å‡ºè®¾ç½®")
        
        # å¯¼å‡ºç±»å‹é€‰æ‹©
        export_type = st.selectbox(
            "é€‰æ‹©å¯¼å‡ºç±»å‹",
            ["å®Œæ•´å›¾è°±æ•°æ®", "åˆ†ææŠ¥å‘Š", "å®ä½“è¯¦æƒ…"],
            help="é€‰æ‹©è¦å¯¼å‡ºçš„æ•°æ®ç±»å‹"
        )
        
        # å¯¼å‡ºæ ¼å¼é€‰æ‹©
        export_format = st.selectbox(
            "å¯¼å‡ºæ ¼å¼",
            ["JSON", "CSV", "Excel"],
            help="é€‰æ‹©å¯¼å‡ºæ–‡ä»¶æ ¼å¼"
        )
        
        # å¦‚æœæ˜¯å®ä½“è¯¦æƒ…ï¼Œéœ€è¦é€‰æ‹©å®ä½“
        if export_type == "å®ä½“è¯¦æƒ…":
            entity_type = st.selectbox(
                "å®ä½“ç±»å‹",
                ["company", "industry", "product"],
                format_func=lambda x: {"company": "å…¬å¸", "industry": "è¡Œä¸š", "product": "äº§å“"}.get(x, x)
            )
            
            # è·å–å®ä½“åˆ—è¡¨
            try:
                entity_query = f"MATCH (n:{entity_type}) RETURN n.name as name ORDER BY n.name LIMIT 100"
                entity_results = db.query(entity_query)
                entity_names = [r["name"] for r in entity_results]
                
                if entity_names:
                    selected_entity = st.selectbox("é€‰æ‹©å®ä½“", entity_names)
                else:
                    st.warning(f"æš‚æ— {entity_type}æ•°æ®")
                    selected_entity = None
            except Exception as e:
                st.error(f"è·å–å®ä½“åˆ—è¡¨å¤±è´¥: {str(e)}")
                selected_entity = None
    
    with col2:
        st.subheader("å¯¼å‡ºæ“ä½œ")
        
        # å¯¼å‡ºæŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹å¯¼å‡º", key="export_button"):
            with st.spinner("æ­£åœ¨å‡†å¤‡å¯¼å‡ºæ•°æ®..."):
                try:
                    success = False
                    message = ""
                    file_data = None
                    filename = ""
                    
                    if export_type == "å®Œæ•´å›¾è°±æ•°æ®":
                        # å¯¼å‡ºå®Œæ•´å›¾è°±æ•°æ®
                        # è·å–æ‰€æœ‰èŠ‚ç‚¹å’Œè¾¹
                        nodes_query = """
                        CALL {
                            MATCH (c:company) RETURN id(c) as id, c.name as label, 'company' as type, c as properties
                            UNION ALL
                            MATCH (i:industry) RETURN id(i) as id, i.name as label, 'industry' as type, i as properties
                            UNION ALL
                            MATCH (p:product) RETURN id(p) as id, p.name as label, 'product' as type, p as properties
                        }
                        RETURN id, label, type, properties
                        """
                        
                        edges_query = """
                        MATCH (a)-[r]->(b)
                        RETURN id(a) as from, id(b) as to, type(r) as label, r as properties
                        """
                        
                        nodes_results = db.query(nodes_query)
                        edges_results = db.query(edges_query)
                        
                        nodes = [{"id": r["id"], "label": r["label"], "type": r["type"], **dict(r["properties"])} for r in nodes_results]
                        edges = [{"from": r["from"], "to": r["to"], "label": r["label"], **dict(r["properties"])} for r in edges_results]
                        
                        format_mapping = {"JSON": "json", "CSV": "csv", "Excel": "xlsx"}
                        success, message, file_data = export_handler.export_graph_data(
                            nodes, edges, format_mapping[export_format]
                        )
                        filename = f"knowledge_graph_full.{format_mapping[export_format]}"
                    
                    elif export_type == "åˆ†ææŠ¥å‘Š":
                        # å¯¼å‡ºåˆ†ææŠ¥å‘Š
                        report_data = analytics.generate_summary_report()
                        
                        format_mapping = {"JSON": "json", "CSV": "csv", "Excel": "xlsx"}
                        success, message, file_data = export_handler.export_analysis_report(
                            report_data, format_mapping[export_format]
                        )
                        filename = f"analysis_report.{format_mapping[export_format]}"
                    
                    elif export_type == "å®ä½“è¯¦æƒ…" and selected_entity:
                        # å¯¼å‡ºå®ä½“è¯¦æƒ…
                        format_mapping = {"JSON": "json", "CSV": "csv", "Excel": "xlsx"}
                        success, message, file_data = export_handler.export_entity_details(
                            selected_entity, entity_type, format_mapping[export_format]
                        )
                        filename = f"{selected_entity}_details.{format_mapping[export_format]}"
                    
                    # æ˜¾ç¤ºå¯¼å‡ºç»“æœ
                    if success and file_data:
                        st.success(message)
                        
                        # è®¾ç½®MIMEç±»å‹
                        mime_types = {
                            "json": "application/json",
                            "csv": "text/csv",
                            "xlsx": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        }
                        
                        format_ext = format_mapping[export_format]
                        
                        st.download_button(
                            label=f"ğŸ“¥ ä¸‹è½½ {export_format} æ–‡ä»¶",
                            data=file_data,
                            file_name=filename,
                            mime=mime_types.get(format_ext, "application/octet-stream"),
                            key="download_export_file"
                        )
                    else:
                        st.error(message or "å¯¼å‡ºå¤±è´¥")
                        
                except Exception as e:
                    st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
                    logger.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
        
        # å¯¼å‡ºç»Ÿè®¡ä¿¡æ¯
        st.markdown("---")
        st.subheader("ğŸ“Š å¯¼å‡ºç»Ÿè®¡")
        
        try:
            export_stats = export_handler.get_export_statistics()
            if export_stats:
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("æ´»è·ƒåˆ†äº«é“¾æ¥", export_stats.get('active_shares', 0))
                    st.metric("æ€»è®¿é—®æ¬¡æ•°", export_stats.get('total_accesses', 0))
                with col2:
                    st.write("**æ”¯æŒæ ¼å¼:**")
                    for fmt in export_stats.get('export_formats_supported', []):
                        st.write(f"- {fmt.upper()}")
            else:
                st.info("æš‚æ— å¯¼å‡ºç»Ÿè®¡æ•°æ®")
        except Exception as e:
            st.error(f"è·å–å¯¼å‡ºç»Ÿè®¡å¤±è´¥: {str(e)}")

# æ•°æ®æŸ¥çœ‹é€‰é¡¹å¡
with tab3:
    st.header("ğŸ‘€ æŸ¥çœ‹çŸ¥è¯†å›¾è°±æ•°æ®")
    
    # æ˜¾ç¤ºæ•°æ®åº“çŠ¶æ€
    st.subheader("æ•°æ®åº“çŠ¶æ€")
    
    try:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            company_count = db.get_node_count("company")
            st.metric("å…¬å¸èŠ‚ç‚¹æ•°é‡", f"{company_count:,}")
        
        with col2:
            industry_count = db.get_node_count("industry")
            st.metric("è¡Œä¸šèŠ‚ç‚¹æ•°é‡", f"{industry_count:,}")
        
        with col3:
            product_count = db.get_node_count("product")
            st.metric("äº§å“èŠ‚ç‚¹æ•°é‡", f"{product_count:,}")
        
        # æ˜¾ç¤ºå…³ç³»æ•°é‡
        st.subheader("å…³ç³»ç»Ÿè®¡")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            try:
                company_industry_count = db.get_relationship_count("company", "industry", "æ‰€å±è¡Œä¸š")
                st.metric("å…¬å¸-è¡Œä¸šå…³ç³»", f"{company_industry_count:,}")
            except:
                st.metric("å…¬å¸-è¡Œä¸šå…³ç³»", "N/A")
        
        with col2:
            try:
                company_product_count = db.get_relationship_count("company", "product", "ä¸»è¥äº§å“")
                st.metric("å…¬å¸-äº§å“å…³ç³»", f"{company_product_count:,}")
            except:
                st.metric("å…¬å¸-äº§å“å…³ç³»", "N/A")
        
        with col3:
            try:
                industry_industry_count = db.get_relationship_count("industry", "industry", "ä¸Šçº§è¡Œä¸š")
                st.metric("è¡Œä¸š-è¡Œä¸šå…³ç³»", f"{industry_industry_count:,}")
            except:
                st.metric("è¡Œä¸š-è¡Œä¸šå…³ç³»", "N/A")
        
        # æ•°æ®æ ·æœ¬é¢„è§ˆ
        st.subheader("æ•°æ®æ ·æœ¬é¢„è§ˆ")
        
        preview_type = st.selectbox(
            "é€‰æ‹©é¢„è§ˆç±»å‹",
            ["company", "industry", "product"],
            format_func=lambda x: {"company": "å…¬å¸", "industry": "è¡Œä¸š", "product": "äº§å“"}.get(x, x)
        )
        
        try:
            preview_query = f"""
            MATCH (n:{preview_type})
            RETURN n.name as name, n.description as description
            ORDER BY n.name
            LIMIT 10
            """
            
            preview_results = db.query(preview_query)
            
            if preview_results:
                df = pd.DataFrame(preview_results)
                df.columns = ["åç§°", "æè¿°"]
                st.dataframe(df, use_container_width=True)
            else:
                st.info(f"æš‚æ— {preview_type}æ•°æ®")
                
        except Exception as e:
            st.error(f"è·å–æ•°æ®é¢„è§ˆå¤±è´¥: {str(e)}")
        
    except Exception as e:
        st.error(f"è·å–æ•°æ®åº“çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
        logger.error(f"è·å–æ•°æ®åº“çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")

# ç¤ºä¾‹æ•°æ®é€‰é¡¹å¡
with tab4:
    st.header("ğŸš€ å¯¼å…¥ç¤ºä¾‹æ•°æ®")
    
    st.info("ğŸ’¡ å¦‚æœæ‚¨æ˜¯é¦–æ¬¡ä½¿ç”¨ï¼Œå»ºè®®å¯¼å…¥ç¤ºä¾‹æ•°æ®æ¥ä½“éªŒç³»ç»ŸåŠŸèƒ½")
    
    if st.button("ğŸ“¥ å¯¼å…¥ç¤ºä¾‹æ•°æ®", help="å¯¼å…¥åŒ…æ‹¬é˜¿é‡Œå·´å·´ã€åä¸ºç­‰å…¬å¸çš„ç¤ºä¾‹æ•°æ®", key="import_sample_button"):
        with st.spinner("æ­£åœ¨å¯¼å…¥ç¤ºä¾‹æ•°æ®..."):
            try:
                # å®šä¹‰ç¤ºä¾‹æ•°æ®
                company_data = [
                    {"name": "é˜¿é‡Œå·´å·´", "description": "ä¸­å›½é¢†å…ˆçš„ç”µå­å•†åŠ¡å…¬å¸"},
                    {"name": "è…¾è®¯", "description": "ä¸­å›½é¢†å…ˆçš„äº’è”ç½‘æœåŠ¡æä¾›å•†"},
                    {"name": "ç™¾åº¦", "description": "ä¸­å›½é¢†å…ˆçš„æœç´¢å¼•æ“å…¬å¸"},
                    {"name": "åä¸º", "description": "å…¨çƒé¢†å…ˆçš„é€šä¿¡è®¾å¤‡åˆ¶é€ å•†"},
                    {"name": "å°ç±³", "description": "ä¸­å›½é¢†å…ˆçš„æ™ºèƒ½æ‰‹æœºåˆ¶é€ å•†"}
                ]
                industry_data = [
                    {"name": "äº’è”ç½‘", "description": "äº’è”ç½‘è¡Œä¸š"},
                    {"name": "ç”µå­å•†åŠ¡", "description": "ç”µå­å•†åŠ¡è¡Œä¸š"},
                    {"name": "äººå·¥æ™ºèƒ½", "description": "äººå·¥æ™ºèƒ½è¡Œä¸š"},
                    {"name": "é€šä¿¡", "description": "é€šä¿¡è¡Œä¸š"},
                    {"name": "æ™ºèƒ½ç¡¬ä»¶", "description": "æ™ºèƒ½ç¡¬ä»¶è¡Œä¸š"}
                ]
                product_data = [
                    {"name": "æ·˜å®", "description": "é˜¿é‡Œå·´å·´æ——ä¸‹ç”µå­å•†åŠ¡å¹³å°"},
                    {"name": "å¾®ä¿¡", "description": "è…¾è®¯æ——ä¸‹ç¤¾äº¤é€šè®¯è½¯ä»¶"},
                    {"name": "ç™¾åº¦æœç´¢", "description": "ç™¾åº¦æ——ä¸‹æœç´¢å¼•æ“"},
                    {"name": "åä¸ºæ‰‹æœº", "description": "åä¸ºç”Ÿäº§çš„æ™ºèƒ½æ‰‹æœº"},
                    {"name": "å°ç±³æ‰‹æœº", "description": "å°ç±³ç”Ÿäº§çš„æ™ºèƒ½æ‰‹æœº"}
                ]
                
                # æ¸…é™¤ç°æœ‰æ•°æ®
                db.query("MATCH (n) DETACH DELETE n")
                
                # å¯¼å…¥å…¬å¸èŠ‚ç‚¹
                for company in company_data:
                    db.query(
                        "CREATE (c:company {name: $name, description: $description})",
                        {"name": company["name"], "description": company["description"]}
                    )
                
                # å¯¼å…¥è¡Œä¸šèŠ‚ç‚¹
                for industry in industry_data:
                    db.query(
                        "CREATE (i:industry {name: $name, description: $description})",
                        {"name": industry["name"], "description": industry["description"]}
                    )
                
                # å¯¼å…¥äº§å“èŠ‚ç‚¹
                for product in product_data:
                    db.query(
                        "CREATE (p:product {name: $name, description: $description})",
                        {"name": product["name"], "description": product["description"]}
                    )
                
                # åˆ›å»ºå…¬å¸-è¡Œä¸šå…³ç³»
                relationships = [
                    ("é˜¿é‡Œå·´å·´", "äº’è”ç½‘"), ("é˜¿é‡Œå·´å·´", "ç”µå­å•†åŠ¡"),
                    ("è…¾è®¯", "äº’è”ç½‘"), ("ç™¾åº¦", "äº’è”ç½‘"),
                    ("ç™¾åº¦", "äººå·¥æ™ºèƒ½"), ("åä¸º", "é€šä¿¡"),
                    ("åä¸º", "æ™ºèƒ½ç¡¬ä»¶"), ("å°ç±³", "æ™ºèƒ½ç¡¬ä»¶")
                ]
                
                for rel in relationships:
                    db.query(
                        "MATCH (c:company {name: $company}), (i:industry {name: $industry}) "
                        "CREATE (c)-[:æ‰€å±è¡Œä¸š]->(i)",
                        {"company": rel[0], "industry": rel[1]}
                    )
                
                # åˆ›å»ºå…¬å¸-äº§å“å…³ç³»
                product_rels = [
                    ("é˜¿é‡Œå·´å·´", "æ·˜å®"), ("è…¾è®¯", "å¾®ä¿¡"),
                    ("ç™¾åº¦", "ç™¾åº¦æœç´¢"), ("åä¸º", "åä¸ºæ‰‹æœº"),
                    ("å°ç±³", "å°ç±³æ‰‹æœº")
                ]
                
                for rel in product_rels:
                    db.query(
                        "MATCH (c:company {name: $company}), (p:product {name: $product}) "
                        "CREATE (c)-[:ä¸»è¥äº§å“]->(p)",
                        {"company": rel[0], "product": rel[1]}
                    )
                
                # åˆ›å»ºäº§å“-äº§å“å…³ç³»ï¼ˆä¸Šæ¸¸ææ–™ï¼‰
                upstream_rels = [
                    ("åä¸ºæ‰‹æœº", "å¾®ä¿¡"), ("å°ç±³æ‰‹æœº", "å¾®ä¿¡")
                ]
                
                for rel in upstream_rels:
                    db.query(
                        "MATCH (p1:product {name: $product1}), (p2:product {name: $product2}) "
                        "CREATE (p1)-[:ä¸Šæ¸¸ææ–™]->(p2)",
                        {"product1": rel[0], "product2": rel[1]}
                    )
                
                # åˆ›å»ºè¡Œä¸š-è¡Œä¸šå…³ç³»
                industry_rels = [
                    ("ç”µå­å•†åŠ¡", "äº’è”ç½‘"), ("äººå·¥æ™ºèƒ½", "äº’è”ç½‘")
                ]
                
                for rel in industry_rels:
                    db.query(
                        "MATCH (i1:industry {name: $industry1}), (i2:industry {name: $industry2}) "
                        "CREATE (i1)-[:ä¸Šçº§è¡Œä¸š]->(i2)",
                        {"industry1": rel[0], "industry2": rel[1]}
                    )
                
                st.success("âœ… ç¤ºä¾‹æ•°æ®å¯¼å…¥æˆåŠŸï¼")
                st.info("ğŸ‰ æ‚¨ç°åœ¨å¯ä»¥ä½¿ç”¨å…¶ä»–åŠŸèƒ½é¡µé¢æ¥æ¢ç´¢è¿™äº›æ•°æ®äº†")
                
                # æ¸…é™¤ç¼“å­˜
                st.cache_data.clear()
                
            except Exception as e:
                st.error(f"å¯¼å…¥ç¤ºä¾‹æ•°æ®å¤±è´¥: {str(e)}")
                logger.error(f"å¯¼å…¥ç¤ºä¾‹æ•°æ®å¤±è´¥: {str(e)}\n{traceback.format_exc()}")
    
    # æ˜¾ç¤ºç¤ºä¾‹æ•°æ®ç»“æ„
    with st.expander("ğŸ“‹ æŸ¥çœ‹ç¤ºä¾‹æ•°æ®ç»“æ„"):
        st.code("""
# å…¬å¸æ•°æ®æ ¼å¼ (JSON)
[
    {"name": "é˜¿é‡Œå·´å·´", "description": "ä¸­å›½é¢†å…ˆçš„ç”µå­å•†åŠ¡å…¬å¸"},
    {"name": "è…¾è®¯", "description": "ä¸­å›½é¢†å…ˆçš„äº’è”ç½‘æœåŠ¡æä¾›å•†"},
    ...
]

# è¡Œä¸šæ•°æ®æ ¼å¼ (JSON)
[
    {"name": "äº’è”ç½‘", "description": "äº’è”ç½‘è¡Œä¸š"},
    {"name": "ç”µå­å•†åŠ¡", "description": "ç”µå­å•†åŠ¡è¡Œä¸š"},
    ...
]

# äº§å“æ•°æ®æ ¼å¼ (JSON)
[
    {"name": "æ·˜å®", "description": "é˜¿é‡Œå·´å·´æ——ä¸‹ç”µå­å•†åŠ¡å¹³å°"},
    {"name": "å¾®ä¿¡", "description": "è…¾è®¯æ——ä¸‹ç¤¾äº¤é€šè®¯è½¯ä»¶"},
    ...
]

# å…¬å¸-è¡Œä¸šå…³ç³»æ•°æ®æ ¼å¼ (JSON)
[
    {"company_name": "é˜¿é‡Œå·´å·´", "industry_name": "äº’è”ç½‘"},
    {"company_name": "é˜¿é‡Œå·´å·´", "industry_name": "ç”µå­å•†åŠ¡"},
    ...
]

# å…¬å¸-äº§å“å…³ç³»æ•°æ®æ ¼å¼ (JSON)
[
    {"company_name": "é˜¿é‡Œå·´å·´", "product_name": "æ·˜å®"},
    {"company_name": "è…¾è®¯", "product_name": "å¾®ä¿¡"},
    ...
]

# è¡Œä¸š-è¡Œä¸šå…³ç³»æ•°æ®æ ¼å¼ (JSON)
[
    {"from_industry": "ç”µå­å•†åŠ¡", "to_industry": "äº’è”ç½‘"},
    {"from_industry": "äººå·¥æ™ºèƒ½", "to_industry": "äº’è”ç½‘"},
    ...
]
        """, language="json")

# é¡µè„š
st.markdown("---")
st.caption(f"çŸ¥è¯†å›¾è°±æ•°æ®ç®¡ç†å·¥å…· | {datetime.now().strftime('%Y-%m-%d')}")

# ä¾§è¾¹æ å¸®åŠ©ä¿¡æ¯
with st.sidebar:
    st.markdown("---")
    st.subheader("ğŸ“– åŠŸèƒ½è¯´æ˜")
    
    with st.expander("æ•°æ®ç®¡ç†åŠŸèƒ½"):
        st.markdown("""
        - **æ•°æ®å¯¼å…¥**: ä¸Šä¼ JSONæ ¼å¼çš„æ•°æ®æ–‡ä»¶
        - **æ•°æ®å¯¼å‡º**: å¯¼å‡ºå›¾è°±æ•°æ®å’Œåˆ†ææŠ¥å‘Š
        - **æ•°æ®æŸ¥çœ‹**: æŸ¥çœ‹æ•°æ®åº“çŠ¶æ€å’Œæ•°æ®æ ·æœ¬
        - **ç¤ºä¾‹æ•°æ®**: å¿«é€Ÿå¯¼å…¥æ¼”ç¤ºæ•°æ®
        """)
    
    with st.expander("æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"):
        st.markdown("""
        **å¯¼å…¥æ ¼å¼:**
        - JSON (æ¨è)
        
        **å¯¼å‡ºæ ¼å¼:**
        - JSON - ç»“æ„åŒ–æ•°æ®
        - CSV - è¡¨æ ¼æ•°æ®
        - Excel - ç”µå­è¡¨æ ¼
        """)