import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import traceback
import json
import io
import os
from datetime import datetime
import time
import pickle
import plotly.express as px
import logging
import sys
from build_graph import MedicalGraph
import streamlit_echarts as st_echarts
from kg_visualization import (
    get_entity_options,
    display_network_graph,
    display_hierarchy_tree,
    display_relationship_matrix,
    display_industry_chain
)
from kg_network_visualization import visualize_network, visualize_matrix
from src.neo4j_handler import Neo4jHandler, Config
from pathlib import Path

# æ£€æµ‹æ“ä½œç³»ç»Ÿ
import platform
is_windows = platform.system() == "Windows"

# ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
os.makedirs("logs", exist_ok=True)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join("logs", "app.log"), mode='a'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger("KG_Dashboard")

logger.info("å¯åŠ¨çŸ¥è¯†å›¾è°±æ•°æ®å¯¼å…¥å¯è§†åŒ–å·¥å…·")

# åŠ è½½é…ç½®æ–‡ä»¶
def load_config():
    try:
        # ä¼˜å…ˆåŠ è½½ä¸“ç”¨é…ç½®
        config_file = None
        if is_windows and os.path.exists('config_windows.json'):
            logger.info("åŠ è½½Windowsä¸“ç”¨é…ç½®æ–‡ä»¶")
            config_file = 'config_windows.json'
        # å¦‚æœæ²¡æœ‰ä¸“ç”¨é…ç½®ï¼ŒåŠ è½½é€šç”¨é…ç½®
        elif os.path.exists('config.json'):
            logger.info("åŠ è½½é€šç”¨é…ç½®æ–‡ä»¶")
            config_file = 'config.json'
        
        if config_file:
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            logger.warning("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return {
                "neo4j": {
                    "uri": "bolt://127.0.0.1:7687",
                    "username": "neo4j",
                    "password": "12345678"
                },
                "app": {
                    "title": "çŸ¥è¯†å›¾è°±æ•°æ®å¯¼å…¥å¯è§†åŒ–å·¥å…·",
                    "batch_size_default": 10000,
                    "batch_size_min": 1000,
                    "batch_size_max": 50000
                }
            }
    except Exception as e:
        logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        st.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return {}

# åŠ è½½é…ç½®
config = load_config()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="çŸ¥è¯†å›¾è°±æ•°æ®å¯¼å…¥å¯è§†åŒ–å·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# è‡ªå®šä¹‰CSSï¼Œä½¿ç•Œé¢æ›´ç´§å‡‘
st.markdown("""
<style>
    /* General container padding */
    .block-container {
        padding-top: 0.1rem; /* Reduced from 0.5rem */
        padding-bottom: 0.1rem; /* Reduced from 0.5rem */
        padding-left: 0.5rem; /* Add some horizontal padding */
        padding-right: 0.5rem; /* Add some horizontal padding */
    }
    /* Tabs styling */
    .stTabs [data-baseweb="tab-list"] {
        gap: 3px; /* Reduced gap */
    }
    .stTabs [data-baseweb="tab"] {
        height: 28px; /* Reduced height */
        white-space: pre-wrap;
        padding: 3px 8px; /* Reduced padding */
        font-size: 0.85rem; /* Slightly smaller font for tabs */
    }
    /* Sidebar width (if used, though collapsed) */
    div[data-testid="stSidebar"] {
        width: 180px !important; /* Slightly reduced */
    }
    /* Slider margins */
    div[role="slider"] {
        margin-top: 0.1rem; /* Reduced from 0.3rem */
        margin-bottom: 0.1rem; /* Reduced from 0.3rem */
    }
    /* Alert/Info/Warning messages */
    .stAlert {
        padding: 3px; /* Reduced from 5px */
        margin-top: 0.1rem; /* Reduced from 0.3rem */
        margin-bottom: 0.1rem; /* Reduced from 0.3rem */
        font-size: 0.85rem; /* Slightly smaller font */
    }
    /* Dataframe margins */
    .stDataFrame {
        margin-top: 0.1rem; /* Reduced from 0.3rem */
        margin-bottom: 0.1rem; /* Reduced from 0.3rem */
    }
    /* Button padding */
    .stButton button {
        width: 100%;
        padding: 1px 6px; /* Reduced from 2px 8px */
        font-size: 0.85rem; /* Slightly smaller font */
    }
    /* Markdown headings and text */
    .stMarkdown {
        margin-top: 0.1rem; /* Reduced from 0.2rem */
        margin-bottom: 0.1rem; /* Reduced from 0.2rem */
    }
    h1, h2, h3, h4, h5, h6 {
        margin-top: 0.1rem; /* Reduced from 0.3rem */
        margin-bottom: 0.1rem; /* Reduced from 0.3rem */
    }
    .stMarkdown h3 {
        font-size: 1.1rem; /* Slightly smaller */
    }
    .stMarkdown h4 {
        font-size: 0.95rem; /* Slightly smaller */
    }
    .stMarkdown h5 {
        font-size: 0.85rem; /* Slightly smaller */
        margin-top: 0.05rem; /* Reduced from 0.1rem */
        margin-bottom: 0.05rem; /* Reduced from 0.1rem */
    }
    .stMarkdown h6 {
        font-size: 0.8rem; /* Slightly smaller */
        margin-top: 0.05rem; /* Reduced from 0.1rem */
        margin-bottom: 0.05rem; /* Reduced from 0.1rem */
    }
    /* Element container margins */
    .element-container {
        margin-top: 0.1rem; /* Reduced from 0.2rem */
        margin-bottom: 0.1rem; /* Reduced from 0.2rem */
    }
    /* Selectbox and TextInput heights/margins */
    .stSelectbox, .stTextInput {
        margin-top: 0.1rem; /* Reduced from 0.2rem */
        margin-bottom: 0.1rem; /* Reduced from 0.2rem */
    }
    div[data-baseweb="select"], div[data-baseweb="input"] {
        min-height: 28px; /* Reduced from 32px */
        font-size: 0.85rem; /* Slightly smaller font */
    }
    /* Notification padding */
    div[data-baseweb="notification"] {
        padding: 0.2rem; /* Reduced from 0.3rem */
    }
    /* Echarts margins */
    .echarts-for-react {
        margin: 0 !important;
        padding: 0 !important;
    }
    /* Expander padding */
    .streamlit-expanderHeader {
        padding-top: 0.1rem; /* Reduced from 0.2rem */
        padding-bottom: 0.1rem; /* Reduced from 0.2rem */
        font-size: 0.85rem; /* Slightly smaller font */
    }
    .streamlit-expanderContent {
        padding-top: 0.1rem; /* Reduced from 0.2rem */
        padding-bottom: 0.1rem; /* Reduced from 0.2rem */
    }
    /* Slider height */
    div[data-testid="stSlider"] {
        padding-top: 0.1rem; /* Reduced from 0.2rem */
        padding-bottom: 0.1rem; /* Reduced from 0.2rem */
    }
    /* Metric component */
    div[data-testid="stMetric"] {
        padding: 0.1rem; /* Reduce padding */
    }
    div[data-testid="stMetricLabel"] {
        font-size: 0.8rem; /* Smaller label */
    }
    div[data-testid="stMetricValue"] {
        font-size: 1.2rem; /* Smaller value */
    }
    div[data-testid="stMetricDelta"] {
        font-size: 0.7rem; /* Smaller delta */
    }
    /* Plotly chart margins */
    .js-plotly-plot .plotly .modebar {
        margin-top: -20px; /* Move modebar up to save space */
    }
</style>
""", unsafe_allow_html=True)

# ç»Ÿä¸€çš„é¡µé¢æ ‡é¢˜
st.markdown("<h4 style='font-size:1.1rem; margin:0; padding:0.2rem 0; text-align: center;'>çŸ¥è¯†å›¾è°±æ•°æ®å¯¼å…¥å¯è§†åŒ–å·¥å…· <span style='font-size:0.8rem; color:#666;'>ç‰ˆæœ¬: 1.0</span></h4>", unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'import_history' not in st.session_state:
    st.session_state.import_history = []

if 'last_refresh' not in st.session_state:
    st.session_state.last_refresh = time.time()

if 'is_importing' not in st.session_state:
    st.session_state.is_importing = False

if 'error_message' not in st.session_state:
    st.session_state.error_message = None

# åˆ›å»ºMedicalGraphå®ä¾‹
@st.cache_resource
def get_graph_handler():
    logger.info("åˆå§‹åŒ–å›¾è°±å¤„ç†å™¨")
    try:
        return MedicalGraph()
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–å›¾è°±å¤„ç†å™¨å¤±è´¥: {e}")
        return None

# å°è¯•è·å–å›¾è°±å¤„ç†å™¨
try:
    logger.info("å°è¯•åˆå§‹åŒ–å›¾è°±å¤„ç†å™¨")
    handler = get_graph_handler()
    logger.info(f"å›¾è°±å¤„ç†å™¨åˆå§‹åŒ–ç»“æœ: {handler is not None}")
except Exception as e:
    logger.error(f"è·å–å›¾è°±å¤„ç†å™¨æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
    handler = None

# ä¸»é¡µé¢
# st.markdown("<h3 style='font-size:1.2rem; margin-bottom:0.2rem;'>çŸ¥è¯†å›¾è°±æ•°æ®å¯¼å…¥å¯è§†åŒ–å·¥å…· <span style='font-size:0.8rem; color:#666;'>ç‰ˆæœ¬: 1.0</span></h3>", unsafe_allow_html=True)

# æ£€æŸ¥å›¾è°±å¤„ç†å™¨æ˜¯å¦æˆåŠŸåˆå§‹åŒ–
if handler is None:
    st.error("å›¾è°±å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥Neo4jè¿æ¥å’Œæ•°æ®æ–‡ä»¶ã€‚")
    st.warning("åº”ç”¨å°†ä»¥æœ‰é™åŠŸèƒ½æ¨¡å¼è¿è¡Œï¼Œè¯·ç¡®ä¿Neo4jæœåŠ¡å·²å¯åŠ¨ååˆ·æ–°é¡µé¢ã€‚")
    
    # æ˜¾ç¤ºNeo4jè¿æ¥è®¾ç½®
    st.subheader("Neo4jè¿æ¥è®¾ç½®")
    if os.path.exists('config_windows.json'):
        try:
            with open('config_windows.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                neo4j_config = config.get('neo4j', {})
                st.write(f"è¿æ¥URI: {neo4j_config.get('uri', 'bolt://127.0.0.1:7687')}")
                st.write(f"ç”¨æˆ·å: {neo4j_config.get('username', 'neo4j')}")
                st.write("å¯†ç : ********")
        except Exception as e:
            st.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    else:
        st.warning("æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ config_windows.json")
    
    # æä¾›Neo4jå¯åŠ¨æŒ‡å—
    with st.expander("Neo4jå¯åŠ¨æŒ‡å—", expanded=True):
        st.markdown("""
        ### å¯åŠ¨Neo4jæ•°æ®åº“çš„æ­¥éª¤
        
        1. **é€šè¿‡Neo4j Desktopå¯åŠ¨**:
           - æ‰“å¼€Neo4j Desktopåº”ç”¨
           - é€‰æ‹©æ‚¨çš„æ•°æ®åº“ï¼Œç‚¹å‡»"Start"æŒ‰é’®
           
        2. **é€šè¿‡WindowsæœåŠ¡å¯åŠ¨**:
           - æŒ‰Win+Ræ‰“å¼€è¿è¡Œå¯¹è¯æ¡†
           - è¾“å…¥`services.msc`å¹¶æŒ‰å›è½¦
           - æ‰¾åˆ°Neo4jæœåŠ¡ï¼Œå³é”®é€‰æ‹©"å¯åŠ¨"
           
        3. **é€šè¿‡å‘½ä»¤è¡Œå¯åŠ¨**:
           - æ‰“å¼€å‘½ä»¤æç¤ºç¬¦æˆ–PowerShell
           - å¯¼èˆªåˆ°Neo4jå®‰è£…ç›®å½•çš„binæ–‡ä»¶å¤¹
           - æ‰§è¡Œ`neo4j.bat console`å‘½ä»¤
        
        å¯åŠ¨Neo4jåï¼Œè¯·åˆ·æ–°æ­¤é¡µé¢ã€‚
        """)
    
    # åˆ·æ–°æŒ‰é’®
    if st.button("åˆ·æ–°é¡µé¢", key="refresh_page"):
        st.experimental_rerun()
    
    # ä¸å®Œå…¨åœæ­¢åº”ç”¨ï¼Œåªæ˜¯ä¸æ‰§è¡Œå¯¼å…¥ç›¸å…³åŠŸèƒ½
    st.info("åº”ç”¨ä»¥æœ‰é™åŠŸèƒ½æ¨¡å¼è¿è¡Œä¸­ï¼Œæ— æ³•æ‰§è¡Œæ•°æ®å¯¼å…¥æ“ä½œã€‚")
    st.stop()

# ç®€åŒ–ç‰ˆæœ¬çš„å¯¼å…¥çŠ¶æ€è·å–å‡½æ•°
def get_simple_import_status():
    try:
        # ä»handlerè·å–å¯¼å…¥çŠ¶æ€
        import_state = handler.import_state
        
        # æå–åŸºæœ¬ä¿¡æ¯
        node_types = ['company', 'industry', 'product']
        rel_types = ['company_industry', 'industry_industry', 'company_product', 'product_product']
        
        # èŠ‚ç‚¹çŠ¶æ€
        node_data = []
        total_nodes = 0
        imported_nodes = 0
        
        for node_type in node_types:
            if node_type in import_state:
                imported = import_state[node_type]
                imported_nodes += imported
                node_data.append({
                    "ç±»å‹": node_type,
                    "å·²å¯¼å…¥æ•°é‡": imported
                })
        
        # å…³ç³»çŠ¶æ€
        rel_data = []
        total_rels = 0
        imported_rels = 0
        
        for rel_type in rel_types:
            if rel_type in import_state:
                imported = import_state[rel_type]
                imported_rels += imported
                rel_data.append({
                    "ç±»å‹": rel_type,
                    "å·²å¯¼å…¥æ•°é‡": imported
                })
        
        return {
            "node_data": node_data,
            "rel_data": rel_data,
            "imported_nodes": imported_nodes,
            "imported_rels": imported_rels,
            "total_imported": imported_nodes + imported_rels
        }
    except Exception as e:
        logger.error(f"è·å–å¯¼å…¥çŠ¶æ€å¤±è´¥: {e}")
        st.session_state.error_message = f"è·å–å¯¼å…¥çŠ¶æ€å¤±è´¥: {str(e)}"
        return None

# ç®€åŒ–ç‰ˆæœ¬çš„å¯¼å…¥å‡½æ•°
def run_simple_import(batch_size):
    try:
        logger.info(f"å¼€å§‹å¯¼å…¥ä»»åŠ¡ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")
        st.session_state.is_importing = True
        st.session_state.error_message = None
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # åˆ›å»ºStreamlitè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
        def update_progress(current, total, message):
            if total > 0:
                progress = min(current / total, 1.0)
                progress_bar.progress(progress)
                status_text.text(f"{message}: {current}/{total} ({int(progress * 100)}%)")
        
        # è¿è¡Œå¯¼å…¥ - ä¿®å¤: ç¡®ä¿å…¼å®¹æ–¹æ³•è¢«æ­£ç¡®è°ƒç”¨
        logger.info("å¼€å§‹å¯¼å…¥èŠ‚ç‚¹...")
        status_text.text("æ­£åœ¨å¯¼å…¥èŠ‚ç‚¹...")
        node_count = handler.create_graphnodes(batch_size)
        logger.info(f"èŠ‚ç‚¹å¯¼å…¥å®Œæˆï¼Œæ•°é‡: {node_count}")
        
        # æ›´æ–°è¿›åº¦æ¡
        progress_bar.progress(0.5)
        status_text.text(f"èŠ‚ç‚¹å¯¼å…¥å®Œæˆï¼Œæ•°é‡: {node_count}ï¼Œæ­£åœ¨å¯¼å…¥å…³ç³»...")
        
        logger.info("å¼€å§‹å¯¼å…¥å…³ç³»...")
        rel_count = handler.create_graphrels(batch_size)
        logger.info(f"å…³ç³»å¯¼å…¥å®Œæˆï¼Œæ•°é‡: {rel_count}")
        
        # å®Œæˆè¿›åº¦æ¡
        progress_bar.progress(1.0)
        status_text.text(f"å¯¼å…¥å®Œæˆ! å…±å¯¼å…¥ {node_count} ä¸ªèŠ‚ç‚¹å’Œ {rel_count} æ¡å…³ç³»")
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        duration = end_time - start_time
        
        # æ·»åŠ åˆ°å†å²è®°å½•
        status = get_simple_import_status()
        if status:
            st.session_state.import_history.append({
                "æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "æ‰¹æ¬¡å¤§å°": batch_size,
                "å¯¼å…¥èŠ‚ç‚¹æ•°": node_count,
                "å¯¼å…¥å…³ç³»æ•°": rel_count,
                "è€—æ—¶(ç§’)": round(duration, 2)
            })
        
        # éªŒè¯å¯¼å…¥ç»“æœ - æ–°å¢éƒ¨åˆ†
        import_results = verify_import_results()
        st.session_state.last_import_results = import_results
        
        logger.info(f"å¯¼å…¥ä»»åŠ¡å®Œæˆï¼Œè€—æ—¶: {round(duration, 2)}ç§’")
        st.session_state.is_importing = False
        return True
    except Exception as e:
        error_msg = f"å¯¼å…¥ä»»åŠ¡å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        logger.error(error_msg)
        st.session_state.error_message = error_msg
        st.session_state.is_importing = False
        return False

# æ–°å¢: éªŒè¯å¯¼å…¥ç»“æœçš„å‡½æ•°
def verify_import_results():
    """éªŒè¯æ•°æ®å¯¼å…¥ç»“æœï¼Œè¿”å›å¯¼å…¥çš„æ–‡ä»¶å’ŒèŠ‚ç‚¹ä¿¡æ¯"""
    try:
        results = {
            "files": [],
            "node_counts": {},
            "sample_nodes": {},
            "total_nodes": 0,
            "total_rels": 0,
            "verification_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # è·å–å¯¼å…¥çš„æ–‡ä»¶åˆ—è¡¨
        if handler:
            data_files = {
                "company": handler.company_path,
                "industry": handler.industry_path,
                "product": handler.product_path,
                "company_industry": handler.company_industry_path,
                "industry_industry": handler.industry_industry,
                "company_product": handler.company_product_path,
                "product_product": handler.product_product
            }
            
            for file_type, file_path in data_files.items():
                if os.path.exists(file_path):
                    file_size = os.path.getsize(file_path) / 1024  # KB
                    results["files"].append({
                        "type": file_type,
                        "path": file_path,
                        "size": f"{file_size:.2f} KB"
                    })
        
        # è·å–å„ç±»å‹èŠ‚ç‚¹æ•°é‡å’Œç¤ºä¾‹
        node_types = ["company", "industry", "product"]
        for node_type in node_types:
            # è·å–èŠ‚ç‚¹æ•°é‡
            count_query = f"MATCH (n:{node_type}) RETURN count(n) as count"
            count_result = handler.g.run(count_query).data()
            node_count = count_result[0]["count"] if count_result else 0
            results["node_counts"][node_type] = node_count
            results["total_nodes"] += node_count
            
            # è·å–å‰50ä¸ªèŠ‚ç‚¹ç¤ºä¾‹
            sample_query = f"MATCH (n:{node_type}) RETURN n.name as name LIMIT 50"
            sample_results = handler.g.run(sample_query).data()
            results["sample_nodes"][node_type] = [node["name"] for node in sample_results]
        
        # è·å–å„ç±»å‹å…³ç³»æ•°é‡
        rel_types = ["å±äº", "æ‹¥æœ‰", "ä¸Šçº§è¡Œä¸š", "ä¸Šæ¸¸ææ–™", "ä¸»è¥äº§å“"]
        rel_count = 0
        for rel_type in rel_types:
            count_query = f"MATCH ()-[r:{rel_type}]->() RETURN count(r) as count"
            try:
                count_result = handler.g.run(count_query).data()
                if count_result:
                    rel_count += count_result[0]["count"]
            except:
                # å…³ç³»ç±»å‹å¯èƒ½ä¸å­˜åœ¨
                pass
        
        results["total_rels"] = rel_count
        
        return results
    except Exception as e:
        logger.error(f"éªŒè¯å¯¼å…¥ç»“æœæ—¶å‡ºé”™: {e}")
        return {"error": str(e)}

# æ–°å¢: æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ•°æ®éœ€è¦å¯¼å…¥
def check_remaining_data():
    """æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ•°æ®éœ€è¦å¯¼å…¥ï¼Œè¿”å›å‰©ä½™æ•°æ®æ•°é‡å’Œè¯¦ç»†ä¿¡æ¯"""
    try:
        # èŠ‚ç‚¹æ•°æ®
        node_files = {
            'company': handler.company_path,
            'industry': handler.industry_path,
            'product': handler.product_path
        }
        
        # å…³ç³»æ•°æ®
        rel_files = {
            'company_industry': handler.company_industry_path,
            'industry_industry': handler.industry_industry,
            'company_product': handler.company_product_path,
            'product_product': handler.product_product
        }
        
        remaining_data = {
            "nodes": {},
            "relationships": {},
            "total_remaining": 0,
            "verification_details": {}
        }
        
        # æ£€æŸ¥èŠ‚ç‚¹æ•°æ®
        for node_type, file_path in node_files.items():
            if os.path.exists(file_path):
                try:
                    # è·å–æ–‡ä»¶æ€»è¡Œæ•°
                    total_lines = handler._count_file_lines(file_path)
                    # è·å–å·²å¯¼å…¥è¡Œæ•°
                    imported = handler.import_state.get(node_type, 0)
                    # è®¡ç®—å‰©ä½™è¡Œæ•°
                    remaining = max(0, total_lines - imported)
                    
                    # æ·»åŠ éªŒè¯æ­¥éª¤ï¼šæ£€æŸ¥æ•°æ®åº“ä¸­å®é™…èŠ‚ç‚¹æ•°é‡
                    query = f"MATCH (n:{node_type}) RETURN count(n) as count"
                    result = handler.g.run(query).data()
                    actual_count = result[0]["count"] if result else 0
                    
                    # å¦‚æœå®é™…èŠ‚ç‚¹æ•°é‡ä¸å¯¼å…¥çŠ¶æ€ä¸ä¸€è‡´ï¼Œè°ƒæ•´å‰©ä½™æ•°é‡
                    if actual_count > imported:
                        logger.warning(f"{node_type}èŠ‚ç‚¹å¯¼å…¥çŠ¶æ€ä¸ä¸€è‡´ï¼šå¯¼å…¥çŠ¶æ€è®°å½•{imported}ä¸ªï¼Œå®é™…æ•°æ®åº“ä¸­æœ‰{actual_count}ä¸ª")
                        # æ›´æ–°å¯¼å…¥çŠ¶æ€ä»¥åŒ¹é…å®é™…æ•°æ®åº“çŠ¶æ€
                        handler.import_state[node_type] = actual_count
                        remaining = max(0, total_lines - actual_count)
                    
                    # è®°å½•éªŒè¯è¯¦æƒ…
                    remaining_data["verification_details"][node_type] = {
                        "total_lines": total_lines,
                        "imported_state": imported,
                        "actual_count": actual_count,
                        "remaining": remaining
                    }
                    
                    if remaining > 0:
                        remaining_data["nodes"][node_type] = remaining
                        remaining_data["total_remaining"] += remaining
                except Exception as e:
                    logger.error(f"æ£€æŸ¥{node_type}èŠ‚ç‚¹æ•°æ®æ—¶å‡ºé”™: {e}")
        
        # æ£€æŸ¥å…³ç³»æ•°æ®
        for rel_type, file_path in rel_files.items():
            if os.path.exists(file_path):
                try:
                    # è·å–æ–‡ä»¶æ€»è¡Œæ•°
                    total_lines = handler._count_file_lines(file_path)
                    # è·å–å·²å¯¼å…¥è¡Œæ•°
                    imported = handler.import_state.get(rel_type, 0)
                    # è®¡ç®—å‰©ä½™è¡Œæ•°
                    remaining = max(0, total_lines - imported)
                    
                    # æ·»åŠ éªŒè¯æ­¥éª¤ï¼šå°è¯•æ£€æŸ¥æ•°æ®åº“ä¸­å®é™…å…³ç³»æ•°é‡
                    # ç”±äºå…³ç³»ç±»å‹å¯èƒ½æœ‰å¤šç§ï¼Œè¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€åŒ–çš„æ–¹æ³•
                    actual_count = 0
                    if rel_type == 'company_industry':
                        query = "MATCH ()-[r:å±äº|éš¶å±|æ‰€å±|BELONGS_TO]->() RETURN count(r) as count"
                        result = handler.g.run(query).data()
                        actual_count = result[0]["count"] if result else 0
                    elif rel_type == 'industry_industry':
                        query = "MATCH (:industry)-[r]->(:industry) RETURN count(r) as count"
                        result = handler.g.run(query).data()
                        actual_count = result[0]["count"] if result else 0
                    elif rel_type == 'company_product':
                        query = "MATCH (:company)-[r:æ‹¥æœ‰|ç”Ÿäº§|ä¸»è¥|OWNS|PRODUCES]->(:product) RETURN count(r) as count"
                        result = handler.g.run(query).data()
                        actual_count = result[0]["count"] if result else 0
                    elif rel_type == 'product_product':
                        query = "MATCH (:product)-[r]->(:product) RETURN count(r) as count"
                        result = handler.g.run(query).data()
                        actual_count = result[0]["count"] if result else 0
                    
                    # å¦‚æœå®é™…å…³ç³»æ•°é‡ä¸å¯¼å…¥çŠ¶æ€ä¸ä¸€è‡´ï¼Œè°ƒæ•´å‰©ä½™æ•°é‡
                    if actual_count > imported:
                        logger.warning(f"{rel_type}å…³ç³»å¯¼å…¥çŠ¶æ€ä¸ä¸€è‡´ï¼šå¯¼å…¥çŠ¶æ€è®°å½•{imported}æ¡ï¼Œå®é™…æ•°æ®åº“ä¸­æœ‰{actual_count}æ¡")
                        # æ›´æ–°å¯¼å…¥çŠ¶æ€ä»¥åŒ¹é…å®é™…æ•°æ®åº“çŠ¶æ€
                        handler.import_state[rel_type] = actual_count
                        remaining = max(0, total_lines - actual_count)
                    
                    # è®°å½•éªŒè¯è¯¦æƒ…
                    remaining_data["verification_details"][rel_type] = {
                        "total_lines": total_lines,
                        "imported_state": imported,
                        "actual_count": actual_count,
                        "remaining": remaining
                    }
                    
                    if remaining > 0:
                        remaining_data["relationships"][rel_type] = remaining
                        remaining_data["total_remaining"] += remaining
                except Exception as e:
                    logger.error(f"æ£€æŸ¥{rel_type}å…³ç³»æ•°æ®æ—¶å‡ºé”™: {e}")
        
        # ä¿å­˜æ›´æ–°åçš„å¯¼å…¥çŠ¶æ€
        handler.save_import_state()
        
        return remaining_data
    except Exception as e:
        logger.error(f"æ£€æŸ¥å‰©ä½™æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        return {"error": str(e), "total_remaining": 0}

# åˆ›å»ºé€‰é¡¹å¡
tab1, tab2, tab3, tab4, tab5 = st.tabs(["å¯¼å…¥çŠ¶æ€", "æ“ä½œæ§åˆ¶", "å›¾è°±æ¢ç´¢", "å›¾è°±å¯è§†åŒ–", "è¡Œä¸šé“¾åˆ†æ"])

with tab1:
    status = get_simple_import_status()
    
    if status:
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>å¯¼å…¥æ‘˜è¦</h5>", unsafe_allow_html=True)
        metrics_cols = st.columns(3)
        with metrics_cols[0]:
            st.metric("å·²å¯¼å…¥èŠ‚ç‚¹æ€»æ•°", f"{status['imported_nodes']:,}")
        with metrics_cols[1]:
            st.metric("å·²å¯¼å…¥å…³ç³»æ€»æ•°", f"{status['imported_rels']:,}")
        with metrics_cols[2]:
            st.metric("æ€»å¯¼å…¥æ•°æ®é‡", f"{status['total_imported']:,}")
        
        main_col1, main_col2 = st.columns([1, 1]) # New main columns for tables and charts
        
        with main_col1:
            st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>èŠ‚ç‚¹å¯¼å…¥è¯¦æƒ…</h6>", unsafe_allow_html=True)
            if status["node_data"]:
                st.dataframe(pd.DataFrame(status["node_data"]), height=130, use_container_width=True)
            else:
                st.info("æš‚æ— èŠ‚ç‚¹å¯¼å…¥æ•°æ®")
            
            st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>å…³ç³»å¯¼å…¥è¯¦æƒ…</h6>", unsafe_allow_html=True)
            if status["rel_data"]:
                st.dataframe(pd.DataFrame(status["rel_data"]), height=130, use_container_width=True)
            else:
                st.info("æš‚æ— å…³ç³»å¯¼å…¥æ•°æ®")
        
        with main_col2:
            if status and (status["node_data"] or status["rel_data"]):
                chart_tabs = st.tabs(["èŠ‚ç‚¹ç»Ÿè®¡", "å…³ç³»ç»Ÿè®¡"])
                
                with chart_tabs[0]:
                    if status["node_data"]:
                        df = pd.DataFrame(status["node_data"])
                        fig = px.bar(
                            df,
                            x="ç±»å‹",
                            y="å·²å¯¼å…¥æ•°é‡",
                            title="å„ç±»å‹èŠ‚ç‚¹å¯¼å…¥æ•°é‡",
                            height=320,  # Adjusted height to fill space
                            text_auto=True
                        )
                        fig.update_layout(margin=dict(l=0, r=0, t=30, b=0))
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("æš‚æ— èŠ‚ç‚¹æ•°æ®å¯ä¾›å¯è§†åŒ–")
                    
                with chart_tabs[1]:
                    if status["rel_data"]:
                        df = pd.DataFrame(status["rel_data"])
                        fig = px.bar(
                            df,
                            x="ç±»å‹",
                            y="å·²å¯¼å…¥æ•°é‡",
                            title="å„ç±»å‹å…³ç³»å¯¼å…¥æ•°é‡",
                            height=320,  # Adjusted height to fill space
                            text_auto=True
                        )
                        fig.update_layout(margin=dict(l=0, r=0, t=30, b=0))
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("æš‚æ— å…³ç³»æ•°æ®å¯ä¾›å¯è§†åŒ–")
    else:
        st.info("æš‚æ— å¯¼å…¥çŠ¶æ€æ•°æ®ã€‚è¯·å°è¯•å¯¼å…¥æ•°æ®ã€‚")

with tab2:
    # ä½¿ç”¨ä¸¤åˆ—å¸ƒå±€
    col_controls, col_history = st.columns([1, 1])
    
    with col_controls:
        # ä¸€ä¸ªæ›´ç´§å‡‘çš„æ§åˆ¶é¢æ¿
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>æ“ä½œæ§åˆ¶</h5>", unsafe_allow_html=True)
        
        # æ‰¹æ¬¡å¤§å°è®¾ç½®ï¼Œä½¿ç”¨æ›´å°çš„é—´è·
        batch_size = st.slider(
            "æ‰¹æ¬¡å¤§å°", 
            min_value=config["app"].get("batch_size_min", 1000),
            max_value=config["app"].get("batch_size_max", 50000),
            value=config["app"].get("batch_size_default", 10000),
            step=1000
        )
        
        # å¹¶æ’æ”¾ç½®æŒ‰é’®
        col_start, col_refresh = st.columns(2)
        
        with col_start:
            # æ·»åŠ æ›´è¯¦ç»†çš„æç¤º
            import_help = "å¯¼å…¥æŒ‡å®šæ‰¹æ¬¡å¤§å°çš„èŠ‚ç‚¹å’Œå…³ç³»æ•°æ®åˆ°Neo4jæ•°æ®åº“"
            if st.button("å¼€å§‹å¯¼å…¥", disabled=st.session_state.is_importing, key="start_btn", use_container_width=True, help=import_help):
                with st.spinner('æ­£åœ¨å¯¼å…¥æ•°æ®ï¼Œè¯·ç¨å€™...'):
                    try:
                        # é¦–å…ˆæ£€æŸ¥Neo4jè¿æ¥æ˜¯å¦æˆåŠŸåˆå§‹åŒ–
                        if handler.g is None:
                            error_msg = "Neo4jè¿æ¥æœªæˆåŠŸåˆå§‹åŒ–ï¼Œè¯·ç¡®ä¿Neo4jæ•°æ®åº“å·²å¯åŠ¨"
                            logger.error(error_msg)
                            st.session_state.error_message = error_msg
                            st.error(error_msg)
                        # å¦‚æœè¿æ¥æˆåŠŸï¼Œå†æ£€æŸ¥è¿æ¥æ˜¯å¦æœ‰æ•ˆ
                        elif handler.g:
                            try:
                                # å°è¯•æ‰§è¡Œä¸€ä¸ªç®€å•çš„CypheræŸ¥è¯¢æ¥éªŒè¯è¿æ¥
                                handler.g.run("RETURN 1 AS test").data()
                                logger.info("Neo4jæ•°æ®åº“è¿æ¥æ­£å¸¸ï¼Œå¼€å§‹å¯¼å…¥æµç¨‹")
                                
                                # æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®éœ€è¦å¯¼å…¥
                                remaining_data = check_remaining_data()
                                if remaining_data.get("total_remaining", 0) == 0:
                                    st.info("æ‰€æœ‰æ•°æ®å·²å¯¼å…¥å®Œæˆï¼Œæ— éœ€å†æ¬¡å¯¼å…¥")
                                    
                                    # æ˜¾ç¤ºå½“å‰æ•°æ®åº“çŠ¶æ€æ‘˜è¦
                                    import_results = verify_import_results()
                                    if "error" not in import_results:
                                        st.success(f"æ•°æ®åº“ä¸­å·²æœ‰ {import_results['total_nodes']} ä¸ªèŠ‚ç‚¹å’Œ {import_results['total_rels']} æ¡å…³ç³»")
                                    
                                    # æä¾›å¯¼å…¥ç¤ºä¾‹æ•°æ®çš„å»ºè®®
                                    if import_results.get('total_nodes', 0) == 0:
                                        st.info("æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ã€‚æ‚¨å¯ä»¥åœ¨'å›¾è°±æ¢ç´¢'æ ‡ç­¾é¡µä¸­ç‚¹å‡»'å¯¼å…¥ç¤ºä¾‹æ•°æ®'æŒ‰é’®æ·»åŠ ä¸€äº›ç¤ºä¾‹æ•°æ®è¿›è¡Œæµ‹è¯•ã€‚")
                                else:
                                    # æ˜¾ç¤ºå‰©ä½™æ•°æ®ä¿¡æ¯
                                    st.info(f"å‘ç° {remaining_data['total_remaining']} æ¡æ•°æ®å¾…å¯¼å…¥")
                                    
                                    # å¦‚æœæœ‰æ•°æ®éœ€è¦å¯¼å…¥ï¼Œåˆ™æ‰§è¡Œå¯¼å…¥
                                    success = run_simple_import(batch_size)
                                    if success:
                                        st.success(f"æˆåŠŸå¯¼å…¥ä¸€æ‰¹æ•°æ®ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")
                                    else:
                                        st.error("å¯¼å…¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æŸ¥çœ‹ä¸‹æ–¹é”™è¯¯ä¿¡æ¯")
                            except Exception as e:
                                error_msg = f"Neo4jæ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}"
                                logger.error(error_msg)
                                st.session_state.error_message = error_msg
                                st.error(error_msg)
                        else:
                            error_msg = "æ— æ³•è¿æ¥åˆ°Neo4jæ•°æ®åº“ï¼Œè¯·ç¡®ä¿æ•°æ®åº“å·²å¯åŠ¨"
                            logger.error(error_msg)
                            st.session_state.error_message = error_msg
                            st.error(error_msg)
                    except Exception as e:
                        error_msg = f"å¯¼å…¥å‰æ£€æŸ¥å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
                        logger.error(error_msg)
                        st.session_state.error_message = error_msg
                        st.error("å¯¼å…¥å‰æ£€æŸ¥å¤±è´¥ï¼Œè¯·æŸ¥çœ‹é”™è¯¯è¯¦æƒ…")
        
        with col_refresh:
            refresh_help = "åˆ·æ–°é¡µé¢æ˜¾ç¤ºæœ€æ–°çš„å¯¼å…¥çŠ¶æ€"
            if st.button("åˆ·æ–°çŠ¶æ€", key="refresh_btn", use_container_width=True, help=refresh_help):
                st.session_state.last_refresh = time.time()
                st.experimental_rerun()
        
        # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        if st.session_state.error_message:
            with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…", expanded=False):  # é»˜è®¤æŠ˜å é”™è¯¯ä¿¡æ¯
                st.error(st.session_state.error_message)
                if st.button("æ¸…é™¤é”™è¯¯ä¿¡æ¯"):
                    st.session_state.error_message = None
                    st.experimental_rerun()
        
        # é«˜çº§é€‰é¡¹ä½œä¸ºæŠ˜å é¢æ¿
        with st.expander("é«˜çº§é€‰é¡¹", expanded=False):
            st.warning("è­¦å‘Šï¼šé‡ç½®å¯¼å…¥çŠ¶æ€å°†æ¸…é™¤æ‰€æœ‰å¯¼å…¥è¿›åº¦ï¼Œæ— æ³•æ¢å¤ï¼")
            if st.button("é‡ç½®å¯¼å…¥çŠ¶æ€", key="reset_btn"):
                confirm = st.text_input("è¾“å…¥'ç¡®è®¤'ä»¥é‡ç½®æ‰€æœ‰å¯¼å…¥çŠ¶æ€ï¼ˆè¿™å°†æ¸…é™¤æ‰€æœ‰å¯¼å…¥è¿›åº¦ï¼‰:")
                if confirm == "ç¡®è®¤":
                    try:
                        handler.reset_import_state()
                        st.success("å¯¼å…¥çŠ¶æ€å·²é‡ç½®")
                        st.session_state.import_history = []
                        st.experimental_rerun()
                    except Exception as e:
                        st.error(f"é‡ç½®å¯¼å…¥çŠ¶æ€å¤±è´¥: {e}")
            
            # æ–°å¢ï¼šæ•°æ®åº“å®Œå…¨é‡ç½®åŠŸèƒ½
            st.error("å±é™©æ“ä½œï¼šé‡ç½®Neo4jæ•°æ®åº“å°†åˆ é™¤æ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»ï¼")
            if st.button("é‡ç½®Neo4jæ•°æ®åº“", key="reset_db_btn"):
                confirm_db = st.text_input("è¾“å…¥'æˆ‘ç¡®è®¤åˆ é™¤æ‰€æœ‰æ•°æ®'ä»¥é‡ç½®Neo4jæ•°æ®åº“ï¼ˆæ­¤æ“ä½œå°†åˆ é™¤æ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»ï¼Œæ— æ³•æ¢å¤ï¼‰:")
                if confirm_db == "æˆ‘ç¡®è®¤åˆ é™¤æ‰€æœ‰æ•°æ®":
                    try:
                        # æ‰§è¡Œæ¸…ç©ºæ•°æ®åº“çš„CypheræŸ¥è¯¢
                        handler.g.run("MATCH (n) DETACH DELETE n")
                        # é‡ç½®å¯¼å…¥çŠ¶æ€
                        handler.reset_import_state()
                        st.success("Neo4jæ•°æ®åº“å·²é‡ç½®ï¼Œæ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»å·²åˆ é™¤")
                        st.session_state.import_history = []
                        # æ·»åŠ ä¸€ä¸ªç©ºçš„å¯¼å…¥ç»“æœè®°å½•
                        st.session_state.last_import_results = {
                            "files": [],
                            "node_counts": {"company": 0, "industry": 0, "product": 0},
                            "sample_nodes": {"company": [], "industry": [], "product": []},
                            "total_nodes": 0,
                            "total_rels": 0,
                            "verification_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        }
                        st.experimental_rerun()
                    except Exception as e:
                        st.error(f"é‡ç½®Neo4jæ•°æ®åº“å¤±è´¥: {str(e)}")
            
            # æ–°å¢ï¼šæ¸…ç†å¯¼å…¥æ•°æ®åº“å‰çš„æµ‹è¯•æ•°æ®
            st.warning("æ¸…ç†æµ‹è¯•æ•°æ®ï¼šåˆ é™¤ç³»ç»Ÿè‡ªåŠ¨åˆ›å»ºçš„ç¤ºä¾‹æ•°æ®ï¼ˆåä¸ºã€é˜¿é‡Œå·´å·´ç­‰ï¼‰")
            if st.button("æ¸…ç†ç¤ºä¾‹æ•°æ®", key="clean_samples_btn"):
                try:
                    # åˆ é™¤ç¤ºä¾‹å…¬å¸èŠ‚ç‚¹
                    sample_companies = ["é˜¿é‡Œå·´å·´", "è…¾è®¯", "ç™¾åº¦", "åä¸º", "å°ç±³", "äº¬ä¸œ", "ç½‘æ˜“", "ç¾å›¢", "å­—èŠ‚è·³åŠ¨", "æ‹¼å¤šå¤š"]
                    for company in sample_companies:
                        handler.g.run(f"MATCH (c:company {{name: '{company}'}}) DETACH DELETE c")
                    
                    # åˆ é™¤ç¤ºä¾‹è¡Œä¸šå’Œäº§å“èŠ‚ç‚¹
                    handler.g.run("MATCH (i:industry) WHERE i.name IN ['äº’è”ç½‘', 'ç”µå­å•†åŠ¡', 'äººå·¥æ™ºèƒ½', 'é€šä¿¡', 'æ™ºèƒ½ç¡¬ä»¶'] DETACH DELETE i")
                    handler.g.run("MATCH (p:product) WHERE p.name IN ['æ·˜å®', 'å¾®ä¿¡', 'ç™¾åº¦æœç´¢', 'åä¸ºæ‰‹æœº', 'å°ç±³æ‰‹æœº'] DETACH DELETE p")
                    
                    st.success("ç¤ºä¾‹æ•°æ®å·²æ¸…ç†å®Œæˆ")
                    # åˆ·æ–°å¯¼å…¥ç»“æœ
                    if 'last_import_results' in st.session_state:
                        st.session_state.last_import_results = verify_import_results()
                    st.experimental_rerun()
                except Exception as e:
                    st.error(f"æ¸…ç†ç¤ºä¾‹æ•°æ®å¤±è´¥: {str(e)}")
        
        # æ·»åŠ å¯¼å…¥ç»“æœæ˜¾ç¤ºéƒ¨åˆ†
        if 'last_import_results' in st.session_state:
            with st.expander("æŸ¥çœ‹æœ€è¿‘å¯¼å…¥ç»“æœ", expanded=True):
                results = st.session_state.last_import_results
                
                if "error" in results:
                    st.error(f"è·å–å¯¼å…¥ç»“æœæ—¶å‡ºé”™: {results['error']}")
                else:
                    st.success(f"å¯¼å…¥éªŒè¯æ—¶é—´: {results['verification_time']}")
                    
                    # æ˜¾ç¤ºå¯¼å…¥æ–‡ä»¶ä¿¡æ¯
                    st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>å¯¼å…¥çš„æ•°æ®æ–‡ä»¶</h6>", unsafe_allow_html=True)
                    file_data = []
                    for file_info in results["files"]:
                        file_data.append({
                            "æ–‡ä»¶ç±»å‹": file_info["type"],
                            "æ–‡ä»¶è·¯å¾„": file_info["path"],
                            "æ–‡ä»¶å¤§å°": file_info["size"]
                        })
                    st.dataframe(pd.DataFrame(file_data), use_container_width=True)
                    
                    # æ˜¾ç¤ºèŠ‚ç‚¹æ•°é‡ç»Ÿè®¡
                    st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>èŠ‚ç‚¹æ•°é‡ç»Ÿè®¡</h6>", unsafe_allow_html=True)
                    cols = st.columns(len(results["node_counts"]) + 1)
                    
                    for i, (node_type, count) in enumerate(results["node_counts"].items()):
                        with cols[i]:
                            st.metric(f"{node_type}èŠ‚ç‚¹æ•°", f"{count:,}")
                    
                    with cols[-1]:
                        st.metric("æ€»èŠ‚ç‚¹æ•°", f"{results['total_nodes']:,}")
                    
                    # æ˜¾ç¤ºå‰50ä¸ªèŠ‚ç‚¹ç¤ºä¾‹
                    st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>èŠ‚ç‚¹ç¤ºä¾‹ (å‰50ä¸ª)</h6>", unsafe_allow_html=True)
                    node_tabs = st.tabs(list(results["sample_nodes"].keys()))
                    
                    for i, (node_type, samples) in enumerate(results["sample_nodes"].items()):
                        with node_tabs[i]:
                            if samples:
                                sample_text = ", ".join(samples)
                                st.write(sample_text)
                            else:
                                st.info(f"æ²¡æœ‰æ‰¾åˆ°{node_type}ç±»å‹çš„èŠ‚ç‚¹")
                                
                    # æ˜¾ç¤ºå…³ç³»æ•°é‡
                    st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>å…³ç³»ç»Ÿè®¡</h6>", unsafe_allow_html=True)
                    st.metric("æ€»å…³ç³»æ•°", f"{results['total_rels']:,}")
    
    with col_history:
        # å¯¼å…¥å†å²
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>å¯¼å…¥å†å²</h5>", unsafe_allow_html=True)
        if st.session_state.import_history:
            # åˆ›å»ºä¸€ä¸ªæ›´ç´§å‡‘çš„æ•°æ®æ¡†ï¼Œå‡å°é«˜åº¦
            history_df = pd.DataFrame(st.session_state.import_history)
            st.dataframe(history_df, use_container_width=True, height=150)
            
            # æ·»åŠ æ¸…é™¤å†å²æŒ‰é’®
            if st.button("æ¸…é™¤å†å²è®°å½•", key="clear_history"):
                st.session_state.import_history = []
                st.experimental_rerun()
        else:
            st.info("æš‚æ— å¯¼å…¥å†å²è®°å½•")

with tab3:
    st.markdown("<h4 style='font-size:1rem; margin:0.1rem 0;'>å›¾è°±æ¢ç´¢</h4>", unsafe_allow_html=True)

    # å°†ç¤ºä¾‹æ•°æ®å¯¼å…¥åŠŸèƒ½æ”¾å…¥ä¸€ä¸ªæŠ˜å é¢æ¿ä¸­ï¼Œä»¥èŠ‚çœç©ºé—´
    with st.expander("ç¤ºä¾‹æ•°æ®æ“ä½œ"):
        if st.button("å¯¼å…¥é¢„å®šä¹‰ç¤ºä¾‹æ•°æ®", key="import_samples", help="å¯¼å…¥åŒ…æ‹¬é˜¿é‡Œå·´å·´ã€åä¸ºç­‰å…¬å¸çš„ç¤ºä¾‹æ•°æ®åˆ°Neo4j", use_container_width=True):
            with st.spinner("æ­£åœ¨å¯¼å…¥ç¤ºä¾‹æ•°æ®..."):
                try:
                    # å®šä¹‰çœŸå®å…¬å¸ç¤ºä¾‹æ•°æ®
                    company_data = [
                        {"name": "é˜¿é‡Œå·´å·´", "description": "ä¸­å›½é¢†å…ˆçš„ç”µå­å•†åŠ¡å…¬å¸"},
                        {"name": "è…¾è®¯", "description": "ä¸­å›½é¢†å…ˆçš„äº’è”ç½‘æœåŠ¡æä¾›å•†"},
                        {"name": "ç™¾åº¦", "description": "ä¸­å›½é¢†å…ˆçš„æœç´¢å¼•æ“å…¬å¸"},
                        {"name": "åä¸º", "description": "å…¨çƒé¢†å…ˆçš„é€šä¿¡è®¾å¤‡åˆ¶é€ å•†"},
                        {"name": "å°ç±³", "description": "ä¸­å›½é¢†å…ˆçš„æ™ºèƒ½æ‰‹æœºåˆ¶é€ å•†"},
                        {"name": "äº¬ä¸œ", "description": "ä¸­å›½é¢†å…ˆçš„ç”µå­å•†åŠ¡å¹³å°"},
                        {"name": "ç½‘æ˜“", "description": "ä¸­å›½é¢†å…ˆçš„äº’è”ç½‘ç§‘æŠ€å…¬å¸"},
                        {"name": "ç¾å›¢", "description": "ä¸­å›½é¢†å…ˆçš„ç”Ÿæ´»æœåŠ¡ç”µå­å•†åŠ¡å¹³å°"},
                        {"name": "å­—èŠ‚è·³åŠ¨", "description": "ä¸­å›½é¢†å…ˆçš„äº’è”ç½‘ç§‘æŠ€å…¬å¸"},
                        {"name": "æ‹¼å¤šå¤š", "description": "ä¸­å›½é¢†å…ˆçš„ç”µå­å•†åŠ¡å¹³å°"}
                    ]
                    industry_data = [{"name": "äº’è”ç½‘", "description": "äº’è”ç½‘è¡Œä¸š"}, {"name": "ç”µå­å•†åŠ¡", "description": "ç”µå­å•†åŠ¡è¡Œä¸š"}, {"name": "äººå·¥æ™ºèƒ½", "description": "äººå·¥æ™ºèƒ½è¡Œä¸š"}, {"name": "é€šä¿¡", "description": "é€šä¿¡è¡Œä¸š"}, {"name": "æ™ºèƒ½ç¡¬ä»¶", "description": "æ™ºèƒ½ç¡¬ä»¶è¡Œä¸š"}]
                    product_data = [{"name": "æ·˜å®", "description": "é˜¿é‡Œå·´å·´æ——ä¸‹ç”µå­å•†åŠ¡å¹³å°"}, {"name": "å¾®ä¿¡", "description": "è…¾è®¯æ——ä¸‹ç¤¾äº¤é€šè®¯è½¯ä»¶"}, {"name": "ç™¾åº¦æœç´¢", "description": "ç™¾åº¦æ——ä¸‹æœç´¢å¼•æ“"}, {"name": "åä¸ºæ‰‹æœº", "description": "åä¸ºç”Ÿäº§çš„æ™ºèƒ½æ‰‹æœº"}, {"name": "å°ç±³æ‰‹æœº", "description": "å°ç±³ç”Ÿäº§çš„æ™ºèƒ½æ‰‹æœº"}]
                    company_industry_data = [
                        {"start_name": "é˜¿é‡Œå·´å·´", "end_name": "äº’è”ç½‘"}, {"start_name": "é˜¿é‡Œå·´å·´", "end_name": "ç”µå­å•†åŠ¡"},
                        {"start_name": "è…¾è®¯", "end_name": "äº’è”ç½‘"}, {"start_name": "ç™¾åº¦", "end_name": "äº’è”ç½‘"},
                        {"start_name": "ç™¾åº¦", "end_name": "äººå·¥æ™ºèƒ½"}, {"start_name": "åä¸º", "end_name": "é€šä¿¡"},
                        {"start_name": "åä¸º", "end_name": "æ™ºèƒ½ç¡¬ä»¶"}, {"start_name": "å°ç±³", "end_name": "æ™ºèƒ½ç¡¬ä»¶"}
                    ]
                    
                    # åˆ†ç¦»ä¸åŒå…³ç³»ç±»å‹çš„æ•°æ®
                    company_product_own_data = [
                        {"start_name": "é˜¿é‡Œå·´å·´", "end_name": "æ·˜å®", "rel_weight": "100%"},
                        {"start_name": "è…¾è®¯", "end_name": "å¾®ä¿¡", "rel_weight": "100%"},
                        {"start_name": "ç™¾åº¦", "end_name": "ç™¾åº¦æœç´¢", "rel_weight": "100%"}
                    ]
                    company_product_produce_data = [
                        {"start_name": "åä¸º", "end_name": "åä¸ºæ‰‹æœº", "rel_weight": "100%"},
                        {"start_name": "å°ç±³", "end_name": "å°ç±³æ‰‹æœº", "rel_weight": "100%"}
                    ]

                    # ä½¿ç”¨handlerå¯¼å…¥æ•°æ®
                    handler.import_nodes("company", company_data, is_file=False)
                    handler.import_nodes("industry", industry_data, is_file=False)
                    handler.import_nodes("product", product_data, is_file=False)
                    
                    # åˆ†åˆ«å¯¼å…¥ä¸åŒç±»å‹çš„å…³ç³»
                    handler._import_relationships("company_industry", company_industry_data, "company", "industry", "å±äº", is_file=False)
                    handler._import_relationships(rel_key="company_product_own", data=company_product_own_data, start_label="company", end_label="product", rel_type="æ‹¥æœ‰", is_file=False)
                    handler._import_relationships(rel_key="company_product_produce", data=company_product_produce_data, start_label="company", end_label="product", rel_type="ç”Ÿäº§", is_file=False)

                    total_nodes = len(company_data) + len(industry_data) + len(product_data)
                    total_rels = len(company_industry_data) + len(company_product_own_data) + len(company_product_produce_data)
                    st.success(f"æˆåŠŸå¯¼å…¥ç¤ºä¾‹æ•°æ®: {total_nodes} ä¸ªèŠ‚ç‚¹å’Œ {total_rels} æ¡å…³ç³»")
                    st.info("ç°åœ¨æ‚¨å¯ä»¥æœç´¢ä»¥ä¸‹ç¤ºä¾‹å®ä½“: é˜¿é‡Œå·´å·´, è…¾è®¯, ç™¾åº¦, åä¸º, å°ç±³")
                except Exception as e:
                    st.error(f"å¯¼å…¥ç¤ºä¾‹æ•°æ®å¤±è´¥: {str(e)}")
                    st.code(traceback.format_exc())

    # åˆ›å»ºä¸¤åˆ—ç”¨äºæ”¾ç½®"å®ä½“æœç´¢"å’Œ"å…³ç³»æ¢ç´¢"æ§ä»¶
    control_col1, control_col2 = st.columns(2)

    with control_col1:
        st.markdown("<h5 style='font-size:0.9rem; margin:0.05rem 0;'>å®ä½“æœç´¢</h5>", unsafe_allow_html=True)
        search_cols = st.columns([1, 1])
        with search_cols[0]:
            entity_type = st.selectbox("å®ä½“ç±»å‹", ["å…¬å¸(company)", "è¡Œä¸š(industry)", "äº§å“(product)", "æ‰€æœ‰ç±»å‹(all)"], label_visibility="collapsed")
            st.caption("å®ä½“ç±»å‹")
        with search_cols[1]:
            search_term = st.text_input("å®ä½“åç§°", label_visibility="collapsed", placeholder="è¾“å…¥å…³é”®è¯")
            st.caption("æœç´¢å…³é”®è¯")

        with st.expander("æœç´¢é€‰é¡¹", expanded=False):
            option_cols = st.columns(2)
            with option_cols[0]:
                case_sensitive = st.checkbox("åŒºåˆ†å¤§å°å†™", value=False)
                limit_results = st.slider("ç»“æœæ•°é‡", 10, 100, 20)
            with option_cols[1]:
                exact_match = st.checkbox("ç²¾ç¡®åŒ¹é…", value=False)

        if st.button("æœç´¢å®ä½“", use_container_width=True):
            if not search_term:
                st.warning("è¯·è¾“å…¥æœç´¢å…³é”®è¯")
            else:
                with st.spinner("æ­£åœ¨æœç´¢..."):
                    # (ä»£ç å†…å®¹ä¸å˜)
                    # ... [åŸæœ‰çš„å®ä½“æœç´¢æŸ¥è¯¢é€»è¾‘] ...
                    try:
                        if entity_type == "æ‰€æœ‰ç±»å‹(all)": entity_label = None
                        else: entity_label = entity_type.split("(")[1].split(")")[0]
                        if entity_label:
                            if exact_match:
                                if case_sensitive: query = f"MATCH (n:{entity_label}) WHERE n.name = $search_term RETURN n.name AS name, labels(n) AS labels LIMIT {limit_results}"
                                else: query = f"MATCH (n:{entity_label}) WHERE toLower(n.name) = toLower($search_term) RETURN n.name AS name, labels(n) AS labels LIMIT {limit_results}"
                            else:
                                if case_sensitive: query = f"MATCH (n:{entity_label}) WHERE n.name CONTAINS $search_term RETURN n.name AS name, labels(n) AS labels LIMIT {limit_results}"
                                else: query = f"MATCH (n:{entity_label}) WHERE toLower(n.name) CONTAINS toLower($search_term) RETURN n.name AS name, labels(n) AS labels LIMIT {limit_results}"
                        else:
                            if exact_match:
                                if case_sensitive: query = f"MATCH (n) WHERE n.name = $search_term RETURN n.name AS name, labels(n) AS labels LIMIT {limit_results}"
                                else: query = f"MATCH (n) WHERE toLower(n.name) = toLower($search_term) RETURN n.name AS name, labels(n) AS labels LIMIT {limit_results}"
                            else:
                                if case_sensitive: query = f"MATCH (n) WHERE n.name CONTAINS $search_term RETURN n.name AS name, labels(n) AS labels LIMIT {limit_results}"
                                else: query = f"MATCH (n) WHERE toLower(n.name) CONTAINS toLower($search_term) RETURN n.name AS name, labels(n) AS labels LIMIT {limit_results}"
                        result = handler.g.run(query, search_term=search_term).data()
                        if result: st.session_state.search_result = result
                        else:
                            st.info(f"æœªæ‰¾åˆ°åŒ¹é… '{search_term}' çš„å®ä½“")
                            st.session_state.search_result = []
                    except Exception as e:
                        st.error(f"æœç´¢å¤±è´¥: {str(e)}")
                        st.session_state.search_result = []

    with control_col2:
        st.markdown("<h5 style='font-size:0.9rem; margin:0.05rem 0;'>å…³ç³»æ¢ç´¢</h5>", unsafe_allow_html=True)
        if 'search_result' in st.session_state and st.session_state.search_result:
            entity_names = [item['name'] for item in st.session_state.search_result]
            selected_entity = st.selectbox("ä»æœç´¢ç»“æœé€‰æ‹©å®ä½“", entity_names, help="é€‰æ‹©è¦æ¢ç´¢å…³ç³»çš„å®ä½“", label_visibility="collapsed")
            st.caption("é€‰æ‹©å®ä½“è¿›è¡Œæ¢ç´¢")
            
            depth = st.slider("æ¢ç´¢æ·±åº¦", 1, 3, 1, help="è®¾ç½®å…³ç³»æ¢ç´¢çš„æ·±åº¦")
            
            if st.button("æ¢ç´¢å…³ç³»", use_container_width=True):
                with st.spinner(f"æ­£åœ¨æ¢ç´¢ {selected_entity} çš„å…³ç³»..."):
                    # (ä»£ç å†…å®¹ä¸å˜)
                    # ... [åŸæœ‰çš„å…³ç³»æ¢ç´¢æŸ¥è¯¢é€»è¾‘] ...
                    try:
                        query = f"MATCH path = (n)-[*1..{depth}]-(m) WHERE n.name = $entity_name RETURN path LIMIT 100"
                        result = handler.g.run(query, entity_name=selected_entity).data()
                        if result:
                            nodes = set()
                            relationships = []
                            for record in result:
                                path = record['path']
                                path_nodes = path.nodes
                                path_relationships = path.relationships
                                for node in path_nodes: nodes.add((node.identity, node.get('name'), list(node.labels)[0]))
                                for rel in path_relationships:
                                    start_node = rel.start_node.get('name')
                                    end_node = rel.end_node.get('name')
                                    rel_type = type(rel).__name__
                                    relationships.append((start_node, rel_type, end_node))
                            st.session_state.explored_nodes = list(nodes)
                            st.session_state.explored_relationships = relationships
                        else:
                            st.info(f"æœªæ‰¾åˆ°ä¸ '{selected_entity}' ç›¸å…³çš„å…³ç³»")
                            st.session_state.explored_nodes = []
                            st.session_state.explored_relationships = []
                    except Exception as e:
                        st.error(f"å…³ç³»æ¢ç´¢å¤±è´¥: {str(e)}")
                        st.session_state.explored_nodes = []
                        st.session_state.explored_relationships = []
        else:
            st.info("è¯·å…ˆåœ¨å·¦ä¾§æœç´¢å®ä½“ï¼Œç„¶ååœ¨æ­¤å¤„æ¢ç´¢å…³ç³»")

    # --- ç»“æœæ˜¾ç¤ºåŒº ---
    # ä½¿ç”¨tabsç»„ç»‡ä¸åŒç±»å‹çš„ç»“æœï¼Œä½¿æ˜¾ç¤ºæ›´ç´§å‡‘
    result_tabs = st.tabs(["å®ä½“æœç´¢ç»“æœ", "å…³ç³»æ¢ç´¢ç»“æœ", "å¯è§†åŒ–"])

    with result_tabs[0]:
        if 'search_result' in st.session_state and st.session_state.search_result:
            st.success(f"æ‰¾åˆ° {len(st.session_state.search_result)} ä¸ªåŒ¹é…çš„å®ä½“")
            df = pd.DataFrame(st.session_state.search_result)
            st.dataframe(df, use_container_width=True, height=400)
        else:
            st.info("æœç´¢ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ")

    with result_tabs[1]:
        if 'explored_relationships' in st.session_state and st.session_state.explored_relationships:
            st.success(f"æ‰¾åˆ° {len(st.session_state.explored_relationships)} æ¡å…³ç³»")
            rel_data = [{"èµ·å§‹å®ä½“": s, "å…³ç³»ç±»å‹": r, "ç›®æ ‡å®ä½“": e} for s, r, e in st.session_state.explored_relationships]
            if rel_data:
                rel_df = pd.DataFrame(rel_data)
                st.dataframe(rel_df, use_container_width=True, height=400)
        else:
            st.info("å…³ç³»æ¢ç´¢ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ")
    
    with result_tabs[2]:
        if 'explored_relationships' in st.session_state and st.session_state.explored_relationships:
            st.subheader("å…³ç³»ç½‘ç»œå›¾")
            try:
                # (ä»£ç å†…å®¹ä¸å˜)
                # ... [åŸæœ‰çš„å¯è§†åŒ–é€»è¾‘] ...
                node_map = {}
                if 'explored_nodes' in st.session_state:
                    for i, (node_id, node_name, node_type) in enumerate(st.session_state.explored_nodes):
                        node_map[node_name] = i
                success, message = visualize_network(st.session_state.explored_nodes, st.session_state.explored_relationships, node_map)
                if not success:
                    st.error(message)
                    st.warning('æ— æ³•æ˜¾ç¤ºç½‘ç»œå›¾ï¼Œå°†æ˜¾ç¤ºå…³ç³»çŸ©é˜µä½œä¸ºæ›¿ä»£')
                    fig = visualize_matrix(st.session_state.explored_relationships, node_map)
                    st.pyplot(fig)
                else:
                    with st.expander('æŸ¥çœ‹å…³ç³»çŸ©é˜µ'):
                        fig = visualize_matrix(st.session_state.explored_relationships, node_map)
                        st.pyplot(fig)
            except Exception as e:
                st.error(f"åˆ›å»ºå¯è§†åŒ–å›¾è¡¨æ—¶å‡ºé”™: {e}")
        else:
            st.info("å…³ç³»æ¢ç´¢åï¼Œå¯è§†åŒ–å›¾è¡¨å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ")

with tab4:
    st.markdown("<h4 style='font-size:1rem; margin:0.1rem 0;'>çŸ¥è¯†å›¾è°±å¯è§†åŒ–</h4>", unsafe_allow_html=True)
    
    # é¡¶éƒ¨æ§åˆ¶é¢æ¿ï¼Œä½¿ç”¨åˆ—æ¥å¸ƒå±€
    vis_control_col1, vis_control_col2 = st.columns([1, 1])

    with vis_control_col1:
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>å¯è§†åŒ–æ§åˆ¶é¢æ¿</h5>", unsafe_allow_html=True)
        
        # ç¼“å­˜å®ä½“é€‰é¡¹
        @st.cache_data(ttl=300)
        def get_entity_options_cached(entity_type):
            return get_entity_options(handler, entity_type)

        entity_type_vis = st.selectbox(
            "é€‰æ‹©å®ä½“ç±»å‹è¿›è¡Œå¯è§†åŒ–",
            ["å…¬å¸(company)", "è¡Œä¸š(industry)", "äº§å“(product)"],
            key="vis_entity_type",
            index=0,
            label_visibility="collapsed"
        )
        st.caption("é€‰æ‹©å®ä½“ç±»å‹")

        entity_options = get_entity_options_cached(entity_type_vis.split("(")[1].split(")")[0])
        selected_entities = st.multiselect(
            "é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªå®ä½“",
            entity_options,
            default=entity_options[:2] if entity_options else [],
            key="vis_entities",
            label_visibility="collapsed"
        )
        st.caption(f"å·²é€‰æ‹© {len(selected_entities)} ä¸ªå®ä½“")
        
    with vis_control_col2:
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>&nbsp;</h5>", unsafe_allow_html=True) # for alignment
        
        visualization_type = st.selectbox(
            "é€‰æ‹©å¯è§†åŒ–ç±»å‹",
            ["å…³ç³»ç½‘ç»œå›¾", "å±‚æ¬¡ç»“æ„æ ‘", "å…³ç³»çŸ©é˜µ"],
            key="vis_type",
            label_visibility="collapsed"
        )
        st.caption("é€‰æ‹©å¯è§†åŒ–ç±»å‹")

        depth_vis = st.slider("å…³ç³»æ·±åº¦", 1, 3, 1, key="vis_depth")

        if st.button("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨", use_container_width=True, key="generate_vis"):
            if not selected_entities:
                st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå®ä½“")
            else:
                with st.spinner("æ­£åœ¨ç”Ÿæˆå›¾è¡¨..."):
                    try:
                        st.session_state.visualization_data = {
                            "type": visualization_type,
                            "entities": selected_entities,
                            "depth": depth_vis
                        }
                    except Exception as e:
                        st.error(f"ç”Ÿæˆå¯è§†åŒ–å¤±è´¥: {e}")
                        st.code(traceback.format_exc())

    # å¯è§†åŒ–ç»“æœæ˜¾ç¤ºåŒº
    st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>å¯è§†åŒ–ç»“æœ</h5>", unsafe_allow_html=True)
    if 'visualization_data' in st.session_state:
        data = st.session_state.visualization_data
        vis_type = data['type']
        
        with st.container():
            if vis_type == "å…³ç³»ç½‘ç»œå›¾":
                fig = display_network_graph(handler, data['entities'], data['depth'])
                if fig:
                    st_echarts(options=fig, height="600px")
                else:
                    st.info("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨äºç”Ÿæˆå…³ç³»ç½‘ç»œå›¾çš„æ•°æ®ã€‚")
            
            elif vis_type == "å±‚æ¬¡ç»“æ„æ ‘":
                fig = display_hierarchy_tree(handler, data['entities'][0] if data['entities'] else None)
                if fig:
                    st_echarts(options=fig, height="600px")
                else:
                    st.info("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨äºç”Ÿæˆå±‚æ¬¡ç»“æ„æ ‘çš„æ•°æ®ã€‚è¯·ç¡®ä¿é€‰æ‹©äº†å•ä¸ªå®ä½“ã€‚")

            elif vis_type == "å…³ç³»çŸ©é˜µ":
                fig = display_relationship_matrix(handler, data['entities'])
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨äºç”Ÿæˆå…³ç³»çŸ©é˜µçš„æ•°æ®ã€‚")
    else:
        st.info("ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ã€‚")

def get_popular_industries(handler):
    """
    è·å–æ•°æ®åº“ä¸­çƒ­é—¨çš„è¡Œä¸šï¼ˆå‡ºç°é¢‘ç‡æœ€é«˜çš„è¡Œä¸šï¼‰
    """
    if not handler or not handler.g:
        return []
    try:
        query = (
            "MATCH (i:industry)<-[:BELONGS_TO]-(c:company) "
            "RETURN i.name AS industry, count(c) AS company_count "
            "ORDER BY company_count DESC "
            "LIMIT 20"
        )
        result = handler.g.run(query).data()
        return [row['industry'] for row in result]
    except Exception as e:
        logger.error(f"è·å–çƒ­é—¨è¡Œä¸šå¤±è´¥: {e}")
        return []

with tab5:
    st.markdown("<h4 style='font-size:1rem; margin:0.1rem 0;'>è¡Œä¸šé“¾åˆ†æ</h4>", unsafe_allow_html=True)
    
    # å°†é¡µé¢åˆ†ä¸ºæ§åˆ¶åŒºå’Œç»“æœåŒº
    control_col, result_col = st.columns([1, 2])
    
    with control_col:
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>åˆ†æå‚æ•°</h5>", unsafe_allow_html=True)

        # ä½¿ç”¨ç¼“å­˜å‡½æ•°è·å–è¡Œä¸šåˆ—è¡¨
        @st.cache_data(ttl=300)
        def get_popular_industries_cached():
            return get_popular_industries(handler)

        popular_industries = get_popular_industries_cached()
        selected_industry = st.selectbox("é€‰æ‹©ä¸€ä¸ªè¡Œä¸šè¿›è¡Œåˆ†æ", popular_industries, index=0 if popular_industries else -1, label_visibility="collapsed")
        st.caption("é€‰æ‹©è¡Œä¸š")

        analysis_type = st.selectbox(
            "é€‰æ‹©åˆ†æç±»å‹",
            ["äº§ä¸šé“¾åˆ†æ", "ç«äº‰æƒ…æŠ¥åˆ†æ", "ä¼ä¸šå…³è”åˆ†æ", "äº§å“æŠ€æœ¯åˆ†æ"],
            key="analysis_type",
            label_visibility="collapsed"
        )
        st.caption("é€‰æ‹©åˆ†æç±»å‹")

        # å°†åˆ†æç»´åº¦å’ŒæŒ‰é’®æ”¾åœ¨Expanderä¸­ï¼Œå¹¶ä½¿ç”¨åˆ—å¸ƒå±€
        with st.expander("é«˜çº§é€‰é¡¹å’Œæ“ä½œ"):
            dim_cols = st.columns(2)
            with dim_cols[0]:
                st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>åˆ†æç»´åº¦</h6>", unsafe_allow_html=True)
                upstream_depth = st.slider("ä¸Šæ¸¸æ·±åº¦", 1, 3, 1, key="upstream_depth")
                downstream_depth = st.slider("ä¸‹æ¸¸æ·±åº¦", 1, 3, 1, key="downstream_depth")
            
            with dim_cols[1]:
                st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>&nbsp;</h6>", unsafe_allow_html=True) # for alignment
                if st.button("å¼€å§‹åˆ†æ", use_container_width=True, key="start_analysis"):
                    if not selected_industry:
                        st.warning("è¯·é€‰æ‹©ä¸€ä¸ªè¡Œä¸š")
                    else:
                        with st.spinner(f"æ­£åœ¨åˆ†æ {selected_industry} çš„{analysis_type}..."):
                            try:
                                analysis_func = st.session_state.analysis_functions.get(analysis_type)
                                if analysis_func:
                                    results = analysis_func(selected_industry, upstream_depth, downstream_depth)
                                    st.session_state.analysis_results = {
                                        "industry": selected_industry,
                                        "type": analysis_type,
                                        "results": results
                                    }
                                    st.success(f"åˆ†æå®Œæˆï¼Œæ‰¾åˆ° {len(results)} æ¡ç»“æœ")
                                else:
                                    st.error(f"æœªæ‰¾åˆ°â€œ{analysis_type}â€å¯¹åº”çš„åˆ†æåŠŸèƒ½ã€‚")
                            except Exception as e:
                                st.error(f"åˆ†æå¤±è´¥: {str(e)}")
                                st.code(traceback.format_exc())
    
    with result_col:
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>åˆ†æç»“æœ</h5>", unsafe_allow_html=True)
        if 'analysis_results' not in st.session_state:
            st.info("åˆ†æç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œã€‚")
        else:
            analysis_data = st.session_state.analysis_results
            st.markdown(f"**è¡Œä¸š**: {analysis_data['industry']} | **åˆ†æç±»å‹**: {analysis_data['type']}")
            
            # ä½¿ç”¨Tabsæ¥ç»„ç»‡æ•°æ®è¡¨æ ¼å’Œå¯è§†åŒ–å›¾è¡¨
            res_tab1, res_tab2, res_tab3 = st.tabs(["æ•°æ®è¡¨æ ¼", "å¯è§†åŒ–å›¾è¡¨", "æ•°æ®æ´å¯Ÿ"])
            
            with res_tab1:
                # æ•°æ®è¡¨æ ¼å±•ç¤ºé€»è¾‘
                if analysis_data['type'] == "äº§ä¸šé“¾åˆ†æ":
                    if not analysis_data['results']:
                        st.warning("æœªæ‰¾åˆ°äº§ä¸šé“¾æ•°æ®")
                    else:
                        # æå–æ•°æ®
                        industry_data = analysis_data['results'][0]
                        
                        # åˆ›å»ºä¸Šä¸‹æ¸¸è¡¨æ ¼å’Œä¼ä¸šåˆ†å¸ƒè¡¨æ ¼
                        upstream_data = []
                        downstream_data = []
                        companies_data = []
                        
                        if 'upstream' in industry_data and industry_data['upstream']:
                            for up in industry_data['upstream']:
                                if hasattr(up, 'get'):
                                    upstream_data.append({"è¡Œä¸šåç§°": up.get('name', 'æœªçŸ¥'), "ç±»å‹": "ä¸Šæ¸¸"})
                        
                        if 'downstream' in industry_data and industry_data['downstream']:
                            for down in industry_data['downstream']:
                                if hasattr(down, 'get'):
                                    downstream_data.append({"è¡Œä¸šåç§°": down.get('name', 'æœªçŸ¥'), "ç±»å‹": "ä¸‹æ¸¸"})
                        
                        if 'companies' in industry_data and industry_data['companies']:
                            for company in industry_data['companies']:
                                if hasattr(company, 'get'):
                                    companies_data.append({"ä¼ä¸šåç§°": company.get('name', 'æœªçŸ¥')})
                        
                        # æ˜¾ç¤ºä¸Šä¸‹æ¸¸è¡¨æ ¼
                        if upstream_data or downstream_data:
                            st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>ä¸Šä¸‹æ¸¸è¡Œä¸š</h6>", unsafe_allow_html=True)
                            chain_df = pd.DataFrame(upstream_data + downstream_data)
                            st.dataframe(chain_df, use_container_width=True, height=150)
                        
                        # æ˜¾ç¤ºä¼ä¸šåˆ†å¸ƒè¡¨æ ¼
                        if companies_data:
                            st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>ä¼ä¸šåˆ†å¸ƒ</h6>", unsafe_allow_html=True)
                            companies_df = pd.DataFrame(companies_data)
                            st.dataframe(companies_df, use_container_width=True, height=150)
                
                elif analysis_data['type'] == "ç«äº‰æƒ…æŠ¥åˆ†æ":
                    if not analysis_data['results']:
                        st.warning("æœªæ‰¾åˆ°ç«äº‰æƒ…æŠ¥æ•°æ®")
                    else:
                        # åˆ›å»ºç«äº‰å…³ç³»è¡¨æ ¼
                        competition_data = []
                        for item in analysis_data['results']:
                            competition_data.append({
                                "ä¼ä¸š1": item.get('company1', 'æœªçŸ¥'),
                                "ä¼ä¸š2": item.get('company2', 'æœªçŸ¥'),
                                "å…³è”å¼ºåº¦": item.get('strength', 0)
                            })
                        
                        if competition_data:
                            st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>ä¼ä¸šç«äº‰å…³ç³»</h6>", unsafe_allow_html=True)
                            competition_df = pd.DataFrame(competition_data)
                            st.dataframe(competition_df, use_container_width=True, height=250)
                
                elif analysis_data['type'] == "ä¼ä¸šå…³è”åˆ†æ":
                    if not analysis_data['results']:
                        st.warning("æœªæ‰¾åˆ°ä¼ä¸šå…³è”æ•°æ®")
                    else:
                        # åˆ›å»ºä¼ä¸šå…³è”è¡¨æ ¼
                        relation_data = []
                        for item in analysis_data['results']:
                            relation_data.append({
                                "ä¼ä¸š": item.get('company', 'æœªçŸ¥'),
                                "å…³ç³»ç±»å‹": item.get('relationship', 'æœªçŸ¥'),
                                "å…³è”å®ä½“": item.get('related_entity', 'æœªçŸ¥'),
                                "å®ä½“ç±»å‹": item.get('entity_type', 'æœªçŸ¥')
                            })
                        
                        if relation_data:
                            st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>ä¼ä¸šå…³è”ç½‘ç»œ</h6>", unsafe_allow_html=True)
                            relation_df = pd.DataFrame(relation_data)
                            st.dataframe(relation_df, use_container_width=True, height=250)
                
                else:  # äº§å“æŠ€æœ¯åˆ†æ
                    if not analysis_data['results']:
                        st.warning("æœªæ‰¾åˆ°äº§å“æŠ€æœ¯æ•°æ®")
                    else:
                        # åˆ›å»ºäº§å“æŠ€æœ¯è¡¨æ ¼
                        product_data = []
                        for item in analysis_data['results']:
                            product_data.append({
                                "äº§å“": item.get('product', 'æœªçŸ¥'),
                                "å…³è”å®ä½“æ•°": item.get('connection_count', 0),
                                "å…³è”å®ä½“": ", ".join(item.get('related_entities', []))[:50] + ("..." if len(", ".join(item.get('related_entities', []))) > 50 else "")
                            })
                        
                        if product_data:
                            st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>äº§å“æŠ€æœ¯è·¯çº¿å›¾</h6>", unsafe_allow_html=True)
                            product_df = pd.DataFrame(product_data)
                            st.dataframe(product_df, use_container_width=True, height=250)
            
            with res_tab2:
                # å¯è§†åŒ–å›¾è¡¨å±•ç¤ºé€»è¾‘
                if analysis_data['type'] == "äº§ä¸šé“¾åˆ†æ":
                    st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>äº§ä¸šé“¾å›¾</h6>", unsafe_allow_html=True)
                    # è¿™é‡Œå¯ä»¥æ·»åŠ äº§ä¸šé“¾å¯è§†åŒ–ä»£ç 
                    st.info("äº§ä¸šé“¾å›¾å°†åœ¨æ­¤æ˜¾ç¤º")
                
                elif analysis_data['type'] == "ç«äº‰æƒ…æŠ¥åˆ†æ":
                    st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>ç«äº‰ç½‘ç»œå›¾</h6>", unsafe_allow_html=True)
                    # è¿™é‡Œå¯ä»¥æ·»åŠ ç«äº‰ç½‘ç»œå¯è§†åŒ–ä»£ç 
                    st.info("ç«äº‰ç½‘ç»œå›¾å°†åœ¨æ­¤æ˜¾ç¤º")
                
                elif analysis_data['type'] == "ä¼ä¸šå…³è”åˆ†æ":
                    st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>å…³è”ç½‘ç»œå›¾</h6>", unsafe_allow_html=True)
                    # è¿™é‡Œå¯ä»¥æ·»åŠ ä¼ä¸šå…³è”ç½‘ç»œå¯è§†åŒ–ä»£ç 
                    st.info("ä¼ä¸šå…³è”ç½‘ç»œå›¾å°†åœ¨æ­¤æ˜¾ç¤º")
                
                else:  # äº§å“æŠ€æœ¯åˆ†æ
                    st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>äº§å“æŠ€æœ¯å…³è”å›¾</h6>", unsafe_allow_html=True)
                    # è¿™é‡Œå¯ä»¥æ·»åŠ äº§å“æŠ€æœ¯å…³è”å›¾å¯è§†åŒ–ä»£ç 
                    st.info("äº§å“æŠ€æœ¯å…³è”å›¾å°†åœ¨æ­¤æ˜¾ç¤º")

            with res_tab3:
                # æ•°æ®æ´å¯Ÿå±•ç¤ºé€»è¾‘
                # æ ¹æ®å®é™…æ•°æ®ç”Ÿæˆæ´å¯Ÿ
                insights = []
                
                # è·å–æ•°æ®ç»Ÿè®¡
                if analysis_data['type'] == "äº§ä¸šé“¾åˆ†æ" and analysis_data['results']:
                    industry_data = analysis_data['results'][0]
                    
                    # ç»Ÿè®¡æ•°æ®
                    companies_count = len(industry_data.get('companies', []))
                    products_count = len(industry_data.get('products', []))
                    upstream_count = len(industry_data.get('upstream', []))
                    downstream_count = len(industry_data.get('downstream', []))
                    
                    # ç”Ÿæˆæ´å¯Ÿ
                    if companies_count > 0:
                        insights.append(f"**ä¼ä¸šåˆ†å¸ƒ**ï¼š{analysis_data['industry']}è¡Œä¸šå…±æœ‰{companies_count}å®¶ç›¸å…³ä¼ä¸š")
                        
                        # å¢å¼ºï¼šä¼ä¸šé›†ä¸­åº¦åˆ†æ
                        if companies_count > 5:
                            insights.append(f"**ä¼ä¸šé›†ä¸­åº¦**ï¼šè¯¥è¡Œä¸šä¼ä¸šæ•°é‡è¾ƒå¤šï¼Œå¸‚åœºç«äº‰è¾ƒä¸ºå……åˆ†")
                        else:
                            insights.append(f"**ä¼ä¸šé›†ä¸­åº¦**ï¼šè¯¥è¡Œä¸šä¼ä¸šæ•°é‡è¾ƒå°‘ï¼Œå¯èƒ½å­˜åœ¨å¯¡å¤´ç«äº‰æ ¼å±€")
                    
                    if products_count > 0:
                        insights.append(f"**äº§å“åˆ†å¸ƒ**ï¼šè¯¥è¡Œä¸šæ¶‰åŠ{products_count}ç§äº§å“æˆ–æœåŠ¡")
                    
                    if upstream_count > 0 or downstream_count > 0:
                        insights.append(f"**äº§ä¸šé“¾ç»“æ„**ï¼šå‘ç°{upstream_count}ä¸ªä¸Šæ¸¸è¡Œä¸šå’Œ{downstream_count}ä¸ªä¸‹æ¸¸è¡Œä¸š")
                        
                        # å¢å¼ºï¼šäº§ä¸šé“¾ä½ç½®åˆ†æ
                        if upstream_count > 0 and downstream_count == 0:
                            insights.append(f"**äº§ä¸šé“¾ä½ç½®**ï¼šè¯¥è¡Œä¸šä½äºäº§ä¸šé“¾æœ«ç«¯ï¼Œä¸ºç»ˆç«¯æ¶ˆè´¹æˆ–åº”ç”¨è¡Œä¸š")
                        elif upstream_count == 0 and downstream_count > 0:
                            insights.append(f"**äº§ä¸šé“¾ä½ç½®**ï¼šè¯¥è¡Œä¸šä½äºäº§ä¸šé“¾æºå¤´ï¼Œä¸ºåŸºç¡€åŸææ–™æˆ–æŠ€æœ¯è¡Œä¸š")
                        else:
                            insights.append(f"**äº§ä¸šé“¾ä½ç½®**ï¼šè¯¥è¡Œä¸šä½äºäº§ä¸šé“¾ä¸­æ¸¸ï¼Œæ‰¿ä¸Šå¯ä¸‹")
                
                elif analysis_data['type'] == "ç«äº‰æƒ…æŠ¥åˆ†æ" and analysis_data['results']:
                    # ç»Ÿè®¡ç«äº‰å¯¹æ‰‹æ•°é‡
                    companies = set()
                    for item in analysis_data['results']:
                        companies.add(item.get('company1', ''))
                        companies.add(item.get('company2', ''))
                    
                    if companies:
                        insights.append(f"**ç«äº‰æ ¼å±€**ï¼š{analysis_data['industry']}è¡Œä¸šä¸­å‘ç°{len(companies)}å®¶ä¸»è¦ç«äº‰ä¼ä¸š")
                        
                        # å¢å¼ºï¼šç«äº‰å…³ç³»å¯†åº¦åˆ†æ
                        competition_pairs = len(analysis_data['results'])
                        max_pairs = len(companies) * (len(companies) - 1) / 2
                        competition_density = competition_pairs / max_pairs if max_pairs > 0 else 0
                        
                        if competition_density > 0.7:
                            insights.append(f"**ç«äº‰å¼ºåº¦**ï¼šç«äº‰å…³ç³»å¯†åº¦ä¸º{competition_density:.1%}ï¼Œå¸‚åœºç«äº‰æ¿€çƒˆ")
                        elif competition_density > 0.3:
                            insights.append(f"**ç«äº‰å¼ºåº¦**ï¼šç«äº‰å…³ç³»å¯†åº¦ä¸º{competition_density:.1%}ï¼Œå¸‚åœºç«äº‰è¾ƒä¸ºå……åˆ†")
                        else:
                            insights.append(f"**ç«äº‰å¼ºåº¦**ï¼šç«äº‰å…³ç³»å¯†åº¦ä¸º{competition_density:.1%}ï¼Œå¯èƒ½å­˜åœ¨ç»†åˆ†å¸‚åœºåŒºéš”")
                
                elif analysis_data['type'] == "ä¼ä¸šå…³è”åˆ†æ" and analysis_data['results']:
                    # ç»Ÿè®¡å…³ç³»ç±»å‹
                    rel_types = {}
                    for item in analysis_data['results']:
                        rel_type = item.get('relationship', 'æœªçŸ¥')
                        if rel_type not in rel_types:
                            rel_types[rel_type] = 0
                        rel_types[rel_type] += 1
                    
                    if rel_types:
                        main_rel_type = max(rel_types.items(), key=lambda x: x[1])[0]
                        insights.append(f"**å…³ç³»ç½‘ç»œ**ï¼šä¼ä¸šé—´ä¸»è¦é€šè¿‡'{main_rel_type}'å…³ç³»è¿›è¡Œè¿æ¥ï¼Œå…±{len(rel_types)}ç§å…³è”")
                        
                        # å¢å¼ºï¼šå…³ç³»å¤šæ ·æ€§åˆ†æ
                        if len(rel_types) > 3:
                            insights.append(f"**å…³ç³»å¤šæ ·æ€§**ï¼šä¼ä¸šé—´å­˜åœ¨{len(rel_types)}ç§ä¸åŒç±»å‹çš„å…³è”ï¼Œå…³ç³»ç½‘ç»œä¸°å¯Œå¤šæ ·")
                
                elif analysis_data['type'] == "äº§å“æŠ€æœ¯åˆ†æ" and analysis_data['results']:
                    # ç»Ÿè®¡äº§å“æ•°é‡å’Œå…³è”å¼ºåº¦
                    if analysis_data['results']:
                        product_count = len(analysis_data['results'])
                        avg_connections = sum(item.get('connection_count', 0) for item in analysis_data['results']) / product_count if product_count > 0 else 0
                        
                        insights.append(f"**äº§å“åˆ†æ**ï¼š{analysis_data['industry']}è¡Œä¸šæ¶‰åŠ{product_count}ç§ä¸»è¦äº§å“ï¼Œå¹³å‡æ¯ç§äº§å“æœ‰{avg_connections:.1f}ä¸ªå…³è”å®ä½“")
                        
                        # å¢å¼ºï¼šäº§å“å…³è”åº¦åˆ†æ
                        if avg_connections > 5:
                            insights.append(f"**äº§å“å…³è”åº¦**ï¼šäº§å“å¹³å‡å…³è”åº¦ä¸º{avg_connections:.1f}ï¼Œäº§å“é—´é›†æˆåº¦é«˜")
                        else:
                            insights.append(f"**äº§å“å…³è”åº¦**ï¼šäº§å“å¹³å‡å…³è”åº¦ä¸º{avg_connections:.1f}ï¼Œäº§å“ç›¸å¯¹ç‹¬ç«‹")
                        
                        # å¢å¼ºï¼šäº§å“æŠ€æœ¯è·¯å¾„åˆ†æ
                        if avg_connections > 0:
                            max_conn_item = max(analysis_data['results'], key=lambda x: x.get('connection_count', 0))
                            insights.append(f"**æ ¸å¿ƒäº§å“**ï¼š{max_conn_item.get('product', '')}æ˜¯è¯¥è¡Œä¸šå…³è”æœ€å¹¿æ³›çš„äº§å“ï¼Œå…±æœ‰{max_conn_item.get('connection_count', 0)}ä¸ªå…³è”å®ä½“")
                
                # å¦‚æœæ²¡æœ‰ç”Ÿæˆä»»ä½•æ´å¯Ÿï¼Œæ·»åŠ ä¸€ä¸ªé€šç”¨æç¤º
                if not insights:
                    insights.append("**æ•°æ®ä¸è¶³**ï¼šå½“å‰åˆ†æçš„æ•°æ®é‡ä¸è¶³ä»¥ç”Ÿæˆæœ‰æ„ä¹‰çš„æ´å¯Ÿã€‚è¯·å°è¯•é€‰æ‹©å…¶ä»–è¡Œä¸šæˆ–å¯¼å…¥æ›´å¤šæ•°æ®ã€‚")
                
                # æ˜¾ç¤ºæ´å¯Ÿ
                for insight in insights:
                    st.markdown(f"- {insight}")