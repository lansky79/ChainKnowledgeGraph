import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import traceback
import json
import io
import os
from datetime import datetime
import time
import pickle
import plotly.express as px
import logging
import sys
from build_graph import MedicalGraph
import streamlit_echarts as st_echarts
from kg_visualization import (
    get_entity_options,
    display_network_graph,
    display_hierarchy_tree,
    display_relationship_matrix,
    display_industry_chain
)
from kg_network_visualization import visualize_network, visualize_matrix
from src.neo4j_handler import Neo4jHandler, Config
from pathlib import Path

# æ£€æµ‹æ“ä½œç³»ç»Ÿ
import platform
is_windows = platform.system() == "Windows"

# ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
os.makedirs("logs", exist_ok=True)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join("logs", "app.log"), mode='a'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger("KG_Dashboard")

logger.info("å¯åŠ¨çŸ¥è¯†å›¾è°±æ•°æ®å¯¼å…¥å¯è§†åŒ–å·¥å…·")

# åŠ è½½é…ç½®æ–‡ä»¶
def load_config():
    try:
        # ä¼˜å…ˆåŠ è½½ä¸“ç”¨é…ç½®
        config_file = None
        if is_windows and os.path.exists('config_windows.json'):
            logger.info("åŠ è½½Windowsä¸“ç”¨é…ç½®æ–‡ä»¶")
            config_file = 'config_windows.json'
        # å¦‚æœæ²¡æœ‰ä¸“ç”¨é…ç½®ï¼ŒåŠ è½½é€šç”¨é…ç½®
        elif os.path.exists('config.json'):
            logger.info("åŠ è½½é€šç”¨é…ç½®æ–‡ä»¶")
            config_file = 'config.json'
        
        if config_file:
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            logger.warning("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return {
                "neo4j": {
                    "uri": "bolt://127.0.0.1:7687",
                    "username": "neo4j",
                    "password": "12345678"
                },
                "app": {
                    "title": "çŸ¥è¯†å›¾è°±æ•°æ®å¯¼å…¥å¯è§†åŒ–å·¥å…·",
                    "batch_size_default": 10000,
                    "batch_size_min": 1000,
                    "batch_size_max": 50000
                }
            }
    except Exception as e:
        logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        st.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return {}

# åŠ è½½é…ç½®
config = load_config()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="çŸ¥è¯†å›¾è°±æ•°æ®å¯¼å…¥å¯è§†åŒ–å·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# è‡ªå®šä¹‰CSSï¼Œä½¿ç•Œé¢æ›´ç´§å‡‘
st.markdown("""
<style>
    /* General container padding */
    .block-container {
        padding-top: 0.1rem; /* Reduced from 0.5rem */
        padding-bottom: 0.1rem; /* Reduced from 0.5rem */
        padding-left: 0.5rem; /* Add some horizontal padding */
        padding-right: 0.5rem; /* Add some horizontal padding */
    }
    /* Tabs styling */
    .stTabs [data-baseweb="tab-list"] {
        gap: 3px; /* Reduced gap */
    }
    .stTabs [data-baseweb="tab"] {
        height: 28px; /* Reduced height */
        white-space: pre-wrap;
        padding: 3px 8px; /* Reduced padding */
        font-size: 0.85rem; /* Slightly smaller font for tabs */
    }
    /* Sidebar width (if used, though collapsed) */
    div[data-testid="stSidebar"] {
        width: 180px !important; /* Slightly reduced */
    }
    /* Slider margins */
    div[role="slider"] {
        margin-top: 0.1rem; /* Reduced from 0.3rem */
        margin-bottom: 0.1rem; /* Reduced from 0.3rem */
    }
    /* Alert/Info/Warning messages */
    .stAlert {
        padding: 3px; /* Reduced from 5px */
        margin-top: 0.1rem; /* Reduced from 0.3rem */
        margin-bottom: 0.1rem; /* Reduced from 0.3rem */
        font-size: 0.85rem; /* Slightly smaller font */
    }
    /* Dataframe margins */
    .stDataFrame {
        margin-top: 0.1rem; /* Reduced from 0.3rem */
        margin-bottom: 0.1rem; /* Reduced from 0.3rem */
    }
    /* Button padding */
    .stButton button {
        width: 100%;
        padding: 1px 6px; /* Reduced from 2px 8px */
        font-size: 0.85rem; /* Slightly smaller font */
    }
    /* Markdown headings and text */
    .stMarkdown {
        margin-top: 0.1rem; /* Reduced from 0.2rem */
        margin-bottom: 0.1rem; /* Reduced from 0.2rem */
    }
    h1, h2, h3, h4, h5, h6 {
        margin-top: 0.1rem; /* Reduced from 0.3rem */
        margin-bottom: 0.1rem; /* Reduced from 0.3rem */
    }
    .stMarkdown h3 {
        font-size: 1.1rem; /* Slightly smaller */
    }
    .stMarkdown h4 {
        font-size: 0.95rem; /* Slightly smaller */
    }
    .stMarkdown h5 {
        font-size: 0.85rem; /* Slightly smaller */
        margin-top: 0.05rem; /* Reduced from 0.1rem */
        margin-bottom: 0.05rem; /* Reduced from 0.1rem */
    }
    .stMarkdown h6 {
        font-size: 0.8rem; /* Slightly smaller */
        margin-top: 0.05rem; /* Reduced from 0.1rem */
        margin-bottom: 0.05rem; /* Reduced from 0.1rem */
    }
    /* Element container margins */
    .element-container {
        margin-top: 0.1rem; /* Reduced from 0.2rem */
        margin-bottom: 0.1rem; /* Reduced from 0.2rem */
    }
    /* Selectbox and TextInput heights/margins */
    .stSelectbox, .stTextInput {
        margin-top: 0.1rem; /* Reduced from 0.2rem */
        margin-bottom: 0.1rem; /* Reduced from 0.2rem */
    }
    div[data-baseweb="select"], div[data-baseweb="input"] {
        min-height: 28px; /* Reduced from 32px */
        font-size: 0.85rem; /* Slightly smaller font */
    }
    /* Notification padding */
    div[data-baseweb="notification"] {
        padding: 0.2rem; /* Reduced from 0.3rem */
    }
    /* Echarts margins */
    .echarts-for-react {
        margin: 0 !important;
        padding: 0 !important;
    }
    /* Expander padding */
    .streamlit-expanderHeader {
        padding-top: 0.1rem; /* Reduced from 0.2rem */
        padding-bottom: 0.1rem; /* Reduced from 0.2rem */
        font-size: 0.85rem; /* Slightly smaller font */
    }
    .streamlit-expanderContent {
        padding-top: 0.1rem; /* Reduced from 0.2rem */
        padding-bottom: 0.1rem; /* Reduced from 0.2rem */
    }
    /* Slider height */
    div[data-testid="stSlider"] {
        padding-top: 0.1rem; /* Reduced from 0.2rem */
        padding-bottom: 0.1rem; /* Reduced from 0.2rem */
    }
    /* Metric component */
    div[data-testid="stMetric"] {
        padding: 0.1rem; /* Reduce padding */
    }
    div[data-testid="stMetricLabel"] {
        font-size: 0.8rem; /* Smaller label */
    }
    div[data-testid="stMetricValue"] {
        font-size: 1.2rem; /* Smaller value */
    }
    div[data-testid="stMetricDelta"] {
        font-size: 0.7rem; /* Smaller delta */
    }
    /* Plotly chart margins */
    .js-plotly-plot .plotly .modebar {
        margin-top: -20px; /* Move modebar up to save space */
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'import_history' not in st.session_state:
    st.session_state.import_history = []

if 'last_refresh' not in st.session_state:
    st.session_state.last_refresh = time.time()

if 'is_importing' not in st.session_state:
    st.session_state.is_importing = False

if 'error_message' not in st.session_state:
    st.session_state.error_message = None

# åˆ›å»ºMedicalGraphå®ä¾‹
@st.cache_resource
def get_graph_handler():
    logger.info("åˆå§‹åŒ–å›¾è°±å¤„ç†å™¨")
    try:
        return MedicalGraph()
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–å›¾è°±å¤„ç†å™¨å¤±è´¥: {e}")
        return None

# å°è¯•è·å–å›¾è°±å¤„ç†å™¨
try:
    logger.info("å°è¯•åˆå§‹åŒ–å›¾è°±å¤„ç†å™¨")
    handler = get_graph_handler()
    logger.info(f"å›¾è°±å¤„ç†å™¨åˆå§‹åŒ–ç»“æœ: {handler is not None}")
except Exception as e:
    logger.error(f"è·å–å›¾è°±å¤„ç†å™¨æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
    handler = None

# ä¸»é¡µé¢
st.markdown("<h3 style='font-size:1.2rem; margin-bottom:0.2rem;'>çŸ¥è¯†å›¾è°±æ•°æ®å¯¼å…¥å¯è§†åŒ–å·¥å…· <span style='font-size:0.8rem; color:#666;'>ç‰ˆæœ¬: 1.0</span></h3>", unsafe_allow_html=True)

# æ£€æŸ¥å›¾è°±å¤„ç†å™¨æ˜¯å¦æˆåŠŸåˆå§‹åŒ–
if handler is None:
    st.error("å›¾è°±å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥Neo4jè¿æ¥å’Œæ•°æ®æ–‡ä»¶ã€‚")
    st.warning("åº”ç”¨å°†ä»¥æœ‰é™åŠŸèƒ½æ¨¡å¼è¿è¡Œï¼Œè¯·ç¡®ä¿Neo4jæœåŠ¡å·²å¯åŠ¨ååˆ·æ–°é¡µé¢ã€‚")
    
    # æ˜¾ç¤ºNeo4jè¿æ¥è®¾ç½®
    st.subheader("Neo4jè¿æ¥è®¾ç½®")
    if os.path.exists('config_windows.json'):
        try:
            with open('config_windows.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                neo4j_config = config.get('neo4j', {})
                st.write(f"è¿æ¥URI: {neo4j_config.get('uri', 'bolt://127.0.0.1:7687')}")
                st.write(f"ç”¨æˆ·å: {neo4j_config.get('username', 'neo4j')}")
                st.write("å¯†ç : ********")
        except Exception as e:
            st.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    else:
        st.warning("æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ config_windows.json")
    
    # æä¾›Neo4jå¯åŠ¨æŒ‡å—
    with st.expander("Neo4jå¯åŠ¨æŒ‡å—", expanded=True):
        st.markdown("""
        ### å¯åŠ¨Neo4jæ•°æ®åº“çš„æ­¥éª¤
        
        1. **é€šè¿‡Neo4j Desktopå¯åŠ¨**:
           - æ‰“å¼€Neo4j Desktopåº”ç”¨
           - é€‰æ‹©æ‚¨çš„æ•°æ®åº“ï¼Œç‚¹å‡»"Start"æŒ‰é’®
           
        2. **é€šè¿‡WindowsæœåŠ¡å¯åŠ¨**:
           - æŒ‰Win+Ræ‰“å¼€è¿è¡Œå¯¹è¯æ¡†
           - è¾“å…¥`services.msc`å¹¶æŒ‰å›è½¦
           - æ‰¾åˆ°Neo4jæœåŠ¡ï¼Œå³é”®é€‰æ‹©"å¯åŠ¨"
           
        3. **é€šè¿‡å‘½ä»¤è¡Œå¯åŠ¨**:
           - æ‰“å¼€å‘½ä»¤æç¤ºç¬¦æˆ–PowerShell
           - å¯¼èˆªåˆ°Neo4jå®‰è£…ç›®å½•çš„binæ–‡ä»¶å¤¹
           - æ‰§è¡Œ`neo4j.bat console`å‘½ä»¤
        
        å¯åŠ¨Neo4jåï¼Œè¯·åˆ·æ–°æ­¤é¡µé¢ã€‚
        """)
    
    # åˆ·æ–°æŒ‰é’®
    if st.button("åˆ·æ–°é¡µé¢", key="refresh_page"):
        st.experimental_rerun()
    
    # ä¸å®Œå…¨åœæ­¢åº”ç”¨ï¼Œåªæ˜¯ä¸æ‰§è¡Œå¯¼å…¥ç›¸å…³åŠŸèƒ½
    st.info("åº”ç”¨ä»¥æœ‰é™åŠŸèƒ½æ¨¡å¼è¿è¡Œä¸­ï¼Œæ— æ³•æ‰§è¡Œæ•°æ®å¯¼å…¥æ“ä½œã€‚")
    st.stop()

# ç®€åŒ–ç‰ˆæœ¬çš„å¯¼å…¥çŠ¶æ€è·å–å‡½æ•°
def get_simple_import_status():
    try:
        # ä»handlerè·å–å¯¼å…¥çŠ¶æ€
        import_state = handler.import_state
        
        # æå–åŸºæœ¬ä¿¡æ¯
        node_types = ['company', 'industry', 'product']
        rel_types = ['company_industry', 'industry_industry', 'company_product', 'product_product']
        
        # èŠ‚ç‚¹çŠ¶æ€
        node_data = []
        total_nodes = 0
        imported_nodes = 0
        
        for node_type in node_types:
            if node_type in import_state:
                imported = import_state[node_type]
                imported_nodes += imported
                node_data.append({
                    "ç±»å‹": node_type,
                    "å·²å¯¼å…¥æ•°é‡": imported
                })
        
        # å…³ç³»çŠ¶æ€
        rel_data = []
        total_rels = 0
        imported_rels = 0
        
        for rel_type in rel_types:
            if rel_type in import_state:
                imported = import_state[rel_type]
                imported_rels += imported
                rel_data.append({
                    "ç±»å‹": rel_type,
                    "å·²å¯¼å…¥æ•°é‡": imported
                })
        
        return {
            "node_data": node_data,
            "rel_data": rel_data,
            "imported_nodes": imported_nodes,
            "imported_rels": imported_rels,
            "total_imported": imported_nodes + imported_rels
        }
    except Exception as e:
        logger.error(f"è·å–å¯¼å…¥çŠ¶æ€å¤±è´¥: {e}")
        st.session_state.error_message = f"è·å–å¯¼å…¥çŠ¶æ€å¤±è´¥: {str(e)}"
        return None

# ç®€åŒ–ç‰ˆæœ¬çš„å¯¼å…¥å‡½æ•°
def run_simple_import(batch_size):
    try:
        logger.info(f"å¼€å§‹å¯¼å…¥ä»»åŠ¡ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")
        st.session_state.is_importing = True
        st.session_state.error_message = None
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # åˆ›å»ºStreamlitè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
        def update_progress(current, total, message):
            if total > 0:
                progress = min(current / total, 1.0)
                progress_bar.progress(progress)
                status_text.text(f"{message}: {current}/{total} ({int(progress * 100)}%)")
        
        # è¿è¡Œå¯¼å…¥ - ä¿®å¤: ç¡®ä¿å…¼å®¹æ–¹æ³•è¢«æ­£ç¡®è°ƒç”¨
        logger.info("å¼€å§‹å¯¼å…¥èŠ‚ç‚¹...")
        status_text.text("æ­£åœ¨å¯¼å…¥èŠ‚ç‚¹...")
        node_count = handler.create_graphnodes(batch_size)
        logger.info(f"èŠ‚ç‚¹å¯¼å…¥å®Œæˆï¼Œæ•°é‡: {node_count}")
        
        # æ›´æ–°è¿›åº¦æ¡
        progress_bar.progress(0.5)
        status_text.text(f"èŠ‚ç‚¹å¯¼å…¥å®Œæˆï¼Œæ•°é‡: {node_count}ï¼Œæ­£åœ¨å¯¼å…¥å…³ç³»...")
        
        logger.info("å¼€å§‹å¯¼å…¥å…³ç³»...")
        rel_count = handler.create_graphrels(batch_size)
        logger.info(f"å…³ç³»å¯¼å…¥å®Œæˆï¼Œæ•°é‡: {rel_count}")
        
        # å®Œæˆè¿›åº¦æ¡
        progress_bar.progress(1.0)
        status_text.text(f"å¯¼å…¥å®Œæˆ! å…±å¯¼å…¥ {node_count} ä¸ªèŠ‚ç‚¹å’Œ {rel_count} æ¡å…³ç³»")
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        duration = end_time - start_time
        
        # æ·»åŠ åˆ°å†å²è®°å½•
        status = get_simple_import_status()
        if status:
            st.session_state.import_history.append({
                "æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "æ‰¹æ¬¡å¤§å°": batch_size,
                "å¯¼å…¥èŠ‚ç‚¹æ•°": node_count,
                "å¯¼å…¥å…³ç³»æ•°": rel_count,
                "è€—æ—¶(ç§’)": round(duration, 2)
            })
        
        # éªŒè¯å¯¼å…¥ç»“æœ - æ–°å¢éƒ¨åˆ†
        import_results = verify_import_results()
        st.session_state.last_import_results = import_results
        
        logger.info(f"å¯¼å…¥ä»»åŠ¡å®Œæˆï¼Œè€—æ—¶: {round(duration, 2)}ç§’")
        st.session_state.is_importing = False
        return True
    except Exception as e:
        error_msg = f"å¯¼å…¥ä»»åŠ¡å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        logger.error(error_msg)
        st.session_state.error_message = error_msg
        st.session_state.is_importing = False
        return False

# æ–°å¢: éªŒè¯å¯¼å…¥ç»“æœçš„å‡½æ•°
def verify_import_results():
    """éªŒè¯æ•°æ®å¯¼å…¥ç»“æœï¼Œè¿”å›å¯¼å…¥çš„æ–‡ä»¶å’ŒèŠ‚ç‚¹ä¿¡æ¯"""
    try:
        results = {
            "files": [],
            "node_counts": {},
            "sample_nodes": {},
            "total_nodes": 0,
            "total_rels": 0,
            "verification_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # è·å–å¯¼å…¥çš„æ–‡ä»¶åˆ—è¡¨
        if handler:
            data_files = {
                "company": handler.company_path,
                "industry": handler.industry_path,
                "product": handler.product_path,
                "company_industry": handler.company_industry_path,
                "industry_industry": handler.industry_industry,
                "company_product": handler.company_product_path,
                "product_product": handler.product_product
            }
            
            for file_type, file_path in data_files.items():
                if os.path.exists(file_path):
                    file_size = os.path.getsize(file_path) / 1024  # KB
                    results["files"].append({
                        "type": file_type,
                        "path": file_path,
                        "size": f"{file_size:.2f} KB"
                    })
        
        # è·å–å„ç±»å‹èŠ‚ç‚¹æ•°é‡å’Œç¤ºä¾‹
        node_types = ["company", "industry", "product"]
        for node_type in node_types:
            # è·å–èŠ‚ç‚¹æ•°é‡
            count_query = f"MATCH (n:{node_type}) RETURN count(n) as count"
            count_result = handler.g.run(count_query).data()
            node_count = count_result[0]["count"] if count_result else 0
            results["node_counts"][node_type] = node_count
            results["total_nodes"] += node_count
            
            # è·å–å‰50ä¸ªèŠ‚ç‚¹ç¤ºä¾‹
            sample_query = f"MATCH (n:{node_type}) RETURN n.name as name LIMIT 50"
            sample_results = handler.g.run(sample_query).data()
            results["sample_nodes"][node_type] = [node["name"] for node in sample_results]
        
        # è·å–å„ç±»å‹å…³ç³»æ•°é‡
        rel_types = ["å±äº", "æ‹¥æœ‰", "ä¸Šçº§è¡Œä¸š", "ä¸Šæ¸¸ææ–™", "ä¸»è¥äº§å“"]
        rel_count = 0
        for rel_type in rel_types:
            count_query = f"MATCH ()-[r:{rel_type}]->() RETURN count(r) as count"
            try:
                count_result = handler.g.run(count_query).data()
                if count_result:
                    rel_count += count_result[0]["count"]
            except:
                # å…³ç³»ç±»å‹å¯èƒ½ä¸å­˜åœ¨
                pass
        
        results["total_rels"] = rel_count
        
        return results
    except Exception as e:
        logger.error(f"éªŒè¯å¯¼å…¥ç»“æœæ—¶å‡ºé”™: {e}")
        return {"error": str(e)}

# æ–°å¢: æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ•°æ®éœ€è¦å¯¼å…¥
def check_remaining_data():
    """æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ•°æ®éœ€è¦å¯¼å…¥ï¼Œè¿”å›å‰©ä½™æ•°æ®æ•°é‡å’Œè¯¦ç»†ä¿¡æ¯"""
    try:
        # èŠ‚ç‚¹æ•°æ®
        node_files = {
            'company': handler.company_path,
            'industry': handler.industry_path,
            'product': handler.product_path
        }
        
        # å…³ç³»æ•°æ®
        rel_files = {
            'company_industry': handler.company_industry_path,
            'industry_industry': handler.industry_industry,
            'company_product': handler.company_product_path,
            'product_product': handler.product_product
        }
        
        remaining_data = {
            "nodes": {},
            "relationships": {},
            "total_remaining": 0,
            "verification_details": {}
        }
        
        # æ£€æŸ¥èŠ‚ç‚¹æ•°æ®
        for node_type, file_path in node_files.items():
            if os.path.exists(file_path):
                try:
                    # è·å–æ–‡ä»¶æ€»è¡Œæ•°
                    total_lines = handler._count_file_lines(file_path)
                    # è·å–å·²å¯¼å…¥è¡Œæ•°
                    imported = handler.import_state.get(node_type, 0)
                    # è®¡ç®—å‰©ä½™è¡Œæ•°
                    remaining = max(0, total_lines - imported)
                    
                    # æ·»åŠ éªŒè¯æ­¥éª¤ï¼šæ£€æŸ¥æ•°æ®åº“ä¸­å®é™…èŠ‚ç‚¹æ•°é‡
                    query = f"MATCH (n:{node_type}) RETURN count(n) as count"
                    result = handler.g.run(query).data()
                    actual_count = result[0]["count"] if result else 0
                    
                    # å¦‚æœå®é™…èŠ‚ç‚¹æ•°é‡ä¸å¯¼å…¥çŠ¶æ€ä¸ä¸€è‡´ï¼Œè°ƒæ•´å‰©ä½™æ•°é‡
                    if actual_count > imported:
                        logger.warning(f"{node_type}èŠ‚ç‚¹å¯¼å…¥çŠ¶æ€ä¸ä¸€è‡´ï¼šå¯¼å…¥çŠ¶æ€è®°å½•{imported}ä¸ªï¼Œå®é™…æ•°æ®åº“ä¸­æœ‰{actual_count}ä¸ª")
                        # æ›´æ–°å¯¼å…¥çŠ¶æ€ä»¥åŒ¹é…å®é™…æ•°æ®åº“çŠ¶æ€
                        handler.import_state[node_type] = actual_count
                        remaining = max(0, total_lines - actual_count)
                    
                    # è®°å½•éªŒè¯è¯¦æƒ…
                    remaining_data["verification_details"][node_type] = {
                        "total_lines": total_lines,
                        "imported_state": imported,
                        "actual_count": actual_count,
                        "remaining": remaining
                    }
                    
                    if remaining > 0:
                        remaining_data["nodes"][node_type] = remaining
                        remaining_data["total_remaining"] += remaining
                except Exception as e:
                    logger.error(f"æ£€æŸ¥{node_type}èŠ‚ç‚¹æ•°æ®æ—¶å‡ºé”™: {e}")
        
        # æ£€æŸ¥å…³ç³»æ•°æ®
        for rel_type, file_path in rel_files.items():
            if os.path.exists(file_path):
                try:
                    # è·å–æ–‡ä»¶æ€»è¡Œæ•°
                    total_lines = handler._count_file_lines(file_path)
                    # è·å–å·²å¯¼å…¥è¡Œæ•°
                    imported = handler.import_state.get(rel_type, 0)
                    # è®¡ç®—å‰©ä½™è¡Œæ•°
                    remaining = max(0, total_lines - imported)
                    
                    # æ·»åŠ éªŒè¯æ­¥éª¤ï¼šå°è¯•æ£€æŸ¥æ•°æ®åº“ä¸­å®é™…å…³ç³»æ•°é‡
                    # ç”±äºå…³ç³»ç±»å‹å¯èƒ½æœ‰å¤šç§ï¼Œè¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€åŒ–çš„æ–¹æ³•
                    actual_count = 0
                    if rel_type == 'company_industry':
                        query = "MATCH ()-[r:å±äº|éš¶å±|æ‰€å±|BELONGS_TO]->() RETURN count(r) as count"
                        result = handler.g.run(query).data()
                        actual_count = result[0]["count"] if result else 0
                    elif rel_type == 'industry_industry':
                        query = "MATCH (:industry)-[r]->(:industry) RETURN count(r) as count"
                        result = handler.g.run(query).data()
                        actual_count = result[0]["count"] if result else 0
                    elif rel_type == 'company_product':
                        query = "MATCH (:company)-[r:æ‹¥æœ‰|ç”Ÿäº§|ä¸»è¥|OWNS|PRODUCES]->(:product) RETURN count(r) as count"
                        result = handler.g.run(query).data()
                        actual_count = result[0]["count"] if result else 0
                    elif rel_type == 'product_product':
                        query = "MATCH (:product)-[r]->(:product) RETURN count(r) as count"
                        result = handler.g.run(query).data()
                        actual_count = result[0]["count"] if result else 0
                    
                    # å¦‚æœå®é™…å…³ç³»æ•°é‡ä¸å¯¼å…¥çŠ¶æ€ä¸ä¸€è‡´ï¼Œè°ƒæ•´å‰©ä½™æ•°é‡
                    if actual_count > imported:
                        logger.warning(f"{rel_type}å…³ç³»å¯¼å…¥çŠ¶æ€ä¸ä¸€è‡´ï¼šå¯¼å…¥çŠ¶æ€è®°å½•{imported}æ¡ï¼Œå®é™…æ•°æ®åº“ä¸­æœ‰{actual_count}æ¡")
                        # æ›´æ–°å¯¼å…¥çŠ¶æ€ä»¥åŒ¹é…å®é™…æ•°æ®åº“çŠ¶æ€
                        handler.import_state[rel_type] = actual_count
                        remaining = max(0, total_lines - actual_count)
                    
                    # è®°å½•éªŒè¯è¯¦æƒ…
                    remaining_data["verification_details"][rel_type] = {
                        "total_lines": total_lines,
                        "imported_state": imported,
                        "actual_count": actual_count,
                        "remaining": remaining
                    }
                    
                    if remaining > 0:
                        remaining_data["relationships"][rel_type] = remaining
                        remaining_data["total_remaining"] += remaining
                except Exception as e:
                    logger.error(f"æ£€æŸ¥{rel_type}å…³ç³»æ•°æ®æ—¶å‡ºé”™: {e}")
        
        # ä¿å­˜æ›´æ–°åçš„å¯¼å…¥çŠ¶æ€
        handler.save_import_state()
        
        return remaining_data
    except Exception as e:
        logger.error(f"æ£€æŸ¥å‰©ä½™æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        return {"error": str(e), "total_remaining": 0}

# åˆ›å»ºé€‰é¡¹å¡
tab1, tab2, tab3, tab4, tab5 = st.tabs(["å¯¼å…¥çŠ¶æ€", "æ“ä½œæ§åˆ¶", "å›¾è°±æ¢ç´¢", "å›¾è°±å¯è§†åŒ–", "è¡Œä¸šé“¾åˆ†æ"])

with tab1:
    status = get_simple_import_status()
    
    if status:
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>å¯¼å…¥æ‘˜è¦</h5>", unsafe_allow_html=True)
        metrics_cols = st.columns(3)
        with metrics_cols[0]:
            st.metric("å·²å¯¼å…¥èŠ‚ç‚¹æ€»æ•°", f"{status['imported_nodes']:,}")
        with metrics_cols[1]:
            st.metric("å·²å¯¼å…¥å…³ç³»æ€»æ•°", f"{status['imported_rels']:,}")
        with metrics_cols[2]:
            st.metric("æ€»å¯¼å…¥æ•°æ®é‡", f"{status['total_imported']:,}")
        
        main_col1, main_col2 = st.columns([1, 1]) # New main columns for tables and charts
        
        with main_col1:
            st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>èŠ‚ç‚¹å¯¼å…¥è¯¦æƒ…</h6>", unsafe_allow_html=True)
            if status["node_data"]:
                st.dataframe(pd.DataFrame(status["node_data"]), height=130, use_container_width=True)
            else:
                st.info("æš‚æ— èŠ‚ç‚¹å¯¼å…¥æ•°æ®")
            
            st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>å…³ç³»å¯¼å…¥è¯¦æƒ…</h6>", unsafe_allow_html=True)
            if status["rel_data"]:
                st.dataframe(pd.DataFrame(status["rel_data"]), height=130, use_container_width=True)
            else:
                st.info("æš‚æ— å…³ç³»å¯¼å…¥æ•°æ®")
        
        with main_col2:
            if status and (status["node_data"] or status["rel_data"]):
                chart_tabs = st.tabs(["èŠ‚ç‚¹ç»Ÿè®¡", "å…³ç³»ç»Ÿè®¡"])
                
                with chart_tabs[0]:
                    if status["node_data"]:
                        df = pd.DataFrame(status["node_data"])
                        fig = px.bar(
                            df,
                            x="ç±»å‹",
                            y="å·²å¯¼å…¥æ•°é‡",
                            title="å„ç±»å‹èŠ‚ç‚¹å¯¼å…¥æ•°é‡",
                            height=320,  # Adjusted height to fill space
                            text_auto=True
                        )
                        fig.update_layout(margin=dict(l=0, r=0, t=30, b=0))
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("æš‚æ— èŠ‚ç‚¹æ•°æ®å¯ä¾›å¯è§†åŒ–")
                    
                with chart_tabs[1]:
                    if status["rel_data"]:
                        df = pd.DataFrame(status["rel_data"])
                        fig = px.bar(
                            df,
                            x="ç±»å‹",
                            y="å·²å¯¼å…¥æ•°é‡",
                            title="å„ç±»å‹å…³ç³»å¯¼å…¥æ•°é‡",
                            height=320,  # Adjusted height to fill space
                            text_auto=True
                        )
                        fig.update_layout(margin=dict(l=0, r=0, t=30, b=0))
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("æš‚æ— å…³ç³»æ•°æ®å¯ä¾›å¯è§†åŒ–")
    else:
        st.info("æš‚æ— å¯¼å…¥çŠ¶æ€æ•°æ®ã€‚è¯·å°è¯•å¯¼å…¥æ•°æ®ã€‚")

with tab2:
    # ä½¿ç”¨ä¸¤åˆ—å¸ƒå±€
    col_controls, col_history = st.columns([1, 1])
    
    with col_controls:
        # ä¸€ä¸ªæ›´ç´§å‡‘çš„æ§åˆ¶é¢æ¿
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>æ“ä½œæ§åˆ¶</h5>", unsafe_allow_html=True)
        
        # æ‰¹æ¬¡å¤§å°è®¾ç½®ï¼Œä½¿ç”¨æ›´å°çš„é—´è·
        batch_size = st.slider(
            "æ‰¹æ¬¡å¤§å°", 
            min_value=config["app"].get("batch_size_min", 1000),
            max_value=config["app"].get("batch_size_max", 50000),
            value=config["app"].get("batch_size_default", 10000),
            step=1000
        )
        
        # å¹¶æ’æ”¾ç½®æŒ‰é’®
        col_start, col_refresh = st.columns(2)
        
        with col_start:
            # æ·»åŠ æ›´è¯¦ç»†çš„æç¤º
            import_help = "å¯¼å…¥æŒ‡å®šæ‰¹æ¬¡å¤§å°çš„èŠ‚ç‚¹å’Œå…³ç³»æ•°æ®åˆ°Neo4jæ•°æ®åº“"
            if st.button("å¼€å§‹å¯¼å…¥", disabled=st.session_state.is_importing, key="start_btn", use_container_width=True, help=import_help):
                with st.spinner('æ­£åœ¨å¯¼å…¥æ•°æ®ï¼Œè¯·ç¨å€™...'):
                    try:
                        # é¦–å…ˆæ£€æŸ¥Neo4jè¿æ¥æ˜¯å¦æˆåŠŸåˆå§‹åŒ–
                        if handler.g is None:
                            error_msg = "Neo4jè¿æ¥æœªæˆåŠŸåˆå§‹åŒ–ï¼Œè¯·ç¡®ä¿Neo4jæ•°æ®åº“å·²å¯åŠ¨"
                            logger.error(error_msg)
                            st.session_state.error_message = error_msg
                            st.error(error_msg)
                        # å¦‚æœè¿æ¥æˆåŠŸï¼Œå†æ£€æŸ¥è¿æ¥æ˜¯å¦æœ‰æ•ˆ
                        elif handler.g:  # ç®€å•æ£€æŸ¥è¿æ¥å¯¹è±¡æ˜¯å¦å­˜åœ¨ï¼Œè€Œä¸æ˜¯è°ƒç”¨exists()æ–¹æ³•
                            try:
                                # å°è¯•æ‰§è¡Œä¸€ä¸ªç®€å•çš„CypheræŸ¥è¯¢æ¥éªŒè¯è¿æ¥
                                handler.g.run("RETURN 1 AS test").data()
                                logger.info("Neo4jæ•°æ®åº“è¿æ¥æ­£å¸¸ï¼Œå¼€å§‹å¯¼å…¥æµç¨‹")
                                
                                # æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®éœ€è¦å¯¼å…¥
                                remaining_data = check_remaining_data()
                                if remaining_data.get("total_remaining", 0) == 0:
                                    st.info("æ‰€æœ‰æ•°æ®å·²å¯¼å…¥å®Œæˆï¼Œæ— éœ€å†æ¬¡å¯¼å…¥")
                                    
                                    # æ˜¾ç¤ºå½“å‰æ•°æ®åº“çŠ¶æ€æ‘˜è¦
                                    import_results = verify_import_results()
                                    if "error" not in import_results:
                                        st.success(f"æ•°æ®åº“ä¸­å·²æœ‰ {import_results['total_nodes']} ä¸ªèŠ‚ç‚¹å’Œ {import_results['total_rels']} æ¡å…³ç³»")
                                    
                                    # æä¾›å¯¼å…¥ç¤ºä¾‹æ•°æ®çš„å»ºè®®
                                    if import_results.get('total_nodes', 0) == 0:
                                        st.info("æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ã€‚æ‚¨å¯ä»¥åœ¨'å›¾è°±æ¢ç´¢'æ ‡ç­¾é¡µä¸­ç‚¹å‡»'å¯¼å…¥ç¤ºä¾‹æ•°æ®'æŒ‰é’®æ·»åŠ ä¸€äº›ç¤ºä¾‹æ•°æ®è¿›è¡Œæµ‹è¯•ã€‚")
                                else:
                                    # æ˜¾ç¤ºå‰©ä½™æ•°æ®ä¿¡æ¯
                                    st.info(f"å‘ç° {remaining_data['total_remaining']} æ¡æ•°æ®å¾…å¯¼å…¥")
                                    
                                    # å¦‚æœæœ‰æ•°æ®éœ€è¦å¯¼å…¥ï¼Œåˆ™æ‰§è¡Œå¯¼å…¥
                                    success = run_simple_import(batch_size)
                                    if success:
                                        st.success(f"æˆåŠŸå¯¼å…¥ä¸€æ‰¹æ•°æ®ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")
                                    else:
                                        st.error("å¯¼å…¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æŸ¥çœ‹ä¸‹æ–¹é”™è¯¯ä¿¡æ¯")
                            except Exception as e:
                                error_msg = f"Neo4jæ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}"
                                logger.error(error_msg)
                                st.session_state.error_message = error_msg
                                st.error(error_msg)
                        else:
                            error_msg = "æ— æ³•è¿æ¥åˆ°Neo4jæ•°æ®åº“ï¼Œè¯·ç¡®ä¿æ•°æ®åº“å·²å¯åŠ¨"
                            logger.error(error_msg)
                            st.session_state.error_message = error_msg
                            st.error(error_msg)
                    except Exception as e:
                        error_msg = f"å¯¼å…¥å‰æ£€æŸ¥å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
                        logger.error(error_msg)
                        st.session_state.error_message = error_msg
                        st.error("å¯¼å…¥å‰æ£€æŸ¥å¤±è´¥ï¼Œè¯·æŸ¥çœ‹é”™è¯¯è¯¦æƒ…")
        
        with col_refresh:
            refresh_help = "åˆ·æ–°é¡µé¢æ˜¾ç¤ºæœ€æ–°çš„å¯¼å…¥çŠ¶æ€"
            if st.button("åˆ·æ–°çŠ¶æ€", key="refresh_btn", use_container_width=True, help=refresh_help):
                st.session_state.last_refresh = time.time()
                st.experimental_rerun()
        
        # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        if st.session_state.error_message:
            with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…", expanded=False):  # é»˜è®¤æŠ˜å é”™è¯¯ä¿¡æ¯
                st.error(st.session_state.error_message)
                if st.button("æ¸…é™¤é”™è¯¯ä¿¡æ¯"):
                    st.session_state.error_message = None
                    st.experimental_rerun()
        
        # é«˜çº§é€‰é¡¹ä½œä¸ºæŠ˜å é¢æ¿
        with st.expander("é«˜çº§é€‰é¡¹", expanded=False):
            st.warning("è­¦å‘Šï¼šé‡ç½®å¯¼å…¥çŠ¶æ€å°†æ¸…é™¤æ‰€æœ‰å¯¼å…¥è¿›åº¦ï¼Œæ— æ³•æ¢å¤ï¼")
            if st.button("é‡ç½®å¯¼å…¥çŠ¶æ€", key="reset_btn"):
                confirm = st.text_input("è¾“å…¥'ç¡®è®¤'ä»¥é‡ç½®æ‰€æœ‰å¯¼å…¥çŠ¶æ€ï¼ˆè¿™å°†æ¸…é™¤æ‰€æœ‰å¯¼å…¥è¿›åº¦ï¼‰:")
                if confirm == "ç¡®è®¤":
                    try:
                        handler.reset_import_state()
                        st.success("å¯¼å…¥çŠ¶æ€å·²é‡ç½®")
                        st.session_state.import_history = []
                        st.experimental_rerun()
                    except Exception as e:
                        st.error(f"é‡ç½®å¯¼å…¥çŠ¶æ€å¤±è´¥: {e}")
            
            # æ–°å¢ï¼šæ•°æ®åº“å®Œå…¨é‡ç½®åŠŸèƒ½
            st.error("å±é™©æ“ä½œï¼šé‡ç½®Neo4jæ•°æ®åº“å°†åˆ é™¤æ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»ï¼")
            if st.button("é‡ç½®Neo4jæ•°æ®åº“", key="reset_db_btn"):
                confirm_db = st.text_input("è¾“å…¥'æˆ‘ç¡®è®¤åˆ é™¤æ‰€æœ‰æ•°æ®'ä»¥é‡ç½®Neo4jæ•°æ®åº“ï¼ˆæ­¤æ“ä½œå°†åˆ é™¤æ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»ï¼Œæ— æ³•æ¢å¤ï¼‰:")
                if confirm_db == "æˆ‘ç¡®è®¤åˆ é™¤æ‰€æœ‰æ•°æ®":
                    try:
                        # æ‰§è¡Œæ¸…ç©ºæ•°æ®åº“çš„CypheræŸ¥è¯¢
                        handler.g.run("MATCH (n) DETACH DELETE n")
                        # é‡ç½®å¯¼å…¥çŠ¶æ€
                        handler.reset_import_state()
                        st.success("Neo4jæ•°æ®åº“å·²é‡ç½®ï¼Œæ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»å·²åˆ é™¤")
                        st.session_state.import_history = []
                        # æ·»åŠ ä¸€ä¸ªç©ºçš„å¯¼å…¥ç»“æœè®°å½•
                        st.session_state.last_import_results = {
                            "files": [],
                            "node_counts": {"company": 0, "industry": 0, "product": 0},
                            "sample_nodes": {"company": [], "industry": [], "product": []},
                            "total_nodes": 0,
                            "total_rels": 0,
                            "verification_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        }
                        st.experimental_rerun()
                    except Exception as e:
                        st.error(f"é‡ç½®Neo4jæ•°æ®åº“å¤±è´¥: {str(e)}")
            
            # æ–°å¢ï¼šæ¸…ç†å¯¼å…¥æ•°æ®åº“å‰çš„æµ‹è¯•æ•°æ®
            st.warning("æ¸…ç†æµ‹è¯•æ•°æ®ï¼šåˆ é™¤ç³»ç»Ÿè‡ªåŠ¨åˆ›å»ºçš„ç¤ºä¾‹æ•°æ®ï¼ˆåä¸ºã€é˜¿é‡Œå·´å·´ç­‰ï¼‰")
            if st.button("æ¸…ç†ç¤ºä¾‹æ•°æ®", key="clean_samples_btn"):
                try:
                    # åˆ é™¤ç¤ºä¾‹å…¬å¸èŠ‚ç‚¹
                    sample_companies = ["é˜¿é‡Œå·´å·´", "è…¾è®¯", "ç™¾åº¦", "åä¸º", "å°ç±³", "äº¬ä¸œ", "ç½‘æ˜“", "ç¾å›¢", "å­—èŠ‚è·³åŠ¨", "æ‹¼å¤šå¤š"]
                    for company in sample_companies:
                        handler.g.run(f"MATCH (c:company {{name: '{company}'}}) DETACH DELETE c")
                    
                    # åˆ é™¤ç¤ºä¾‹è¡Œä¸šå’Œäº§å“èŠ‚ç‚¹
                    handler.g.run("MATCH (i:industry) WHERE i.name IN ['äº’è”ç½‘', 'ç”µå­å•†åŠ¡', 'äººå·¥æ™ºèƒ½', 'é€šä¿¡', 'æ™ºèƒ½ç¡¬ä»¶'] DETACH DELETE i")
                    handler.g.run("MATCH (p:product) WHERE p.name IN ['æ·˜å®', 'å¾®ä¿¡', 'ç™¾åº¦æœç´¢', 'åä¸ºæ‰‹æœº', 'å°ç±³æ‰‹æœº'] DETACH DELETE p")
                    
                    st.success("ç¤ºä¾‹æ•°æ®å·²æ¸…ç†å®Œæˆ")
                    # åˆ·æ–°å¯¼å…¥ç»“æœ
                    if 'last_import_results' in st.session_state:
                        st.session_state.last_import_results = verify_import_results()
                    st.experimental_rerun()
                except Exception as e:
                    st.error(f"æ¸…ç†ç¤ºä¾‹æ•°æ®å¤±è´¥: {str(e)}")
        
        # æ·»åŠ å¯¼å…¥ç»“æœæ˜¾ç¤ºéƒ¨åˆ†
        if 'last_import_results' in st.session_state:
            with st.expander("æŸ¥çœ‹æœ€è¿‘å¯¼å…¥ç»“æœ", expanded=True):
                results = st.session_state.last_import_results
                
                if "error" in results:
                    st.error(f"è·å–å¯¼å…¥ç»“æœæ—¶å‡ºé”™: {results['error']}")
                else:
                    st.success(f"å¯¼å…¥éªŒè¯æ—¶é—´: {results['verification_time']}")
                    
                    # æ˜¾ç¤ºå¯¼å…¥æ–‡ä»¶ä¿¡æ¯
                    st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>å¯¼å…¥çš„æ•°æ®æ–‡ä»¶</h6>", unsafe_allow_html=True)
                    file_data = []
                    for file_info in results["files"]:
                        file_data.append({
                            "æ–‡ä»¶ç±»å‹": file_info["type"],
                            "æ–‡ä»¶è·¯å¾„": file_info["path"],
                            "æ–‡ä»¶å¤§å°": file_info["size"]
                        })
                    st.dataframe(pd.DataFrame(file_data), use_container_width=True)
                    
                    # æ˜¾ç¤ºèŠ‚ç‚¹æ•°é‡ç»Ÿè®¡
                    st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>èŠ‚ç‚¹æ•°é‡ç»Ÿè®¡</h6>", unsafe_allow_html=True)
                    cols = st.columns(len(results["node_counts"]) + 1)
                    
                    for i, (node_type, count) in enumerate(results["node_counts"].items()):
                        with cols[i]:
                            st.metric(f"{node_type}èŠ‚ç‚¹æ•°", f"{count:,}")
                    
                    with cols[-1]:
                        st.metric("æ€»èŠ‚ç‚¹æ•°", f"{results['total_nodes']:,}")
                    
                    # æ˜¾ç¤ºå‰50ä¸ªèŠ‚ç‚¹ç¤ºä¾‹
                    st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>èŠ‚ç‚¹ç¤ºä¾‹ (å‰50ä¸ª)</h6>", unsafe_allow_html=True)
                    node_tabs = st.tabs(list(results["sample_nodes"].keys()))
                    
                    for i, (node_type, samples) in enumerate(results["sample_nodes"].items()):
                        with node_tabs[i]:
                            if samples:
                                sample_text = ", ".join(samples)
                                st.write(sample_text)
                            else:
                                st.info(f"æ²¡æœ‰æ‰¾åˆ°{node_type}ç±»å‹çš„èŠ‚ç‚¹")
                                
                    # æ˜¾ç¤ºå…³ç³»æ•°é‡
                    st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>å…³ç³»ç»Ÿè®¡</h6>", unsafe_allow_html=True)
                    st.metric("æ€»å…³ç³»æ•°", f"{results['total_rels']:,}")
    
    with col_history:
        # å¯¼å…¥å†å²
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>å¯¼å…¥å†å²</h5>", unsafe_allow_html=True)
        if st.session_state.import_history:
            # åˆ›å»ºä¸€ä¸ªæ›´ç´§å‡‘çš„æ•°æ®æ¡†ï¼Œå‡å°é«˜åº¦
            history_df = pd.DataFrame(st.session_state.import_history)
            st.dataframe(history_df, use_container_width=True, height=150)
            
            # æ·»åŠ æ¸…é™¤å†å²æŒ‰é’®
            if st.button("æ¸…é™¤å†å²è®°å½•", key="clear_history"):
                st.session_state.import_history = []
                st.experimental_rerun()
        else:
            st.info("æš‚æ— å¯¼å…¥å†å²è®°å½•")

with tab3:
    st.markdown("<h4 style='font-size:1rem; margin:0.1rem 0;'>å›¾è°±æ¢ç´¢</h4>", unsafe_allow_html=True)
    
    # åˆ›å»ºå·¦å³ä¸¤åˆ—ä¸»å¸ƒå±€ï¼Œç»™å³ä¾§æ›´å¤šç©ºé—´
    main_cols = st.columns([1, 2])
    
    with main_cols[0]:  # å·¦ä¾§æ“ä½œåŒº
        # åˆ›å»ºå‚ç›´åˆ†åŒºï¼Œå°†åŸæœ¬çºµå‘æ’åˆ—çš„æ§ä»¶åˆ†æˆä¸Šä¸‹ä¸¤å—ï¼šå®ä½“æœç´¢å’Œå…³ç³»æ¢ç´¢
        # æ·»åŠ ä¸€ä¸ªå¯¼å…¥ç¤ºä¾‹æ•°æ®çš„æŒ‰é’®
        if st.button("å¯¼å…¥ç¤ºä¾‹æ•°æ®", key="import_samples", help="å¯¼å…¥é¢„å®šä¹‰çš„ç¤ºä¾‹æ•°æ®åˆ°Neo4j", use_container_width=True):
            with st.spinner("æ­£åœ¨å¯¼å…¥ç¤ºä¾‹æ•°æ®..."):
                try:
                    # é‡ç½®å¯¼å…¥çŠ¶æ€
                    handler.reset_import_state()
                    
                    # å®šä¹‰çœŸå®å…¬å¸ç¤ºä¾‹æ•°æ®
                    company_data = [
                        {"name": "é˜¿é‡Œå·´å·´", "description": "ä¸­å›½é¢†å…ˆçš„ç”µå­å•†åŠ¡å…¬å¸"},
                        {"name": "è…¾è®¯", "description": "ä¸­å›½é¢†å…ˆçš„äº’è”ç½‘æœåŠ¡æä¾›å•†"},
                        {"name": "ç™¾åº¦", "description": "ä¸­å›½é¢†å…ˆçš„æœç´¢å¼•æ“å…¬å¸"},
                        {"name": "åä¸º", "description": "å…¨çƒé¢†å…ˆçš„é€šä¿¡è®¾å¤‡åˆ¶é€ å•†"},
                        {"name": "å°ç±³", "description": "ä¸­å›½é¢†å…ˆçš„æ™ºèƒ½æ‰‹æœºåˆ¶é€ å•†"},
                        {"name": "äº¬ä¸œ", "description": "ä¸­å›½é¢†å…ˆçš„ç”µå­å•†åŠ¡å¹³å°"},
                        {"name": "ç½‘æ˜“", "description": "ä¸­å›½é¢†å…ˆçš„äº’è”ç½‘ç§‘æŠ€å…¬å¸"},
                        {"name": "ç¾å›¢", "description": "ä¸­å›½é¢†å…ˆçš„ç”Ÿæ´»æœåŠ¡ç”µå­å•†åŠ¡å¹³å°"},
                        {"name": "å­—èŠ‚è·³åŠ¨", "description": "ä¸­å›½é¢†å…ˆçš„äº’è”ç½‘ç§‘æŠ€å…¬å¸"},
                        {"name": "æ‹¼å¤šå¤š", "description": "ä¸­å›½é¢†å…ˆçš„ç”µå­å•†åŠ¡å¹³å°"}
                    ]
                    
                    # å®šä¹‰è¡Œä¸šç¤ºä¾‹æ•°æ®
                    industry_data = [
                        {"name": "äº’è”ç½‘", "description": "äº’è”ç½‘è¡Œä¸š"},
                        {"name": "ç”µå­å•†åŠ¡", "description": "ç”µå­å•†åŠ¡è¡Œä¸š"},
                        {"name": "äººå·¥æ™ºèƒ½", "description": "äººå·¥æ™ºèƒ½è¡Œä¸š"},
                        {"name": "é€šä¿¡", "description": "é€šä¿¡è¡Œä¸š"},
                        {"name": "æ™ºèƒ½ç¡¬ä»¶", "description": "æ™ºèƒ½ç¡¬ä»¶è¡Œä¸š"}
                    ]
                    
                    # å®šä¹‰äº§å“ç¤ºä¾‹æ•°æ®
                    product_data = [
                        {"name": "æ·˜å®", "description": "é˜¿é‡Œå·´å·´æ——ä¸‹ç”µå­å•†åŠ¡å¹³å°"},
                        {"name": "å¾®ä¿¡", "description": "è…¾è®¯æ——ä¸‹ç¤¾äº¤é€šè®¯è½¯ä»¶"},
                        {"name": "ç™¾åº¦æœç´¢", "description": "ç™¾åº¦æ——ä¸‹æœç´¢å¼•æ“"},
                        {"name": "åä¸ºæ‰‹æœº", "description": "åä¸ºç”Ÿäº§çš„æ™ºèƒ½æ‰‹æœº"},
                        {"name": "å°ç±³æ‰‹æœº", "description": "å°ç±³ç”Ÿäº§çš„æ™ºèƒ½æ‰‹æœº"}
                    ]
                    
                    # å®šä¹‰å…¬å¸-è¡Œä¸šå…³ç³»
                    company_industry_data = [
                        {"company_name": "é˜¿é‡Œå·´å·´", "industry_name": "äº’è”ç½‘", "rel": "å±äº"},
                        {"company_name": "é˜¿é‡Œå·´å·´", "industry_name": "ç”µå­å•†åŠ¡", "rel": "å±äº"},
                        {"company_name": "è…¾è®¯", "industry_name": "äº’è”ç½‘", "rel": "å±äº"},
                        {"company_name": "ç™¾åº¦", "industry_name": "äº’è”ç½‘", "rel": "å±äº"},
                        {"company_name": "ç™¾åº¦", "industry_name": "äººå·¥æ™ºèƒ½", "rel": "å±äº"},
                        {"company_name": "åä¸º", "industry_name": "é€šä¿¡", "rel": "å±äº"},
                        {"company_name": "åä¸º", "industry_name": "æ™ºèƒ½ç¡¬ä»¶", "rel": "å±äº"},
                        {"company_name": "å°ç±³", "industry_name": "æ™ºèƒ½ç¡¬ä»¶", "rel": "å±äº"}
                    ]
                    
                    # å®šä¹‰å…¬å¸-äº§å“å…³ç³»
                    company_product_data = [
                        {"company_name": "é˜¿é‡Œå·´å·´", "product_name": "æ·˜å®", "rel": "æ‹¥æœ‰", "rel_weight": "100%"},
                        {"company_name": "è…¾è®¯", "product_name": "å¾®ä¿¡", "rel": "æ‹¥æœ‰", "rel_weight": "100%"},
                        {"company_name": "ç™¾åº¦", "product_name": "ç™¾åº¦æœç´¢", "rel": "æ‹¥æœ‰", "rel_weight": "100%"},
                        {"company_name": "åä¸º", "product_name": "åä¸ºæ‰‹æœº", "rel": "ç”Ÿäº§", "rel_weight": "100%"},
                        {"company_name": "å°ç±³", "product_name": "å°ç±³æ‰‹æœº", "rel": "ç”Ÿäº§", "rel_weight": "100%"}
                    ]
                    
                    # ç›´æ¥ä½¿ç”¨Neo4jæ‰¹é‡åˆ›å»ºèŠ‚ç‚¹å’Œå…³ç³»
                    # åˆ›å»ºå…¬å¸èŠ‚ç‚¹
                    handler.g.run("""
                    UNWIND $data AS row
                    MERGE (c:company {name: row.name})
                    ON CREATE SET c.description = row.description
                    """, data=company_data)
                    
                    # åˆ›å»ºè¡Œä¸šèŠ‚ç‚¹
                    handler.g.run("""
                    UNWIND $data AS row
                    MERGE (i:industry {name: row.name})
                    ON CREATE SET i.description = row.description
                    """, data=industry_data)
                    
                    # åˆ›å»ºäº§å“èŠ‚ç‚¹
                    handler.g.run("""
                    UNWIND $data AS row
                    MERGE (p:product {name: row.name})
                    ON CREATE SET p.description = row.description
                    """, data=product_data)
                    
                    # åˆ›å»ºå…¬å¸-è¡Œä¸šå…³ç³»
                    handler.g.run("""
                    UNWIND $data AS row
                    MATCH (c:company {name: row.company_name})
                    MATCH (i:industry {name: row.industry_name})
                    MERGE (c)-[r:å±äº]->(i)
                    """, data=company_industry_data)
                    
                    # åˆ›å»ºå…¬å¸-äº§å“å…³ç³»
                    handler.g.run("""
                    UNWIND $data AS row
                    MATCH (c:company {name: row.company_name})
                    MATCH (p:product {name: row.product_name})
                    MERGE (c)-[r:æ‹¥æœ‰ {æƒé‡: row.rel_weight}]->(p)
                    """, data=company_product_data)
                    
                    # æ›´æ–°å¯¼å…¥çŠ¶æ€
                    total_nodes = len(company_data) + len(industry_data) + len(product_data)
                    total_rels = len(company_industry_data) + len(company_product_data)
                    
                    st.success(f"æˆåŠŸå¯¼å…¥ç¤ºä¾‹æ•°æ®: {total_nodes} ä¸ªèŠ‚ç‚¹å’Œ {total_rels} æ¡å…³ç³»")
                    
                    # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹å®ä½“
                    st.info("ç°åœ¨æ‚¨å¯ä»¥æœç´¢ä»¥ä¸‹ç¤ºä¾‹å®ä½“: é˜¿é‡Œå·´å·´, è…¾è®¯, ç™¾åº¦, åä¸º, å°ç±³")
                except Exception as e:
                    st.error(f"å¯¼å…¥ç¤ºä¾‹æ•°æ®å¤±è´¥: {str(e)}")
                    st.code(traceback.format_exc())
        
        # åˆ›å»ºä¸¤ä¸ªç´§å‡‘åŒºåŸŸï¼šå®ä½“æœç´¢å’Œå…³ç³»æ¢ç´¢
        search_container = st.container()
        relation_container = st.container()
        
        with search_container:
            st.markdown("<h5 style='font-size:0.9rem; margin:0.05rem 0;'>å®ä½“æœç´¢</h5>", unsafe_allow_html=True)
            
            # ä½¿ç”¨ä¸¤åˆ—å¸ƒå±€ï¼Œä½¿æ§ä»¶æ›´ç´§å‡‘
            search_cols = st.columns([1, 1])
            
            with search_cols[0]:
                # é€‰æ‹©å®ä½“ç±»å‹
                entity_type = st.selectbox(
                    "é€‰æ‹©å®ä½“ç±»å‹",
                    ["å…¬å¸(company)", "è¡Œä¸š(industry)", "äº§å“(product)", "æ‰€æœ‰ç±»å‹(all)"],
                    label_visibility="collapsed"
                )
                st.caption("å®ä½“ç±»å‹")
            
            with search_cols[1]:
                # å®ä½“åç§°æœç´¢
                search_term = st.text_input("å®ä½“åç§°", label_visibility="collapsed", placeholder="è¾“å…¥å…³é”®è¯")
                st.caption("æœç´¢å…³é”®è¯")
            
            # æœç´¢é€‰é¡¹æŠ˜å é¢æ¿ - æ”¹ä¸ºè¡Œå†…å¸ƒå±€
            with st.expander("æœç´¢é€‰é¡¹", expanded=False):
                option_cols = st.columns(2)
                with option_cols[0]:
                    case_sensitive = st.checkbox("åŒºåˆ†å¤§å°å†™", value=False)
                    limit_results = st.slider("ç»“æœæ•°é‡", 10, 100, 20)
                with option_cols[1]:
                    exact_match = st.checkbox("ç²¾ç¡®åŒ¹é…", value=False)
            
            # æœç´¢æŒ‰é’®
            if st.button("æœç´¢å®ä½“", use_container_width=True):
                if not search_term:
                    st.warning("è¯·è¾“å…¥æœç´¢å…³é”®è¯")
                else:
                    with st.spinner("æ­£åœ¨æœç´¢..."):
                        try:
                            # æå–å®ä½“ç±»å‹
                            if entity_type == "æ‰€æœ‰ç±»å‹(all)":
                                entity_label = None
                            else:
                                entity_label = entity_type.split("(")[1].split(")")[0]
                            
                            # æ„å»ºCypheræŸ¥è¯¢
                            if entity_label:
                                if exact_match:
                                    if case_sensitive:
                                        query = f"""
                                        MATCH (n:{entity_label})
                                        WHERE n.name = $search_term
                                        RETURN n.name AS name, labels(n) AS labels
                                        LIMIT {limit_results}
                                        """
                                    else:
                                        query = f"""
                                        MATCH (n:{entity_label})
                                        WHERE toLower(n.name) = toLower($search_term)
                                        RETURN n.name AS name, labels(n) AS labels
                                        LIMIT {limit_results}
                                        """
                                else:
                                    if case_sensitive:
                                        query = f"""
                                        MATCH (n:{entity_label})
                                        WHERE n.name CONTAINS $search_term
                                        RETURN n.name AS name, labels(n) AS labels
                                        LIMIT {limit_results}
                                        """
                                    else:
                                        query = f"""
                                        MATCH (n:{entity_label})
                                        WHERE toLower(n.name) CONTAINS toLower($search_term)
                                        RETURN n.name AS name, labels(n) AS labels
                                        LIMIT {limit_results}
                                        """
                            else:
                                # æœç´¢æ‰€æœ‰ç±»å‹
                                if exact_match:
                                    if case_sensitive:
                                        query = f"""
                                        MATCH (n)
                                        WHERE n.name = $search_term
                                        RETURN n.name AS name, labels(n) AS labels
                                        LIMIT {limit_results}
                                        """
                                    else:
                                        query = f"""
                                        MATCH (n)
                                        WHERE toLower(n.name) = toLower($search_term)
                                        RETURN n.name AS name, labels(n) AS labels
                                        LIMIT {limit_results}
                                        """
                                else:
                                    if case_sensitive:
                                        query = f"""
                                        MATCH (n)
                                        WHERE n.name CONTAINS $search_term
                                        RETURN n.name AS name, labels(n) AS labels
                                        LIMIT {limit_results}
                                        """
                                    else:
                                        query = f"""
                                        MATCH (n)
                                        WHERE toLower(n.name) CONTAINS toLower($search_term)
                                        RETURN n.name AS name, labels(n) AS labels
                                        LIMIT {limit_results}
                                        """
                            
                            # æ‰§è¡ŒæŸ¥è¯¢
                            result = handler.g.run(query, search_term=search_term).data()
                            
                            if result:
                                st.session_state.search_result = result
                                # ä¸åœ¨è¿™é‡Œæ˜¾ç¤ºç»“æœï¼Œç»“æœå°†åœ¨å³ä¾§æ˜¾ç¤º
                            else:
                                st.info(f"æœªæ‰¾åˆ°åŒ¹é… '{search_term}' çš„å®ä½“")
                                st.session_state.search_result = []
                        except Exception as e:
                            st.error(f"æœç´¢å¤±è´¥: {str(e)}")
                            st.session_state.search_result = []
        
        with relation_container:
            st.markdown("<h5 style='font-size:0.9rem; margin:0.05rem 0;'>å…³ç³»æ¢ç´¢</h5>", unsafe_allow_html=True)
            
            if 'search_result' in st.session_state and st.session_state.search_result:
                # ä»æœç´¢ç»“æœä¸­é€‰æ‹©å®ä½“
                entity_names = [item['name'] for item in st.session_state.search_result]
                selected_entity = st.selectbox("é€‰æ‹©å®ä½“", entity_names, help="é€‰æ‹©è¦æ¢ç´¢å…³ç³»çš„å®ä½“")
                
                # å…³ç³»æ·±åº¦å’Œæ¢ç´¢æŒ‰é’®æ”¾åœ¨åŒä¸€è¡Œ
                rel_cols = st.columns([2, 1])
                with rel_cols[0]:
                    depth = st.slider("æ¢ç´¢æ·±åº¦", 1, 3, 1, help="è®¾ç½®å…³ç³»æ¢ç´¢çš„æ·±åº¦")
                
                with rel_cols[1]:
                    explore_button = st.button("æ¢ç´¢å…³ç³»", use_container_width=True)
                
                if explore_button:
                    with st.spinner(f"æ­£åœ¨æ¢ç´¢ {selected_entity} çš„å…³ç³»..."):
                        try:
                            # æ„å»ºCypheræŸ¥è¯¢ - è·¯å¾„æŸ¥è¯¢
                            query = f"""
                            MATCH path = (n)-[*1..{depth}]-(m)
                            WHERE n.name = $entity_name
                            RETURN path
                            LIMIT 100
                            """
                            
                            # æ‰§è¡ŒæŸ¥è¯¢
                            result = handler.g.run(query, entity_name=selected_entity).data()
                            
                            if result:
                                # æå–èŠ‚ç‚¹å’Œå…³ç³»
                                nodes = set()
                                relationships = []
                                
                                for record in result:
                                    path = record['path']
                                    # å¤„ç†è·¯å¾„ä¸­çš„èŠ‚ç‚¹å’Œå…³ç³»
                                    path_nodes = path.nodes
                                    path_relationships = path.relationships
                                    
                                    for node in path_nodes:
                                        nodes.add((node.identity, node.get('name'), list(node.labels)[0]))
                                    
                                    for rel in path_relationships:
                                        start_node = rel.start_node.get('name')
                                        end_node = rel.end_node.get('name')
                                        rel_type = type(rel).__name__
                                        relationships.append((start_node, rel_type, end_node))
                                
                                # å­˜å‚¨åˆ°ä¼šè¯çŠ¶æ€
                                st.session_state.explored_nodes = list(nodes)
                                st.session_state.explored_relationships = relationships
                                
                                # ä¸åœ¨è¿™é‡Œæ˜¾ç¤ºç»“æœï¼Œç»“æœå°†åœ¨å³ä¾§æ˜¾ç¤º
                            else:
                                st.info(f"æœªæ‰¾åˆ°ä¸ '{selected_entity}' ç›¸å…³çš„å…³ç³»")
                                st.session_state.explored_nodes = []
                                st.session_state.explored_relationships = []
                        except Exception as e:
                            st.error(f"å…³ç³»æ¢ç´¢å¤±è´¥: {str(e)}")
                            st.session_state.explored_nodes = []
                            st.session_state.explored_relationships = []
            else:
                st.info("è¯·å…ˆæœç´¢å¹¶é€‰æ‹©å®ä½“")
    
    with main_cols[1]:  # å³ä¾§ç»“æœåŒº
        # ä½¿ç”¨tabsç»„ç»‡ä¸åŒç±»å‹çš„ç»“æœï¼Œä½¿æ˜¾ç¤ºæ›´ç´§å‡‘
        result_tabs = st.tabs(["å®ä½“æœç´¢ç»“æœ", "å…³ç³»æ¢ç´¢ç»“æœ", "å¯è§†åŒ–"])
        
        with result_tabs[0]:  # å®ä½“æœç´¢ç»“æœ
            if 'search_result' in st.session_state and st.session_state.search_result:
                # æ˜¾ç¤ºæœç´¢ç»“æœè¡¨æ ¼ - å¢åŠ é«˜åº¦ä»¥æ˜¾ç¤ºæ›´å¤šç»“æœ
                df = pd.DataFrame(st.session_state.search_result)
                st.dataframe(df, use_container_width=True, height=400)
                
                # æ˜¾ç¤ºæ‰¾åˆ°çš„å®ä½“æ•°é‡
                st.success(f"æ‰¾åˆ° {len(st.session_state.search_result)} ä¸ªåŒ¹é…çš„å®ä½“")
            else:
                st.info("è¯·åœ¨å·¦ä¾§æœç´¢å®ä½“")
        
        with result_tabs[1]:  # å…³ç³»æ¢ç´¢ç»“æœ
            if 'explored_relationships' in st.session_state and st.session_state.explored_relationships:
                # åˆ›å»ºå…³ç³»æ•°æ®æ¡† - å¢åŠ é«˜åº¦ä»¥æ˜¾ç¤ºæ›´å¤šç»“æœ
                rel_data = []
                for start, rel_type, end in st.session_state.explored_relationships:
                    rel_data.append({
                        "èµ·å§‹å®ä½“": start,
                        "å…³ç³»ç±»å‹": rel_type,
                        "ç›®æ ‡å®ä½“": end
                    })
                
                if rel_data:
                    rel_df = pd.DataFrame(rel_data)
                    st.dataframe(rel_df, use_container_width=True, height=400)
                    
                    # æ˜¾ç¤ºæ‰¾åˆ°çš„å…³ç³»æ•°é‡
                    st.success(f"æ‰¾åˆ° {len(rel_data)} ä¸ªå…³ç³»")
                
                # åˆ›å»ºå…³ç³»ç½‘ç»œè¡¨æ ¼ - ä¸ä½¿ç”¨HTMLç›´æ¥å±•ç¤ºï¼Œæ”¹ç”¨st.table
                st.subheader("å…³ç³»ç½‘ç»œè¡¨")
                
                # åˆ›å»ºè¡¨æ ¼æ•°æ®
                network_data = []
                for i, (start, rel_type, end) in enumerate(st.session_state.explored_relationships[:20]):
                    network_data.append({
                        "åºå·": i+1,
                        "èµ·å§‹å®ä½“": start,
                        "å…³ç³»": rel_type,
                        "ç›®æ ‡å®ä½“": end
                    })
                
                if network_data:
                    network_df = pd.DataFrame(network_data)
                    st.table(network_df)
                    
                    if len(st.session_state.explored_relationships) > 20:
                        st.caption(f"ä»…æ˜¾ç¤ºå‰20ä¸ªå…³ç³»ï¼Œå…±æ‰¾åˆ° {len(st.session_state.explored_relationships)} ä¸ªå…³ç³»")
            else:
                st.info("è¯·åœ¨å·¦ä¾§æ¢ç´¢å®ä½“å…³ç³»")
        
        with result_tabs[2]:  # å¯è§†åŒ–
            if 'explored_relationships' in st.session_state and st.session_state.explored_relationships:
                st.subheader("å…³ç³»ç½‘ç»œå›¾")
                
                # åˆ›å»ºç½‘ç»œå›¾æ•°æ®
                network_nodes = []
                network_edges = []
                
                # å¤„ç†èŠ‚ç‚¹
                node_map = {}  # ç”¨äºæ˜ å°„èŠ‚ç‚¹åç§°åˆ°ç´¢å¼•
                
                if 'explored_nodes' in st.session_state:
                    for i, (node_id, node_name, node_type) in enumerate(st.session_state.explored_nodes):
                        node_map[node_name] = i
                        network_nodes.append({
                            "id": i,
                            "label": node_name,
                            "group": node_type
                        })
                
                # å¤„ç†è¾¹
                for start, rel_type, end in st.session_state.explored_relationships:
                    if start in node_map and end in node_map:
                        network_edges.append({
                            "from": node_map[start],
                            "to": node_map[end],
                            "label": rel_type
                        })
                
                # åˆ›å»ºç½‘ç»œå›¾é…ç½®
                network_options = {
                    "nodes": {
                        "shape": "dot",
                        "size": 30,
                        "font": {"size": 12}
                    },
                    "edges": {
                        "arrows": "to",
                        "smooth": {"type": "cubicBezier"},
                        "font": {"size": 10, "align": "middle"}
                    },
                    "physics": {
                        "forceAtlas2Based": {
                            "gravitationalConstant": -50,
                            "springLength": 100,
                            "springConstant": 0.08
                        },
                        "maxVelocity": 50,
                        "solver": "forceAtlas2Based",
                        "timestep": 0.5
                    }
                }
                
                # ä½¿ç”¨Streamlitç»„ä»¶åº“æ˜¾ç¤ºç½‘ç»œå›¾
                try:
                    # ä½¿ç”¨kg_network_visualizationæ¨¡å—æ˜¾ç¤ºç½‘ç»œå›¾
                    success, message = visualize_network(st.session_state.explored_nodes, st.session_state.explored_relationships, node_map)
                    
                    if not success:
                        st.error(message)
                        
                        # å¦‚æœç½‘ç»œå›¾æ˜¾ç¤ºå¤±è´¥ï¼Œå›é€€åˆ°å…³ç³»çŸ©é˜µ
                        st.warning('æ— æ³•æ˜¾ç¤ºç½‘ç»œå›¾ï¼Œå°†æ˜¾ç¤ºå…³ç³»çŸ©é˜µä½œä¸ºæ›¿ä»£')
                        fig = visualize_matrix(st.session_state.explored_relationships, node_map)
                        st.pyplot(fig)
                    else:
                        # æ·»åŠ å…³ç³»çŸ©é˜µä½œä¸ºå¯é€‰è§†å›¾
                        with st.expander('æŸ¥çœ‹å…³ç³»çŸ©é˜µ'):
                            fig = visualize_matrix(st.session_state.explored_relationships, node_map)
                            st.pyplot(fig)
                except Exception as e:
                    st.error(f"æ— æ³•æ˜¾ç¤ºç½‘ç»œå›¾: {str(e)}")
            else:
                st.info("è¯·åœ¨å·¦ä¾§æ¢ç´¢å®ä½“å…³ç³»ä»¥ç”Ÿæˆå¯è§†åŒ–")

with tab4:
    st.markdown("<h4 style='font-size:1rem; margin:0.1rem 0;'>çŸ¥è¯†å›¾è°±å¯è§†åŒ–</h4>", unsafe_allow_html=True)

    # --- Main Layout: Control Column and Result Column ---
    control_col, result_col = st.columns([1, 2])

    # --- LEFT: CONTROL COLUMN ---
    with control_col:
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>å¯è§†åŒ–æ§åˆ¶é¢æ¿</h5>", unsafe_allow_html=True)

        vis_type = st.selectbox(
            "å¯è§†åŒ–ç±»å‹",
            ["ç½‘ç»œå›¾", "å±‚çº§æ ‘", "å…³ç³»çŸ©é˜µ", "äº§ä¸šé“¾"],
            help="é€‰æ‹©å›¾è¡¨ç±»å‹ã€‚"
        )

        entity_type = st.selectbox(
            "å®ä½“ç±»å‹",
            ["industry", "company", "product"],
            help="é€‰æ‹©è¦æŸ¥è¯¢çš„å®ä½“ç±»å‹ã€‚"
        )

        depth = st.slider(
            "æ¢ç´¢æ·±åº¦",
            min_value=1, max_value=3, value=2,
            help="æ§åˆ¶å…³ç³»æ¢ç´¢çš„æ·±åº¦ã€‚"
        )

        st.markdown("**å®ä½“åç§°**")
        name_search = st.text_input(
            "æœç´¢å®ä½“åç§°",
            help="è¾“å…¥å…³é”®è¯ä»¥è¿‡æ»¤ä¸‹é¢çš„åˆ—è¡¨ã€‚"
        )

        @st.cache_data(ttl=300)
        def get_filtered_entities(entity_type, search_term=""):
            try:
                query = f'MATCH (n:{entity_type}) WHERE toLower(n.name) CONTAINS toLower($term) RETURN n.name AS name ORDER BY n.name LIMIT 100'
                results = handler.g.run(query, term=search_term).data()
                return [record["name"] for record in results]
            except Exception as e:
                return []

        filtered_entities = get_filtered_entities(entity_type, name_search)
        
        if not filtered_entities:
            st.info("æœªæ‰¾åˆ°åŒ¹é…å®ä½“ï¼Œè¯·å°è¯•ä¸åŒå…³é”®è¯ã€‚")

        entity_name = st.selectbox(
            "é€‰æ‹©å®ä½“",
            options=filtered_entities if filtered_entities else ["æ— å¯ç”¨é€‰é¡¹"],
            help="ä»è¿‡æ»¤ç»“æœä¸­é€‰æ‹©ä¸€ä¸ªå®ä½“ã€‚"
        )

        if st.button("ç”Ÿæˆå¯è§†åŒ–", use_container_width=True, key="generate_vis_btn"):
            if not entity_name or entity_name == "æ— å¯ç”¨é€‰é¡¹":
                st.warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæœ‰æ•ˆçš„å®ä½“")
            else:
                st.session_state.vis_params = {
                    "vis_type": vis_type,
                    "entity_type": entity_type,
                    "entity_name": entity_name,
                    "depth": depth
                }

    # --- RIGHT: RESULT COLUMN ---
    with result_col:
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>å¯è§†åŒ–ç»“æœ</h5>", unsafe_allow_html=True)

        if 'vis_params' not in st.session_state:
            st.info("è¯·åœ¨å·¦ä¾§é¢æ¿ä¸­é€‰æ‹©å‚æ•°å¹¶ç‚¹å‡»\"ç”Ÿæˆå¯è§†åŒ–\"ä»¥æ˜¾ç¤ºå›¾è¡¨ã€‚")
        else:
            params = st.session_state.vis_params
            with st.spinner(f"æ­£åœ¨ç”Ÿæˆ {params['entity_name']} çš„ {params['vis_type']}..."):
                try:
                    if params['vis_type'] == "ç½‘ç»œå›¾":
                        success, message = display_network_graph(handler, params['entity_type'], params['entity_name'], params['depth'])
                    elif params['vis_type'] == "å±‚çº§æ ‘":
                        success, message = display_hierarchy_tree(handler, params['entity_type'], params['entity_name'], params['depth'])
                    elif params['vis_type'] == "å…³ç³»çŸ©é˜µ":
                        success, message = display_relationship_matrix(handler, params['entity_type'], params['entity_name'], params['depth'])
                    elif params['vis_type'] == "äº§ä¸šé“¾":
                        success, message = display_industry_chain(handler, params['entity_type'], params['entity_name'], params['depth'])
                    
                    if not success:
                        st.error(message)
                except Exception as e:
                    st.error(f"ç”Ÿæˆå¯è§†åŒ–æ—¶å‘ç”Ÿé”™è¯¯: {e}")

with tab5:
    st.markdown("<h4 style='font-size:1rem; margin:0.1rem 0;'>è¡Œä¸šé“¾åˆ†æ</h4>", unsafe_allow_html=True)
    
    # ä¿®æ”¹ä¸ºæ›´ç´§å‡‘çš„ä¸‰åˆ—å¸ƒå±€ï¼Œä½¿ç”¨æ›´å¤šæ°´å¹³ç©ºé—´
    analysis_col1, analysis_col2, analysis_col3 = st.columns([1, 1.5, 1.5])
    
    with analysis_col1:
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>åˆ†æå‚æ•°</h5>", unsafe_allow_html=True)
        
        # é€‰æ‹©åˆ†æç±»å‹ - ä½¿ç”¨æ›´ç´§å‡‘çš„é€‰æ‹©æ¡†
        analysis_type = st.selectbox(
            "åˆ†æç±»å‹",
            ["äº§ä¸šé“¾åˆ†æ", "ç«äº‰æƒ…æŠ¥åˆ†æ", "ä¼ä¸šå…³è”åˆ†æ", "äº§å“æŠ€æœ¯åˆ†æ"],
            help="äº§ä¸šé“¾åˆ†æï¼šåˆ†æè¡Œä¸šä¸Šä¸‹æ¸¸å…³ç³»å’Œç»“æ„\n"
                 "ç«äº‰æƒ…æŠ¥åˆ†æï¼šåˆ†æä¼ä¸šé—´ç«äº‰å…³ç³»\n"
                 "ä¼ä¸šå…³è”åˆ†æï¼šå‘ç°ä¼ä¸šé—´éšè—è”ç³»\n"
                 "äº§å“æŠ€æœ¯åˆ†æï¼šåˆ†æäº§å“æŠ€æœ¯è·¯çº¿å›¾",
            label_visibility="collapsed"
        )
        st.caption("åˆ†æç±»å‹")
        
        # æ–°å¢ï¼šè·å–æ•°æ®åº“ä¸­å­˜åœ¨çš„å…³ç³»ç±»å‹
        @st.cache_data(ttl=300)  # ç¼“å­˜5åˆ†é’Ÿ
        def get_relationship_types():
            try:
                query = """
                CALL db.relationshipTypes() YIELD relationshipType
                RETURN collect(relationshipType) AS types
                """
                result = handler.g.run(query).data()
                if result and result[0]["types"]:
                    return result[0]["types"]
                return []
            except Exception as e:
                logger.error(f"è·å–å…³ç³»ç±»å‹å¤±è´¥: {e}")
                return []
        
        # æ–°å¢ï¼šè·å–æ•°æ®åº“ä¸­çƒ­é—¨è¡Œä¸šï¼ˆæœ‰æœ€å¤šå…³è”çš„è¡Œä¸šï¼‰
        @st.cache_data(ttl=300)  # ç¼“å­˜5åˆ†é’Ÿ
        def get_popular_industries():
            try:
                query = """
                MATCH (i:industry)
                OPTIONAL MATCH (i)-[r]-()
                WITH i, count(r) AS rel_count
                RETURN i.name AS name, rel_count
                ORDER BY rel_count DESC
                LIMIT 10
                """
                result = handler.g.run(query).data()
                return [record["name"] for record in result if record["name"]]
            except Exception as e:
                logger.error(f"è·å–çƒ­é—¨è¡Œä¸šå¤±è´¥: {e}")
                return []
        
        # è·å–å®é™…å…³ç³»ç±»å‹å’Œçƒ­é—¨è¡Œä¸š
        rel_types = get_relationship_types()
        popular_industries = get_popular_industries()
        
        # é€‰æ‹©è¡Œä¸š
        industry_options = get_filtered_entities("industry", "")
        
        # å¦‚æœæ²¡æœ‰æœç´¢ç»“æœï¼Œæ˜¾ç¤ºçƒ­é—¨è¡Œä¸š
        if not industry_options and popular_industries:
            industry_options = popular_industries
        elif not industry_options:
            industry_options = ["è¯·å…ˆå¯¼å…¥è¡Œä¸šæ•°æ®"]
        
        # æ˜¾ç¤ºçƒ­é—¨è¡Œä¸šæ¨è - æ”¹ä¸ºå†…è”æ˜¾ç¤º
        if popular_industries:
            st.caption("æ¨èè¡Œä¸šï¼š" + ", ".join(popular_industries[:3]) + ("..." if len(popular_industries) > 3 else ""))
        
        selected_industry = st.selectbox(
            "é€‰æ‹©è¡Œä¸š",
            options=industry_options,
            help="é€‰æ‹©è¦åˆ†æçš„è¡Œä¸š",
            label_visibility="collapsed"
        )
        st.caption("é€‰æ‹©è¡Œä¸š")
        
        # åˆ†ææ·±åº¦ - ä½¿ç”¨æ›´ç´§å‡‘çš„æ»‘å—
        analysis_depth = st.slider(
            "åˆ†ææ·±åº¦",
            min_value=1,
            max_value=3,
            value=2,
            help="åˆ†æçš„æ·±åº¦ï¼Œè¶Šæ·±åˆ†æè¶Šå…¨é¢ä½†å¯èƒ½å¯¼è‡´ç»“æœè¿‡å¤š",
            label_visibility="collapsed"
        )
        st.caption("åˆ†ææ·±åº¦")
        
        # åˆ†æç»´åº¦ - ä½¿ç”¨æ°´å¹³æ’åˆ—çš„å¤é€‰æ¡†
        st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>åˆ†æç»´åº¦</h6>", unsafe_allow_html=True)
        dim_cols = st.columns(2)
        with dim_cols[0]:
            include_companies = st.checkbox("ä¼ä¸š", value=True)
            include_upstream = st.checkbox("ä¸Šæ¸¸", value=True)
        with dim_cols[1]:
            include_products = st.checkbox("äº§å“", value=True)
            include_downstream = st.checkbox("ä¸‹æ¸¸", value=True)
        
        # åˆ†ææŒ‰é’®
        if st.button("å¼€å§‹åˆ†æ", use_container_width=True):
            if selected_industry == "è¯·å…ˆå¯¼å…¥è¡Œä¸šæ•°æ®":
                st.warning("è¯·å…ˆå¯¼å…¥è¡Œä¸šæ•°æ®")
            else:
                with st.spinner(f"æ­£åœ¨åˆ†æ {selected_industry} è¡Œä¸š..."):
                    try:
                        # æ–°å¢ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶é€‚é…å…³ç³»ç±»å‹
                        # é»˜è®¤å…³ç³»ç±»å‹æ˜ å°„
                        rel_type_mapping = {
                            "company_industry": ["å±äº", "éš¶å±", "æ‰€å±", "BELONGS_TO"],
                            "industry_upstream": ["ä¸Šæ¸¸ææ–™", "ä¸Šæ¸¸", "UPSTREAM", "SUPPLIES"],
                            "company_product": ["æ‹¥æœ‰", "ç”Ÿäº§", "ä¸»è¥", "OWNS", "PRODUCES"],
                            "industry_product": ["åŒ…å«", "ä¸»è¥", "CONTAINS", "INCLUDES"]
                        }
                        
                        # æ ¹æ®æ•°æ®åº“ä¸­å®é™…å­˜åœ¨çš„å…³ç³»ç±»å‹è°ƒæ•´æŸ¥è¯¢
                        company_industry_rels = [r for r in rel_types if any(r.lower().find(x.lower()) >= 0 for x in ["å±äº", "éš¶å±", "æ‰€å±", "belongs"])]
                        industry_upstream_rels = [r for r in rel_types if any(r.lower().find(x.lower()) >= 0 for x in ["ä¸Šæ¸¸", "ææ–™", "upstream", "supplies"])]
                        company_product_rels = [r for r in rel_types if any(r.lower().find(x.lower()) >= 0 for x in ["æ‹¥æœ‰", "ç”Ÿäº§", "ä¸»è¥", "owns", "produces"])]
                        industry_product_rels = [r for r in rel_types if any(r.lower().find(x.lower()) >= 0 for x in ["åŒ…å«", "ä¸»è¥", "contains", "includes"])]
                        
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å…³ç³»ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        if not company_industry_rels:
                            company_industry_rels = rel_type_mapping["company_industry"]
                        if not industry_upstream_rels:
                            industry_upstream_rels = rel_type_mapping["industry_upstream"]
                        if not company_product_rels:
                            company_product_rels = rel_type_mapping["company_product"]
                        if not industry_product_rels:
                            industry_product_rels = rel_type_mapping["industry_product"]
                        
                        # æ„å»ºæŸ¥è¯¢æ¡ä»¶ï¼Œä½¿ç”¨ORè¿æ¥å¤šä¸ªå¯èƒ½çš„å…³ç³»ç±»å‹
                        conditions = []
                        company_condition = ""
                        product_condition = ""
                        upstream_condition = ""
                        downstream_condition = ""
                        
                        if include_companies:
                            company_rel_patterns = "|".join(company_industry_rels)
                            company_condition = f"(i)<-[:{company_rel_patterns}]-(c:company)"
                            conditions.append(company_condition)
                        
                        if include_products:
                            product_rel_patterns = "|".join(company_product_rels + industry_product_rels)
                            product_condition = f"(i)-[:{product_rel_patterns}]-(p:product)"
                            conditions.append(product_condition)
                        
                        if include_upstream:
                            upstream_rel_patterns = "|".join(industry_upstream_rels)
                            # ä¿®æ”¹ï¼šå°†ä¸¤ä¸ªæ–¹å‘çš„å…³ç³»æŸ¥è¯¢åˆ†æˆä¸¤ä¸ªç‹¬ç«‹çš„OPTIONAL MATCHè¯­å¥
                            upstream_condition_1 = f"(i)-[:{upstream_rel_patterns}]->(up:industry)"
                            upstream_condition_2 = f"(up:industry)-[:{upstream_rel_patterns}]->(i)"
                            conditions.append(upstream_condition_1)
                            conditions.append(upstream_condition_2)
                        
                        if include_downstream:
                            downstream_rel_patterns = "|".join(industry_upstream_rels)
                            # ä¿®æ”¹ï¼šå°†ä¸¤ä¸ªæ–¹å‘çš„å…³ç³»æŸ¥è¯¢åˆ†æˆä¸¤ä¸ªç‹¬ç«‹çš„OPTIONAL MATCHè¯­å¥
                            downstream_condition_1 = f"(i)<-[:{downstream_rel_patterns}]-(down:industry)"
                            downstream_condition_2 = f"(down:industry)<-[:{downstream_rel_patterns}]-(i)"
                            conditions.append(downstream_condition_1)
                            conditions.append(downstream_condition_2)
                        
                        # å¦‚æœæ²¡æœ‰é€‰æ‹©ä»»ä½•æ¡ä»¶ï¼Œæ·»åŠ é»˜è®¤æ¡ä»¶
                        if not conditions:
                            conditions.append("(i)")
                        
                        # æ„å»ºCypheræŸ¥è¯¢
                        query_parts = []
                        for i, condition in enumerate(conditions):
                            query_parts.append(f"OPTIONAL MATCH {condition}")
                        
                        # æ·»åŠ è¡Œä¸šåç§°è¿‡æ»¤æ¡ä»¶
                        query = "MATCH (i:industry {name: $industry_name})\n" + "\n".join(query_parts) + "\n"
                        
                        # æ ¹æ®åˆ†æç±»å‹æ·»åŠ è¿”å›è¯­å¥
                        if analysis_type == "äº§ä¸šé“¾åˆ†æ":
                            query += """
                            RETURN 
                                collect(DISTINCT i) as industry,
                                collect(DISTINCT c) as companies,
                                collect(DISTINCT p) as products,
                                collect(DISTINCT up) as upstream,
                                collect(DISTINCT down) as downstream
                            """
                        elif analysis_type == "ç«äº‰æƒ…æŠ¥åˆ†æ":
                            query += f"""
                            WITH i, collect(DISTINCT c) as companies
                            UNWIND companies as c1
                            MATCH (c1)-[:{company_rel_patterns}]->(i)<-[:{company_rel_patterns}]-(c2:company)
                            WHERE c1 <> c2
                            RETURN i.name as industry, 
                                   c1.name as company1, 
                                   c2.name as company2,
                                   count(c1) as strength
                            ORDER BY strength DESC
                            LIMIT 20
                            """
                        elif analysis_type == "ä¼ä¸šå…³è”åˆ†æ":
                            query += """
                            WITH i, collect(DISTINCT c) as companies
                            UNWIND companies as c1
                            MATCH (c1)-[r]-(other)
                            WHERE NOT other:industry
                            RETURN c1.name as company, 
                                   type(r) as relationship,
                                   other.name as related_entity,
                                   labels(other)[0] as entity_type
                            LIMIT 30
                            """
                        else:  # äº§å“æŠ€æœ¯åˆ†æ
                            query += """
                            WITH i, collect(DISTINCT p) as products
                            UNWIND products as prod
                            OPTIONAL MATCH (prod)-[r]-(other)
                            RETURN prod.name as product,
                                   collect(DISTINCT other.name) as related_entities,
                                   count(r) as connection_count
                            ORDER BY connection_count DESC
                            LIMIT 20
                            """
                        
                        # æ‰§è¡ŒæŸ¥è¯¢
                        st.code(query, language="cypher")
                        results = handler.g.run(query, industry_name=selected_industry).data()
                        
                        # å­˜å‚¨ç»“æœåˆ°ä¼šè¯çŠ¶æ€
                        st.session_state.analysis_results = {
                            "type": analysis_type,
                            "industry": selected_industry,
                            "depth": analysis_depth,
                            "results": results,
                            "dimensions": {
                                "companies": include_companies,
                                "products": include_products,
                                "upstream": include_upstream,
                                "downstream": include_downstream
                            },
                            "rel_types": {
                                "company_industry": company_industry_rels,
                                "industry_upstream": industry_upstream_rels,
                                "company_product": company_product_rels,
                                "industry_product": industry_product_rels
                            }
                        }
                        
                        st.success(f"åˆ†æå®Œæˆï¼Œæ‰¾åˆ° {len(results)} æ¡ç»“æœ")
                    except Exception as e:
                        st.error(f"åˆ†æå¤±è´¥: {str(e)}")
                        st.code(traceback.format_exc())
    
    # åˆ†æç»“æœåŒºåŸŸ - åˆ†ä¸ºä¸¤åˆ—æ˜¾ç¤º
    with analysis_col2:
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>æ•°æ®è¡¨æ ¼</h5>", unsafe_allow_html=True)
        
        if 'analysis_results' not in st.session_state:
            st.info("è¯·é€‰æ‹©è¡Œä¸šå¹¶ç‚¹å‡»ã€Œå¼€å§‹åˆ†æã€æŒ‰é’®")
        else:
            analysis_data = st.session_state.analysis_results
            
            # æ˜¾ç¤ºåˆ†ææ‘˜è¦
            st.markdown(f"**è¡Œä¸š**: {analysis_data['industry']} | **åˆ†æç±»å‹**: {analysis_data['type']}")
            
            # æ ¹æ®åˆ†æç±»å‹æ˜¾ç¤ºä¸åŒçš„ç»“æœ
            if analysis_data['type'] == "äº§ä¸šé“¾åˆ†æ":
                # åˆ›å»ºäº§ä¸šé“¾å¯è§†åŒ–
                if not analysis_data['results']:
                    st.warning("æœªæ‰¾åˆ°äº§ä¸šé“¾æ•°æ®")
                else:
                    # æå–æ•°æ®
                    industry_data = analysis_data['results'][0]
                    
                    # åˆ›å»ºä¸Šä¸‹æ¸¸è¡¨æ ¼å’Œä¼ä¸šåˆ†å¸ƒè¡¨æ ¼
                    upstream_data = []
                    downstream_data = []
                    companies_data = []
                    
                    if 'upstream' in industry_data and industry_data['upstream']:
                        for up in industry_data['upstream']:
                            if hasattr(up, 'get'):
                                upstream_data.append({"è¡Œä¸šåç§°": up.get('name', 'æœªçŸ¥'), "ç±»å‹": "ä¸Šæ¸¸"})
                    
                    if 'downstream' in industry_data and industry_data['downstream']:
                        for down in industry_data['downstream']:
                            if hasattr(down, 'get'):
                                downstream_data.append({"è¡Œä¸šåç§°": down.get('name', 'æœªçŸ¥'), "ç±»å‹": "ä¸‹æ¸¸"})
                    
                    if 'companies' in industry_data and industry_data['companies']:
                        for company in industry_data['companies']:
                            if hasattr(company, 'get'):
                                companies_data.append({"ä¼ä¸šåç§°": company.get('name', 'æœªçŸ¥')})
                    
                    # æ˜¾ç¤ºä¸Šä¸‹æ¸¸è¡¨æ ¼
                    if upstream_data or downstream_data:
                        st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>ä¸Šä¸‹æ¸¸è¡Œä¸š</h6>", unsafe_allow_html=True)
                        chain_df = pd.DataFrame(upstream_data + downstream_data)
                        st.dataframe(chain_df, use_container_width=True, height=150)
                    
                    # æ˜¾ç¤ºä¼ä¸šåˆ†å¸ƒè¡¨æ ¼
                    if companies_data:
                        st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>ä¼ä¸šåˆ†å¸ƒ</h6>", unsafe_allow_html=True)
                        companies_df = pd.DataFrame(companies_data)
                        st.dataframe(companies_df, use_container_width=True, height=150)
            
            elif analysis_data['type'] == "ç«äº‰æƒ…æŠ¥åˆ†æ":
                if not analysis_data['results']:
                    st.warning("æœªæ‰¾åˆ°ç«äº‰æƒ…æŠ¥æ•°æ®")
                else:
                    # åˆ›å»ºç«äº‰å…³ç³»è¡¨æ ¼
                    competition_data = []
                    for item in analysis_data['results']:
                        competition_data.append({
                            "ä¼ä¸š1": item.get('company1', 'æœªçŸ¥'),
                            "ä¼ä¸š2": item.get('company2', 'æœªçŸ¥'),
                            "å…³è”å¼ºåº¦": item.get('strength', 0)
                        })
                    
                    if competition_data:
                        st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>ä¼ä¸šç«äº‰å…³ç³»</h6>", unsafe_allow_html=True)
                        competition_df = pd.DataFrame(competition_data)
                        st.dataframe(competition_df, use_container_width=True, height=250)
            
            elif analysis_data['type'] == "ä¼ä¸šå…³è”åˆ†æ":
                if not analysis_data['results']:
                    st.warning("æœªæ‰¾åˆ°ä¼ä¸šå…³è”æ•°æ®")
                else:
                    # åˆ›å»ºä¼ä¸šå…³è”è¡¨æ ¼
                    relation_data = []
                    for item in analysis_data['results']:
                        relation_data.append({
                            "ä¼ä¸š": item.get('company', 'æœªçŸ¥'),
                            "å…³ç³»ç±»å‹": item.get('relationship', 'æœªçŸ¥'),
                            "å…³è”å®ä½“": item.get('related_entity', 'æœªçŸ¥'),
                            "å®ä½“ç±»å‹": item.get('entity_type', 'æœªçŸ¥')
                        })
                    
                    if relation_data:
                        st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>ä¼ä¸šå…³è”ç½‘ç»œ</h6>", unsafe_allow_html=True)
                        relation_df = pd.DataFrame(relation_data)
                        st.dataframe(relation_df, use_container_width=True, height=250)
            
            else:  # äº§å“æŠ€æœ¯åˆ†æ
                if not analysis_data['results']:
                    st.warning("æœªæ‰¾åˆ°äº§å“æŠ€æœ¯æ•°æ®")
                else:
                    # åˆ›å»ºäº§å“æŠ€æœ¯è¡¨æ ¼
                    product_data = []
                    for item in analysis_data['results']:
                        product_data.append({
                            "äº§å“": item.get('product', 'æœªçŸ¥'),
                            "å…³è”å®ä½“æ•°": item.get('connection_count', 0),
                            "å…³è”å®ä½“": ", ".join(item.get('related_entities', []))[:50] + ("..." if len(", ".join(item.get('related_entities', []))) > 50 else "")
                        })
                    
                    if product_data:
                        st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>äº§å“æŠ€æœ¯è·¯çº¿å›¾</h6>", unsafe_allow_html=True)
                        product_df = pd.DataFrame(product_data)
                        st.dataframe(product_df, use_container_width=True, height=250)
    
    # å¯è§†åŒ–å’Œæ´å¯ŸåŒºåŸŸ
    with analysis_col3:
        st.markdown("<h5 style='font-size:0.9rem; margin:0.1rem 0;'>å¯è§†åŒ–ä¸æ´å¯Ÿ</h5>", unsafe_allow_html=True)
        
        if 'analysis_results' not in st.session_state:
            st.info("åˆ†æç»“æœå°†åœ¨æ­¤æ˜¾ç¤º")
        else:
            analysis_data = st.session_state.analysis_results
            
            # æ ¹æ®åˆ†æç±»å‹æ˜¾ç¤ºä¸åŒçš„å¯è§†åŒ–
            if analysis_data['type'] == "äº§ä¸šé“¾åˆ†æ":
                st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>äº§ä¸šé“¾å›¾</h6>", unsafe_allow_html=True)
                st.info("äº§ä¸šé“¾å›¾å°†åœ¨æ­¤æ˜¾ç¤º")
                # è¿™é‡Œå¯ä»¥æ·»åŠ EChartsæˆ–å…¶ä»–å¯è§†åŒ–åº“çš„ä»£ç 
            
            elif analysis_data['type'] == "ç«äº‰æƒ…æŠ¥åˆ†æ":
                st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>ç«äº‰ç½‘ç»œå›¾</h6>", unsafe_allow_html=True)
                st.info("ç«äº‰ç½‘ç»œå›¾å°†åœ¨æ­¤æ˜¾ç¤º")
                # è¿™é‡Œå¯ä»¥æ·»åŠ EChartsæˆ–å…¶ä»–å¯è§†åŒ–åº“çš„ä»£ç 
            
            elif analysis_data['type'] == "ä¼ä¸šå…³è”åˆ†æ":
                st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>å…³è”ç½‘ç»œå›¾</h6>", unsafe_allow_html=True)
                st.info("ä¼ä¸šå…³è”ç½‘ç»œå›¾å°†åœ¨æ­¤æ˜¾ç¤º")
                # è¿™é‡Œå¯ä»¥æ·»åŠ EChartsæˆ–å…¶ä»–å¯è§†åŒ–åº“çš„ä»£ç 
            
            else:  # äº§å“æŠ€æœ¯åˆ†æ
                st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>äº§å“æŠ€æœ¯å…³è”å›¾</h6>", unsafe_allow_html=True)
                st.info("äº§å“æŠ€æœ¯å…³è”å›¾å°†åœ¨æ­¤æ˜¾ç¤º")
                # è¿™é‡Œå¯ä»¥æ·»åŠ EChartsæˆ–å…¶ä»–å¯è§†åŒ–åº“çš„ä»£ç 
            
            # æ·»åŠ åˆ†ææ´å¯Ÿ - ç›´æ¥æ˜¾ç¤ºè€Œä¸æ˜¯æ”¾åœ¨expanderä¸­
            st.markdown("<h6 style='font-size:0.8rem; margin:0.1rem 0;'>æ•°æ®æ´å¯Ÿ</h6>", unsafe_allow_html=True)
            
            # æ ¹æ®å®é™…æ•°æ®ç”Ÿæˆæ´å¯Ÿ
            insights = []
            
            # è·å–æ•°æ®ç»Ÿè®¡
            if analysis_data['type'] == "äº§ä¸šé“¾åˆ†æ" and analysis_data['results']:
                industry_data = analysis_data['results'][0]
                
                # ç»Ÿè®¡æ•°æ®
                companies_count = len(industry_data.get('companies', []))
                products_count = len(industry_data.get('products', []))
                upstream_count = len(industry_data.get('upstream', []))
                downstream_count = len(industry_data.get('downstream', []))
                
                # ç”Ÿæˆæ´å¯Ÿ
                if companies_count > 0:
                    insights.append(f"**ä¼ä¸šåˆ†å¸ƒ**ï¼š{analysis_data['industry']}è¡Œä¸šå…±æœ‰{companies_count}å®¶ç›¸å…³ä¼ä¸š")
                    
                    # å¢å¼ºï¼šä¼ä¸šé›†ä¸­åº¦åˆ†æ
                    if companies_count > 5:
                        insights.append(f"**ä¼ä¸šé›†ä¸­åº¦**ï¼šè¯¥è¡Œä¸šä¼ä¸šæ•°é‡è¾ƒå¤šï¼Œå¸‚åœºç«äº‰è¾ƒä¸ºå……åˆ†")
                    else:
                        insights.append(f"**ä¼ä¸šé›†ä¸­åº¦**ï¼šè¯¥è¡Œä¸šä¼ä¸šæ•°é‡è¾ƒå°‘ï¼Œå¯èƒ½å­˜åœ¨å¯¡å¤´ç«äº‰æ ¼å±€")
                
                if products_count > 0:
                    insights.append(f"**äº§å“åˆ†å¸ƒ**ï¼šè¯¥è¡Œä¸šæ¶‰åŠ{products_count}ç§äº§å“æˆ–æœåŠ¡")
                
                if upstream_count > 0 or downstream_count > 0:
                    insights.append(f"**äº§ä¸šé“¾ç»“æ„**ï¼šå‘ç°{upstream_count}ä¸ªä¸Šæ¸¸è¡Œä¸šå’Œ{downstream_count}ä¸ªä¸‹æ¸¸è¡Œä¸š")
                    
                    # å¢å¼ºï¼šäº§ä¸šé“¾ä½ç½®åˆ†æ
                    if upstream_count > 0 and downstream_count == 0:
                        insights.append(f"**äº§ä¸šé“¾ä½ç½®**ï¼šè¯¥è¡Œä¸šä½äºäº§ä¸šé“¾æœ«ç«¯ï¼Œä¸ºç»ˆç«¯æ¶ˆè´¹æˆ–åº”ç”¨è¡Œä¸š")
                    elif upstream_count == 0 and downstream_count > 0:
                        insights.append(f"**äº§ä¸šé“¾ä½ç½®**ï¼šè¯¥è¡Œä¸šä½äºäº§ä¸šé“¾æºå¤´ï¼Œä¸ºåŸºç¡€åŸææ–™æˆ–æŠ€æœ¯è¡Œä¸š")
                    else:
                        insights.append(f"**äº§ä¸šé“¾ä½ç½®**ï¼šè¯¥è¡Œä¸šä½äºäº§ä¸šé“¾ä¸­æ¸¸ï¼Œæ‰¿ä¸Šå¯ä¸‹")
            
            elif analysis_data['type'] == "ç«äº‰æƒ…æŠ¥åˆ†æ" and analysis_data['results']:
                # ç»Ÿè®¡ç«äº‰å¯¹æ‰‹æ•°é‡
                companies = set()
                for item in analysis_data['results']:
                    companies.add(item.get('company1', ''))
                    companies.add(item.get('company2', ''))
                
                if companies:
                    insights.append(f"**ç«äº‰æ ¼å±€**ï¼š{analysis_data['industry']}è¡Œä¸šä¸­å‘ç°{len(companies)}å®¶ä¸»è¦ç«äº‰ä¼ä¸š")
                    
                    # å¢å¼ºï¼šç«äº‰å…³ç³»å¯†åº¦åˆ†æ
                    competition_pairs = len(analysis_data['results'])
                    max_pairs = len(companies) * (len(companies) - 1) / 2
                    competition_density = competition_pairs / max_pairs if max_pairs > 0 else 0
                    
                    if competition_density > 0.7:
                        insights.append(f"**ç«äº‰å¼ºåº¦**ï¼šç«äº‰å…³ç³»å¯†åº¦ä¸º{competition_density:.1%}ï¼Œå¸‚åœºç«äº‰æ¿€çƒˆ")
                    elif competition_density > 0.3:
                        insights.append(f"**ç«äº‰å¼ºåº¦**ï¼šç«äº‰å…³ç³»å¯†åº¦ä¸º{competition_density:.1%}ï¼Œå¸‚åœºç«äº‰è¾ƒä¸ºå……åˆ†")
                    else:
                        insights.append(f"**ç«äº‰å¼ºåº¦**ï¼šç«äº‰å…³ç³»å¯†åº¦ä¸º{competition_density:.1%}ï¼Œå¯èƒ½å­˜åœ¨ç»†åˆ†å¸‚åœºåŒºéš”")
            
            elif analysis_data['type'] == "ä¼ä¸šå…³è”åˆ†æ" and analysis_data['results']:
                # ç»Ÿè®¡å…³ç³»ç±»å‹
                rel_types = {}
                for item in analysis_data['results']:
                    rel_type = item.get('relationship', 'æœªçŸ¥')
                    if rel_type not in rel_types:
                        rel_types[rel_type] = 0
                    rel_types[rel_type] += 1
                
                if rel_types:
                    main_rel_type = max(rel_types.items(), key=lambda x: x[1])[0]
                    insights.append(f"**å…³ç³»ç½‘ç»œ**ï¼šä¼ä¸šé—´ä¸»è¦é€šè¿‡'{main_rel_type}'å…³ç³»è¿›è¡Œè¿æ¥ï¼Œå…±{len(rel_types)}ç§å…³è”")
                    
                    # å¢å¼ºï¼šå…³ç³»å¤šæ ·æ€§åˆ†æ
                    if len(rel_types) > 3:
                        insights.append(f"**å…³ç³»å¤šæ ·æ€§**ï¼šä¼ä¸šé—´å­˜åœ¨{len(rel_types)}ç§ä¸åŒç±»å‹çš„å…³è”ï¼Œå…³ç³»ç½‘ç»œä¸°å¯Œå¤šæ ·")
            
            elif analysis_data['type'] == "äº§å“æŠ€æœ¯åˆ†æ" and analysis_data['results']:
                # ç»Ÿè®¡äº§å“æ•°é‡å’Œå…³è”å¼ºåº¦
                if analysis_data['results']:
                    product_count = len(analysis_data['results'])
                    avg_connections = sum(item.get('connection_count', 0) for item in analysis_data['results']) / product_count if product_count > 0 else 0
                    
                    insights.append(f"**äº§å“åˆ†æ**ï¼š{analysis_data['industry']}è¡Œä¸šæ¶‰åŠ{product_count}ç§ä¸»è¦äº§å“ï¼Œå¹³å‡æ¯ç§äº§å“æœ‰{avg_connections:.1f}ä¸ªå…³è”å®ä½“")
                    
                    # å¢å¼ºï¼šäº§å“å…³è”åº¦åˆ†æ
                    if avg_connections > 5:
                        insights.append(f"**äº§å“å…³è”åº¦**ï¼šäº§å“å¹³å‡å…³è”åº¦ä¸º{avg_connections:.1f}ï¼Œäº§å“é—´é›†æˆåº¦é«˜")
                    else:
                        insights.append(f"**äº§å“å…³è”åº¦**ï¼šäº§å“å¹³å‡å…³è”åº¦ä¸º{avg_connections:.1f}ï¼Œäº§å“ç›¸å¯¹ç‹¬ç«‹")
                    
                    # å¢å¼ºï¼šäº§å“æŠ€æœ¯è·¯å¾„åˆ†æ
                    if avg_connections > 0:
                        max_conn_item = max(analysis_data['results'], key=lambda x: x.get('connection_count', 0))
                        insights.append(f"**æ ¸å¿ƒäº§å“**ï¼š{max_conn_item.get('product', '')}æ˜¯è¯¥è¡Œä¸šå…³è”æœ€å¹¿æ³›çš„äº§å“ï¼Œå…±æœ‰{max_conn_item.get('connection_count', 0)}ä¸ªå…³è”å®ä½“")
            
            # å¦‚æœæ²¡æœ‰ç”Ÿæˆä»»ä½•æ´å¯Ÿï¼Œæ·»åŠ ä¸€ä¸ªé€šç”¨æç¤º
            if not insights:
                insights.append("**æ•°æ®ä¸è¶³**ï¼šå½“å‰åˆ†æçš„æ•°æ®é‡ä¸è¶³ä»¥ç”Ÿæˆæœ‰æ„ä¹‰çš„æ´å¯Ÿã€‚è¯·å°è¯•é€‰æ‹©å…¶ä»–è¡Œä¸šæˆ–å¯¼å…¥æ›´å¤šæ•°æ®ã€‚")
            
            # æ˜¾ç¤ºæ´å¯Ÿ
            for insight in insights[:5]:  # é™åˆ¶æ˜¾ç¤ºå‰5æ¡æ´å¯Ÿ
                st.markdown(f"- {insight}")
            
            # å¦‚æœæœ‰æ›´å¤šæ´å¯Ÿï¼Œæä¾›å±•å¼€é€‰é¡¹
            if len(insights) > 5:
                with st.expander("æ˜¾ç¤ºæ›´å¤šæ´å¯Ÿ"):
                    for insight in insights[5:]:
                        st.markdown(f"- {insight}")
            
            # æ·»åŠ å…³ç³»ç±»å‹ä¿¡æ¯ - ç®€åŒ–æ˜¾ç¤º
            if 'rel_types' in analysis_data:
                st.caption("ä½¿ç”¨çš„å…³ç³»ç±»å‹ï¼š" + ", ".join([rel_list[0] if rel_list else "" for rel_category, rel_list in analysis_data['rel_types'].items() if rel_list]))